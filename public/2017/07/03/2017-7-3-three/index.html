<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8" />
  
  <title>机器学习笔记（十一）神经网络应用 | Serenityd Blog</title>
  <meta name="author" content="Serenityd" />

  
  <meta name="description" content="关于非线性转化方程(non-linear transformation function)sigmoid函数(S 曲线)用来作为activation function:1.1双曲函数(tanh)1.2逻辑函数(logistic function)
用类实现一个简单的神经网络算法" />
  

  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

  <meta property="og:title" content="机器学习笔记（十一）神经网络应用" />
  <meta property="og:site_name" content="Serenityd Blog" />

  
  

  
    <meta property="og:image" content="" />
  

  
  <link href="/css/images/favicon.ico" rel="icon" />
  

  <link rel="alternate" href="/atom.xml" title="Serenityd Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <!-- baidu webmaster push -->
  <script src='//push.zhanzhang.baidu.com/push.js'></script>

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Serenityd Blog</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-07-03T13:08:39.000Z"><a href="/2017/07/03/2017-7-3-three/">2017-07-03</a></time>
      
      
  
    <h1 class="title">机器学习笔记（十一）神经网络应用</h1>
  

    </header>
    <div class="entry">
      
        <ol>
<li>关于非线性转化方程(non-linear transformation function)<br>sigmoid函数(S 曲线)用来作为activation function:<br>1.1双曲函数(tanh)<br>1.2逻辑函数(logistic function)</li>
<li><p>用类实现一个简单的神经网络算法</p>
<a id="more"></a>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def tanh(x):  </span><br><span class="line">    <span class="built_in">return</span> np.tanh(x)</span><br><span class="line">def tanh_deriv(x):  </span><br><span class="line">    <span class="built_in">return</span> 1.0 - np.tanh(x)*np.tanh(x)</span><br><span class="line">def logistic(x):  </span><br><span class="line">    <span class="built_in">return</span> 1/(1 + np.exp(-x))</span><br><span class="line">def logistic_derivative(x):  </span><br><span class="line">    <span class="built_in">return</span> logistic(x)*(1-logistic(x))</span><br><span class="line">class NeuralNetwork:   </span><br><span class="line">    def __init__(self, layers, activation=<span class="string">'tanh'</span>):  </span><br><span class="line">        <span class="string">""</span><span class="string">"  </span></span><br><span class="line"><span class="string">        :param layers: A list containing the number of units in each layer.</span></span><br><span class="line"><span class="string">        Should be at least two values  </span></span><br><span class="line"><span class="string">        :param activation: The activation function to be used. Can be</span></span><br><span class="line"><span class="string">        "</span>logistic<span class="string">" or "</span>tanh<span class="string">"  </span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span>  </span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'logistic'</span>:  </span><br><span class="line">            self.activation = logistic  </span><br><span class="line">            self.activation_deriv = logistic_derivative  </span><br><span class="line">        <span class="keyword">elif</span> activation == <span class="string">'tanh'</span>:  </span><br><span class="line">            self.activation = tanh  </span><br><span class="line">            self.activation_deriv = tanh_deriv</span><br><span class="line">    </span><br><span class="line">        self.weights = []  </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(1, len(layers) - 1):  </span><br><span class="line">            self.weights.append((2*np.random.random((layers[i - 1] + 1, layers[i] + 1))-1)*0.25)  </span><br><span class="line">            self.weights.append((2*np.random.random((layers[i] + 1, layers[i + 1]))-1)*0.25)</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">    def fit(self, X, y, learning_rate=0.2, epochs=10000):         </span><br><span class="line">        X = np.atleast_2d(X)         </span><br><span class="line">        temp = np.ones([X.shape[0], X.shape[1]+1])         </span><br><span class="line">        temp[:, 0:-1] = X  <span class="comment"># adding the bias unit to the input layer         </span></span><br><span class="line">        X = temp         </span><br><span class="line">        y = np.array(y)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(epochs):  </span><br><span class="line">            i = np.random.randint(X.shape[0])  </span><br><span class="line">            a = [X[i]]</span><br><span class="line">    </span><br><span class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> range(len(self.weights)):  <span class="comment">#going forward network, for each layer</span></span><br><span class="line">                a.append(self.activation(np.dot(a[l], self.weights[l])))  <span class="comment">#Computer the node value for each layer (O_i) using activation function</span></span><br><span class="line">            error = y[i] - a[-1]  <span class="comment">#Computer the error at the top layer</span></span><br><span class="line">            deltas = [error * self.activation_deriv(a[-1])] <span class="comment">#For output layer, Err calculation (delta is updated error)</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#Staring backprobagation</span></span><br><span class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> range(len(a) - 2, 0, -1): <span class="comment"># we need to begin at the second to last layer </span></span><br><span class="line">                <span class="comment">#Compute the updated error (i,e, deltas) for each node going from top layer to input layer </span></span><br><span class="line">                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))  </span><br><span class="line">            deltas.reverse()  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.weights)):  </span><br><span class="line">                layer = np.atleast_2d(a[i])  </span><br><span class="line">                delta = np.atleast_2d(deltas[i])  </span><br><span class="line">                self.weights[i] += learning_rate * layer.T.dot(delta)</span><br><span class="line">                </span><br><span class="line">                </span><br><span class="line">    def predict(self, x):         </span><br><span class="line">        x = np.array(x)         </span><br><span class="line">        temp = np.ones(x.shape[0]+1)         </span><br><span class="line">        temp[0:-1] = x         </span><br><span class="line">        a = temp         </span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(0, len(self.weights)):             </span><br><span class="line">            a = self.activation(np.dot(a, self.weights[l]))         </span><br><span class="line">        <span class="built_in">return</span> a</span><br></pre></td></tr></table></figure>
</li>
<li><p>简单非线性关系数据集测试(XOR):<br>X:                  Y<br>0 0                 0<br>0 1                 1<br>1 0                 1<br>1 1                 0</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from NeuralNetwork import NeuralNetwork</span><br><span class="line">import numpy as np</span><br><span class="line">nn = NeuralNetwork([2,2,1], <span class="string">'tanh'</span>)     </span><br><span class="line">X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])     </span><br><span class="line">y = np.array([0, 1, 1, 0])     </span><br><span class="line">nn.fit(X, y)     </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [[0, 0], [0, 1], [1, 0], [1,1]]:    </span><br><span class="line">    <span class="built_in">print</span>(i, nn.predict(i))</span><br></pre></td></tr></table></figure>
</li>
<li><p>手写数字识别：<br>每个图片8x8<br>识别数字：0,1,2,3,4,5,6,7,8,9</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np </span><br><span class="line">from sklearn.datasets import load_digits </span><br><span class="line">from sklearn.metrics import confusion_matrix, classification_report </span><br><span class="line">from sklearn.preprocessing import LabelBinarizer </span><br><span class="line">from NeuralNetwork import NeuralNetwork</span><br><span class="line">from sklearn.cross_validation import train_test_split</span><br><span class="line">digits = load_digits()  </span><br><span class="line">X = digits.data  </span><br><span class="line">y = digits.target  </span><br><span class="line">X -= X.min() <span class="comment"># normalize the values to bring them into the range 0-1  </span></span><br><span class="line">X /= X.max()</span><br><span class="line">nn = NeuralNetwork([64,100,10],<span class="string">'logistic'</span>)  </span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y)  </span><br><span class="line">labels_train = LabelBinarizer().fit_transform(y_train)  </span><br><span class="line">labels_test = LabelBinarizer().fit_transform(y_test)</span><br><span class="line"><span class="built_in">print</span> <span class="string">"start fitting"</span></span><br><span class="line">nn.fit(X_train,labels_train,epochs=3000)  </span><br><span class="line">predictions = []  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(X_test.shape[0]):  </span><br><span class="line">    o = nn.predict(X_test[i] )  </span><br><span class="line">    predictions.append(np.argmax(o))  </span><br><span class="line"><span class="built_in">print</span> confusion_matrix(y_test,predictions)  </span><br><span class="line"><span class="built_in">print</span> classification_report(y_test,predictions)</span><br></pre></td></tr></table></figure></li>
</ol>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">分享</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/机器学习/">机器学习</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Buscar">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">Entradas Recientes</h3>
  <ul class="entry">
    
      <li>
        <a href="/2018/02/03/2018-02-03-one/">2018-02-03-one</a>
      </li>
    
      <li>
        <a href="/2017/11/10/2017-11-10-one/">git学习笔记</a>
      </li>
    
      <li>
        <a href="/2017/09/21/2017-9-21-two/">机器学习笔记（二十三） hierarchical clustering 层次聚类应用（完）</a>
      </li>
    
      <li>
        <a href="/2017/09/21/2017-9-21-one/">机器学习笔记（二十二）hierarchical clustering 层次聚类</a>
      </li>
    
      <li>
        <a href="/2017/09/18/2017-9-18-one/">机器学习笔记（二十一）聚类(Clustering) K-means算法应用</a>
      </li>
    
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">Etiquetas</h3>
  <ul class="entry">
  
    <li><a href="/tags/BaiduYun/">BaiduYun</a><small>1</small></li>
  
    <li><a href="/tags/LATEX/">LATEX</a><small>2</small></li>
  
    <li><a href="/tags/git/">git</a><small>1</small></li>
  
    <li><a href="/tags/github/">github</a><small>1</small></li>
  
    <li><a href="/tags/hexo/">hexo</a><small>4</small></li>
  
    <li><a href="/tags/python/">python</a><small>8</small></li>
  
    <li><a href="/tags/多肉植物/">多肉植物</a><small>1</small></li>
  
    <li><a href="/tags/机器学习/">机器学习</a><small>23</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Nube de Etiquetas</h3>
  <div class="entry">
    <a href="/tags/BaiduYun/" style="font-size: 10px;">BaiduYun</a> <a href="/tags/LATEX/" style="font-size: 12.5px;">LATEX</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/python/" style="font-size: 17.5px;">python</a> <a href="/tags/多肉植物/" style="font-size: 10px;">多肉植物</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  <p>
  
  &copy; 2018 Serenityd
  
  All rights reserved.</p>
  <p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></p>
</div>
<div class="clearfix"></div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>
</footer>
  <script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id='bg'></div>
</body>
</html>