{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"themes/landfarz/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/landfarz/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/landfarz/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/landfarz/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/landfarz/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/landfarz/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/landfarz/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/landfarz/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/landfarz/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/landfarz/source/js/gallery.js","path":"js/gallery.js","modified":0,"renderable":1},{"_id":"themes/landfarz/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":0,"renderable":1},{"_id":"themes/landfarz/source/css/font/fontawesome-webfont.eot","path":"css/font/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/landfarz/source/css/font/fontawesome-webfont.woff","path":"css/font/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/landfarz/source/css/images/favicon.ico","path":"css/images/favicon.ico","modified":0,"renderable":1},{"_id":"themes/landfarz/source/css/images/favicon1.ico","path":"css/images/favicon1.ico","modified":0,"renderable":1},{"_id":"themes/landfarz/source/css/font/fontawesome-webfont.ttf","path":"css/font/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/landfarz/source/css/font/fontawesome-webfont.svg","path":"css/font/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/landfarz/source/css/images/body.jpg","path":"css/images/body.jpg","modified":0,"renderable":1},{"_id":"themes/landfarz/source/css/images/body2.jpg","path":"css/images/body2.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"dfe3d683d1e4b6cb30d40eee43eb08697bea3de4","modified":1515830877000},{"_id":"themes/landfarz/LICENSE","hash":"ccf796b213c60a50d27e907c11463c30cf979576","modified":1517544663853},{"_id":"themes/landfarz/README.md","hash":"625967b434141eb98fbb7a62a9ec405809481cac","modified":1517544663853},{"_id":"themes/landfarz/_config.yml","hash":"f7d7ef65580c8fb8b03009f28e55b38e6eddaedd","modified":1517544663853},{"_id":"source/_posts/2016-6-26-one.md","hash":"268d17b47bdcba798a81110a975c3e54e9c7eee9","modified":1515830877000},{"_id":"source/_posts/2017-11-10-one.md","hash":"c2b9f5b9796443b21fde8403700a04dd4acb9eb2","modified":1515830877000},{"_id":"source/_posts/2017-6-14-one.md","hash":"f6d8f71ee7f03e17b05c378b01017d17cc5e1dd1","modified":1515830877000},{"_id":"source/_posts/2017-6-15-one.md","hash":"7994979818339d418500809e311c6ab88f353e5f","modified":1515830877000},{"_id":"source/_posts/2017-6-15-two.md","hash":"65ce0358cb7412817672c0986e20717b0a54d686","modified":1515830877000},{"_id":"source/_posts/2017-6-21-one.md","hash":"ba5ebe5ba79304c74b60e569fe83d33baefd3c4a","modified":1515830877000},{"_id":"source/_posts/2017-6-21-three.md","hash":"e3a2d359685c2dba4d56b09a09d073d0a1ea445a","modified":1515830877000},{"_id":"source/_posts/2017-6-21-two.md","hash":"e63b9ae1885a16a54c87b1f1bab523ca5955c3dc","modified":1515830877000},{"_id":"source/_posts/2017-6-23-one.md","hash":"9d8ef264001b8ec90aa5636834075c87d8661c9a","modified":1515830877000},{"_id":"source/_posts/2017-6-23-three.md","hash":"dcd0426dc134c3cc9809f409ff9de70ba9160eb3","modified":1515830877000},{"_id":"source/_posts/2017-6-23-two.md","hash":"6c89169a0337357cf3450611f20d706e17011d13","modified":1515830877000},{"_id":"source/_posts/2017-6-26-two.md","hash":"a90291edfbd3321d976feee4cb04744f75c69dd5","modified":1515830877000},{"_id":"source/_posts/2017-6-27-four.md","hash":"b2e6c9930f626785347f9739d735e544b8b52e71","modified":1515830877000},{"_id":"source/_posts/2017-6-27-one.md","hash":"a97110f919786babe9f4818256bcbacbb67c3b2d","modified":1515830877000},{"_id":"source/_posts/2017-6-27-three.md","hash":"69c4d52c0ee5e9b0936b2445335087aa0c85659a","modified":1515830877000},{"_id":"source/_posts/2017-6-27-two.md","hash":"c298432081079480083ba778abce2bb331a26be2","modified":1515830877000},{"_id":"source/_posts/2017-6-28-one.md","hash":"68635f5d821350e0d1149a102ee7998d71930828","modified":1515830877000},{"_id":"source/_posts/2017-6-28-two.md","hash":"07cbb07d239bfc26ca49de97be3d9cc95898ce0f","modified":1515830877000},{"_id":"source/_posts/2017-6-30-one.md","hash":"c40a56da370c06f991423f148290d54579252df8","modified":1515830877000},{"_id":"source/_posts/2017-6-30-three.md","hash":"9792c01a8f0c266be3b37be0290433b860ac62a5","modified":1515830877000},{"_id":"source/_posts/2017-6-30-two.md","hash":"65a7f8ccfeb887643d3e578bdfc8230ee9c5d447","modified":1515830877000},{"_id":"source/_posts/2017-7-1-one.md","hash":"5762882b311d74c569f5e2b28bcd1491de8dca37","modified":1515830877000},{"_id":"source/_posts/2017-7-3-one.md","hash":"c8803c015f3519ba440a1af762b27ed6f2ce0851","modified":1515830877000},{"_id":"source/_posts/2017-7-3-three.md","hash":"1d7295f1421768ae44c48943884ef6cb659705d2","modified":1515830877000},{"_id":"source/_posts/2017-7-3-two.md","hash":"96ebd43d052eadccbb637b8f80f6000ee986fbc7","modified":1515830877000},{"_id":"source/_posts/2017-7-8-one.md","hash":"0c89f9019089021444b3f665288d7eff1e955df8","modified":1515830877000},{"_id":"source/_posts/2017-7-8-two.md","hash":"2ca608c87c67262fe57a88e5dd989b5b2ff827c5","modified":1515830877000},{"_id":"source/_posts/2017-8-12-one.md","hash":"28b5aaa23508cd4368dae55286d13c9d50382449","modified":1515830877000},{"_id":"source/_posts/2017-8-31-one.md","hash":"e63e9c44a6583d020d2983b9b0a44b4eb5e18c34","modified":1515830877000},{"_id":"source/_posts/2017-8-12-two.md","hash":"df2678ed7dce447f31cea044c3cf5d9007d01100","modified":1515830877000},{"_id":"source/_posts/2017-9-12-one.md","hash":"ce7c189c443e66f317b42ea1996ac24655867257","modified":1515830877000},{"_id":"source/_posts/2017-9-13-one.md","hash":"724476c82c4d7d23eead416db30f418388ab0d5a","modified":1515830877000},{"_id":"source/_posts/2017-9-13-two.md","hash":"5b31b349ca077a965aaf99d2609a4e0ea5fb47ed","modified":1515830877000},{"_id":"source/_posts/2017-9-14-one.md","hash":"69fb62f6fcfffca04a7a2b14876841b40af4b7b2","modified":1515830877000},{"_id":"source/_posts/2017-9-14-two.md","hash":"a3bf0d8f061172649e8479aace3a946c425e4bf8","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one.md","hash":"803fdb83b9334b6c97c3f6ab3584d9800426dbae","modified":1515830877000},{"_id":"source/_posts/2017-9-18-one.md","hash":"ff67d01d1c6e1d825bd4e90bc0ae2af21be1717f","modified":1515830877000},{"_id":"source/_posts/2017-9-21-one.md","hash":"eb8dbff224034e2c35202d57d06f9eb90c61c723","modified":1515830877000},{"_id":"source/_posts/2017-9-21-two.md","hash":"7d7e08bd1a55deec9b9b0853025fcac59c692548","modified":1515830877000},{"_id":"source/_posts/2018-02-03-one.md","hash":"1a881aef241e339e6f8b16d538fd616cde36c33d","modified":1517644499140},{"_id":"source/_posts/flower.md","hash":"3c692524ba58900fdf9a7bd1efad4656fc32020e","modified":1515830877000},{"_id":"themes/landfarz/layout/archive.ejs","hash":"a18842e3d719fe3ca9b977a6995f8facc75c8673","modified":1517544663869},{"_id":"themes/landfarz/layout/category.ejs","hash":"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea","modified":1517544663869},{"_id":"themes/landfarz/layout/index.ejs","hash":"c7cf84c84c26f1adfc249bc9a7605206fa245f73","modified":1517544663869},{"_id":"themes/landfarz/layout/layout.ejs","hash":"6999916072898aedfe13f4a07211dd1578ad4799","modified":1517544663869},{"_id":"themes/landfarz/layout/page.ejs","hash":"70cbc9854655773cc6ba84eecaaf330fed430465","modified":1517544663869},{"_id":"themes/landfarz/layout/post.ejs","hash":"70cbc9854655773cc6ba84eecaaf330fed430465","modified":1517544663869},{"_id":"themes/landfarz/layout/tag.ejs","hash":"45150a2365768b6b67880193c9264ad2bb4814db","modified":1517544663884},{"_id":"themes/landfarz/languages/de.yml","hash":"1ebe2d4f1b48c84e004c933bec65731fb54c9998","modified":1517544663853},{"_id":"themes/landfarz/languages/default.yml","hash":"360a92ba57b6f7cdfccab4c758f0832f61c6b029","modified":1517544663853},{"_id":"themes/landfarz/languages/es.yml","hash":"727707b95580bbe9773edef4c84a9735fd537742","modified":1517544663853},{"_id":"themes/landfarz/languages/ru.yml","hash":"37161bb9b6cc2dae1f53837185be32e7a0b8abfa","modified":1517544663853},{"_id":"themes/landfarz/languages/zh-CN.yml","hash":"0395331b72062d8a1d7c92e3a45f5f5ca9dda254","modified":1517544663853},{"_id":"themes/landfarz/languages/zh-TW.yml","hash":"2a172dae38a7554b36b031c20dd1625ce12379ed","modified":1517544663853},{"_id":"source/_posts/2017-6-27-one/2.PNG","hash":"f76a880c3faeb66109802c6f0799a8401207e5fe","modified":1515830877000},{"_id":"source/_posts/2017-6-27-one/3.PNG","hash":"c219b606b6ed275754624fb43d89a7f6a41855d4","modified":1515830877000},{"_id":"source/_posts/2017-6-27-one/4.PNG","hash":"c870513166a2457bb1732769b802d0b6ca6d76bc","modified":1515830877000},{"_id":"source/_posts/2017-6-27-one/5.PNG","hash":"3420ef55ec65e28ca213fb1c50e89aa8aeda9605","modified":1515830877000},{"_id":"source/_posts/2017-6-27-one/6.PNG","hash":"fbc8cc835488c64ceb9265e2ddc1d349df0b0259","modified":1515830877000},{"_id":"source/_posts/2017-6-27-one/7.PNG","hash":"1485d57143fb8e4312a4f26d6fb4eb176e358fd1","modified":1515830877000},{"_id":"source/_posts/2017-6-28-one/1.png","hash":"edfbbe0e595efa4aef2ae1b51b30c17423446f12","modified":1515830877000},{"_id":"source/_posts/2017-6-28-one/2.png","hash":"77fecc336bbe81287e1d4dae186fe42750da829f","modified":1515830877000},{"_id":"source/_posts/2017-6-28-one/3.png","hash":"532c0cfe37967c74509964ebaa4ef4997e7454b0","modified":1515830877000},{"_id":"source/_posts/2017-6-30-one/1.png","hash":"043fd7ce7d6bfdd4648444405f97d59443bedb15","modified":1515830877000},{"_id":"source/_posts/2017-6-30-one/2.png","hash":"4d14e33a769a13f54e59ad60a7b0eea0bdcc3de5","modified":1515830877000},{"_id":"source/_posts/2017-6-30-one/4.jpg","hash":"c9ce5fb9ef42151cfafa6444b5a159d1f572f086","modified":1515830877000},{"_id":"source/_posts/2017-6-30-one/3.jpg","hash":"575980026ee1112f5481ebe5cdfe6eeed583e11d","modified":1515830877000},{"_id":"source/_posts/2017-6-30-one/5.png","hash":"c8e5c2817248d704b7827b473abbcc3205b42ca4","modified":1515830877000},{"_id":"source/_posts/2017-6-30-three/1.png","hash":"4d14e33a769a13f54e59ad60a7b0eea0bdcc3de5","modified":1515830877000},{"_id":"source/_posts/2017-6-30-three/2.png","hash":"6b26ac7a96de69c1c0f87a92bbf7b37bf38ef414","modified":1515830877000},{"_id":"source/_posts/2017-6-30-three/3.jpg","hash":"e5b0f33cf251532c39f821db73046971047fd0e5","modified":1515830877000},{"_id":"source/_posts/2017-6-30-three/4.PNG","hash":"f1e70e9258cdc690394241936009cc0e19dff900","modified":1515830877000},{"_id":"source/_posts/2017-7-3-one/1.png","hash":"f75692f985cc85617006a7d7314013e2fdb3e23e","modified":1515830877000},{"_id":"source/_posts/2017-7-3-one/2.jpg","hash":"ff6352a0312ba2fea1edb4879671ee32f15a155f","modified":1515830877000},{"_id":"source/_posts/2017-7-3-one/3.png","hash":"f75692f985cc85617006a7d7314013e2fdb3e23e","modified":1515830877000},{"_id":"source/_posts/2017-7-3-one/4.png","hash":"cffccd3d2ae0e55a07eca9b7d75d00b8adae9261","modified":1515830877000},{"_id":"source/_posts/2017-7-3-one/5.png","hash":"95012599ffbbd3adde15caf0d16ebafeb4207f9d","modified":1515830877000},{"_id":"source/_posts/2017-7-3-one/6.png","hash":"1377ec4e871fe11da53982f627d61fe0251bceb8","modified":1515830877000},{"_id":"source/_posts/2017-7-3-two/1.PNG","hash":"5543400e97396a0bcdbe5564329144321c8bd4bf","modified":1515830877000},{"_id":"source/_posts/2017-7-8-one/1.png","hash":"6854bb0c58e676e9fb913825a8a7e6d9b89f0a7a","modified":1515830877000},{"_id":"source/_posts/2017-7-8-one/2.png","hash":"7f74b93fee2d27fb699be759a337aae8dc4945e9","modified":1515830877000},{"_id":"source/_posts/2017-7-8-one/3.png","hash":"af49a306c8f07026355820aaaca5f76d5972426d","modified":1515830877000},{"_id":"source/_posts/2017-7-8-two/1.png","hash":"fdacb4dbfc79bbef76236a50d2a0467ad6a23599","modified":1515830877000},{"_id":"source/_posts/2017-7-8-two/2.png","hash":"173c4db001b631a0ec52de86c75dda3a49679db5","modified":1515830877000},{"_id":"source/_posts/2017-8-12-one/2.png","hash":"471af56313ccc441cbe5db4f7aa548cf295c16b3","modified":1515830877000},{"_id":"source/_posts/2017-9-12-one/1.png","hash":"1715f568a75cca2cc36db6ba352078b924105ce3","modified":1515830877000},{"_id":"source/_posts/2017-9-12-one/2.png","hash":"7679549acfe19a03d3efa967b7d2889fd9da2b0d","modified":1515830877000},{"_id":"source/_posts/2017-9-12-one/3.jpg","hash":"5c6ec262381980d564acf60b15a588bd95858a4b","modified":1515830877000},{"_id":"source/_posts/2017-9-12-one/4.jpg","hash":"1e6fff1756ab99dd89849121c1455a67c556a8f0","modified":1515830877000},{"_id":"source/_posts/2017-9-12-one/44.jpg","hash":"bd939fd81296b0cd4aa2f12a7844f5e9eed37de4","modified":1515830877000},{"_id":"source/_posts/2017-9-12-one/5.jpg","hash":"0a347cfc939d6f9455428c501fcf929765efc5fa","modified":1515830877000},{"_id":"source/_posts/2017-9-12-one/6.jpg","hash":"f7497eb1222cf9a25cf7d9e833c3e825ef91aa52","modified":1515830877000},{"_id":"source/_posts/2017-9-14-one/1.png","hash":"bd5a75e07f9d1fa30b879bd891c2077c16709279","modified":1515830877000},{"_id":"source/_posts/2017-9-14-one/2.jpg","hash":"d1ee6c1aeb11a88d3faa97ceac8ee71fd80a9b5d","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/1.jpg","hash":"f7390514129e5779077ba1c2979246651f44fed0","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/2.jpg","hash":"f7390514129e5779077ba1c2979246651f44fed0","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/3.png","hash":"7a6a95e5b1a3f0261d912c17ce040483bddc50bc","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/4.png","hash":"a3b90348091900b010f55cb8aa6eb78c23788255","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/5.png","hash":"b8bd6c7c9c89df253f2d223477eceae47e2bb925","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/6.png","hash":"79b4ccc5c45b7d0d855ed1255db878fc316439f6","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/7.png","hash":"801188575a43eed2f37dfed8cd49011956292516","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/8.png","hash":"e32f84908c3fcdd4fbf9029be3c080411863bb6a","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/c1andc2.png","hash":"fbf7c11e82c5393c33bc5da9cd4ff7e3ffd14370","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/c2.png","hash":"48402638bab14d3a91d79b177549caca4dde6009","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/d0.png","hash":"086f15a55a19b7ddfbefdbd7b56d4f0232764681","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/d1.png","hash":"5ba4dafae1f08262b40e7a0d8deeb53a36d5689a","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/d2.png","hash":"1ee7f5aa0282ff5871238a222c6f1d3bd9bd6206","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/g0.png","hash":"cf791141f7f79ae0d82bac5855a7dfaa1f3eeffa","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/g1.png","hash":"4d0fb504d0b8096ce785bbd2dd8c1ef85ca873a4","modified":1515830877000},{"_id":"source/_posts/2017-9-15-one/g2.png","hash":"9653978561fd5f4cb32b46094f9cb44afe456896","modified":1515830877000},{"_id":"source/_posts/2017-9-21-one/1.png","hash":"63eb6baa6aeb8861400a418780ff442494e1e31b","modified":1515830877000},{"_id":"source/_posts/2017-9-21-two/1.jpg","hash":"14136903b379b6f0e022ca1df86c9f75a736878e","modified":1515830877000},{"_id":"themes/landfarz/layout/_partial/after_footer.ejs","hash":"bddbae01aa0887b1b0164d6820a2c70f47e46c66","modified":1517571708069},{"_id":"themes/landfarz/layout/_partial/article.ejs","hash":"abd81dff0d4e7fc088ff39c84e0dfcbdb9e3328e","modified":1517544663853},{"_id":"themes/landfarz/layout/_partial/archive.ejs","hash":"eaab5ad657f16dfc6cff6f462e1234c3cb8f23a0","modified":1517544663853},{"_id":"themes/landfarz/layout/_partial/comment.ejs","hash":"605ce482540ea710df4c832ee0efcdd9909ce1ee","modified":1517544663853},{"_id":"themes/landfarz/layout/_partial/footer.ejs","hash":"b4c87445b889b79223cf331c278357f4c4cced5c","modified":1517571652514},{"_id":"themes/landfarz/layout/_partial/facebook_comment.ejs","hash":"49ee54e84fe2b70bd9540e2eeba5a85f744941b0","modified":1517544663853},{"_id":"themes/landfarz/layout/_partial/google_analytics.ejs","hash":"d70d287956e90e99ba35b2e14cefb477f9203aa0","modified":1517544663869},{"_id":"themes/landfarz/layout/_partial/head.ejs","hash":"50d951b5c24c3a82a31fa46250de813bfe028171","modified":1517544663869},{"_id":"themes/landfarz/layout/_partial/header.ejs","hash":"73c45d7426009feb495710b054868a7f10616178","modified":1517544663869},{"_id":"themes/landfarz/layout/_partial/mathjax.ejs","hash":"6ef32d42126e9e1a45d2269ddd7d940a0504fdb2","modified":1517638839469},{"_id":"themes/landfarz/layout/_partial/pagination.ejs","hash":"a7df8d2d87c6773b74e8dd1ae044b92d72c5c2b0","modified":1517544663869},{"_id":"themes/landfarz/layout/_partial/sidebar.ejs","hash":"016441ca9534769d8e151cffe4027686e9c86f18","modified":1517544663869},{"_id":"themes/landfarz/layout/_widget/category.ejs","hash":"c163a146b0f963f257ddcc244f413bef281fe0a0","modified":1517544663869},{"_id":"themes/landfarz/layout/_widget/recent_posts.ejs","hash":"59f6f8362fa23a6215e3381151a59c2e2a5fd0d3","modified":1517544663869},{"_id":"themes/landfarz/layout/_widget/search.ejs","hash":"93d4a690494dfa405024f23511846ea00d647be7","modified":1517544663869},{"_id":"themes/landfarz/layout/_widget/tag.ejs","hash":"6bf8214fedb8d6306e017e07ad67aab956496500","modified":1517544663869},{"_id":"themes/landfarz/layout/_widget/tagcloud.ejs","hash":"139e91b1e6abcc1e3883bcc03a9a1a7f1d891d7a","modified":1517544663869},{"_id":"themes/landfarz/source/css/style.styl","hash":"8e8458e78717c49c4ff278b741258d77301f6be4","modified":1517544663900},{"_id":"themes/landfarz/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1517544663900},{"_id":"themes/landfarz/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1517544663900},{"_id":"themes/landfarz/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1517544663900},{"_id":"themes/landfarz/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1517544663900},{"_id":"themes/landfarz/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1517544663900},{"_id":"themes/landfarz/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1517544663900},{"_id":"themes/landfarz/source/fancybox/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1517544663900},{"_id":"themes/landfarz/source/fancybox/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1517544663900},{"_id":"themes/landfarz/source/js/gallery.js","hash":"735a714e54f0ac229f292a90df3a1f882904f6c7","modified":1517544663900},{"_id":"themes/landfarz/source/js/jquery.imagesloaded.min.js","hash":"28ef4346743a60c896a9ae492a544c0854904350","modified":1517544663900},{"_id":"source/_posts/2017-6-21-one/1.JPG","hash":"baee12e8d97b2f92f65537308e76b9b538bca796","modified":1515830877000},{"_id":"source/_posts/2017-6-27-one/1.PNG","hash":"fac5831bbd063d2ac750f430cac5f51107d2d17b","modified":1515830877000},{"_id":"source/_posts/2017-6-28-one/4.png","hash":"dadb1d99824d11f20281fd6654916e0a1a95d360","modified":1515830877000},{"_id":"source/_posts/2017-6-28-two/1.png","hash":"00b8f3041d68287270de25b560c0b08b7fd1c1a9","modified":1515830877000},{"_id":"source/_posts/2017-7-8-one/4.png","hash":"434ae3e7eddbe334f6498add28125e2759946a65","modified":1515830877000},{"_id":"source/_posts/2017-8-12-one/1.png","hash":"434ae3e7eddbe334f6498add28125e2759946a65","modified":1515830877000},{"_id":"themes/landfarz/source/css/_base/utils.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1517544663884},{"_id":"source/_posts/2017-11-10-one/1.png","hash":"f0f0cf049cd43a95dd076e12c5b3acc572ba3374","modified":1515830877000},{"_id":"source/_posts/2017-6-28-two/2.png","hash":"5f6c2e107d309cd28e3b4c1ba3415f63f7167f30","modified":1515830877000},{"_id":"source/_posts/2017-6-28-one/5.png","hash":"e46959d09816d0e6a77f2f7376ddc93e70022562","modified":1515830877000},{"_id":"source/_posts/2018-02-03-one/1.jpg","hash":"a7e0f350ce016ca6887e4425d919ea5157628cb1","modified":1517644637383},{"_id":"source/_posts/flower/flower5.jpg","hash":"3f3fd2aa15d8cf55140a76ec9eee739d0ab9ec0e","modified":1515830877000},{"_id":"themes/landfarz/layout/_partial/post/category.ejs","hash":"8bb3f6ee6296df5a0d527b30d5a46a2387b97cb7","modified":1517544663869},{"_id":"themes/landfarz/layout/_partial/post/gallery.ejs","hash":"fc23ef9b5a412e05436f68ff47146b860d2d4225","modified":1517544663869},{"_id":"themes/landfarz/layout/_partial/post/share.ejs","hash":"991cf130c37f08c7e948772fb45587592b165b55","modified":1517544663869},{"_id":"themes/landfarz/layout/_partial/post/tag.ejs","hash":"b21bbfb5479bd5968a610ba8bdb2bdf10d7a40e9","modified":1517544663869},{"_id":"themes/landfarz/layout/_partial/post/title.ejs","hash":"7f93b310927d6238effdde15234d8cb242940893","modified":1517544663869},{"_id":"themes/landfarz/source/css/_base/layout.styl","hash":"b86dca5de36403f104e16321ccd758385b771134","modified":1517544663884},{"_id":"themes/landfarz/source/css/_base/variable.styl","hash":"0833485db79c55e5f8c1cb4dbe46529424923be8","modified":1517544663884},{"_id":"themes/landfarz/source/css/_partial/archive.styl","hash":"b6fa84ea80bfbdb3a93f64c06a8c652e4242128e","modified":1517544663884},{"_id":"themes/landfarz/source/css/_partial/footer.styl","hash":"bc58fb0d56a26ffa9891c80dd23d9add5cae5bdd","modified":1517544663884},{"_id":"themes/landfarz/source/css/_partial/article.styl","hash":"ca982aa3f89b48077f8c2f977b805a3f1ff0b268","modified":1517544663884},{"_id":"themes/landfarz/source/css/_partial/comment.styl","hash":"85106e428b43e9eb488a71f55b9c4a9c33864d66","modified":1517544663884},{"_id":"themes/landfarz/source/css/_partial/header.styl","hash":"c9de2a1718e8612efa58fc52ff4012d01b96031d","modified":1517544663884},{"_id":"themes/landfarz/source/css/_partial/index.styl","hash":"8c52340a3bf3ce559502bcb9fdbd28a63598f1d6","modified":1517544663884},{"_id":"themes/landfarz/source/css/_partial/sidebar.styl","hash":"35bd524572c4164c9b550ab0c436742f691f4ec4","modified":1517544663884},{"_id":"themes/landfarz/source/css/_partial/syntax.styl","hash":"e08fe789237bca9ea36b8fabaacb2e6070bdc639","modified":1517544663884},{"_id":"themes/landfarz/source/css/font/fontawesome-webfont.eot","hash":"d775f599ff3f23be082e6a9604b4898718923a37","modified":1517544663884},{"_id":"themes/landfarz/source/css/font/fontawesome-webfont.woff","hash":"0612cddf2f835cceffccc88fd194f97367d0b024","modified":1517544663884},{"_id":"themes/landfarz/source/css/images/favicon.ico","hash":"305f376268d162fae3a381e2878d6b99eb554ee3","modified":1517548202925},{"_id":"themes/landfarz/source/css/images/favicon1.ico","hash":"b5b7667c7358e7300c4772d481e556b003716dab","modified":1517544663900},{"_id":"source/_posts/2017-6-30-one/6.png","hash":"c294fd80cd53ca8a1be62bb760555bb3dd95e26e","modified":1515830877000},{"_id":"source/_posts/flower/flower4.jpg","hash":"dc9808a905db7006032340d23f1ecb99adab84cf","modified":1515830877000},{"_id":"source/_posts/flower/flower6.jpg","hash":"1610eeb598f124f0be5c878641188a37c06c6f26","modified":1515830877000},{"_id":"themes/landfarz/source/css/font/fontawesome-webfont.ttf","hash":"a9468f6a1fe965fbcaf5a1bd6c11705e2fc5f84c","modified":1517544663884},{"_id":"themes/landfarz/source/css/font/fontawesome-webfont.svg","hash":"ff51bbb11dfe58345f41cead2c425d6e8be28176","modified":1517544663884},{"_id":"source/_posts/2017-6-30-one/7.png","hash":"8997ce4e05c3324d4386255c169e23bd94b82e5c","modified":1515830877000},{"_id":"themes/landfarz/source/css/images/body.jpg","hash":"0e4ff7537e8d9cf759adda77ca03a11bdf133679","modified":1517545457430},{"_id":"themes/landfarz/source/css/images/body2.jpg","hash":"eeecad49947335286ed22fdf942fa99da32b41ca","modified":1517544663900},{"_id":"source/_posts/flower/flower1.jpg","hash":"9b7552839d3fb89f43ce989c16c245a99ea7f57b","modified":1515830877000},{"_id":"source/_posts/flower/flower3.jpg","hash":"fafbe510e0b77fd17fae5c9756b06b0aa182ec55","modified":1515830877000},{"_id":"source/_posts/flower/flower2.jpg","hash":"4038e2a69621b0c76db8d57e9f3ccdf2ca44be7e","modified":1515830877000},{"_id":"public/2018/02/03/2018-02-03-one/index.html","hash":"6bb4c28c738e9c30f15073422fd1bf7702d921fe","modified":1517644648726},{"_id":"public/2017/11/10/2017-11-10-one/index.html","hash":"6a762c203526dc22a805dbec3b31b0bd97d94eda","modified":1517644648726},{"_id":"public/2017/09/21/2017-9-21-two/index.html","hash":"7e025145370cbed9547ecf1fdb335df5a8439271","modified":1517644648726},{"_id":"public/2017/09/21/2017-9-21-one/index.html","hash":"e1de4b19d36b2cf9cf20704fbe9dd87c34d45273","modified":1517644648726},{"_id":"public/2017/09/15/2017-9-15-one/index.html","hash":"58fc3ccd8935fc6170e0c286105650ad695a0184","modified":1517644648726},{"_id":"public/2017/09/14/2017-9-14-two/index.html","hash":"59a9dfb1a8ed49d945f07d0f3da12275e2850142","modified":1517644648726},{"_id":"public/2017/09/14/2017-9-14-one/index.html","hash":"8121c9db0eefd631e01c0835c3a7da1af87350b8","modified":1517644648726},{"_id":"public/2017/09/13/2017-9-13-two/index.html","hash":"46be152ae82f0f0300bed97418360e24c28818c7","modified":1517644648726},{"_id":"public/2017/09/13/2017-9-13-one/index.html","hash":"df1b2aa44926c8fecd8cd4107494b1ef6e613833","modified":1517644648726},{"_id":"public/2017/09/12/2017-9-12-one/index.html","hash":"a0845b2987d896ea05bfb4d724a6ae609e1ed76a","modified":1517644648726},{"_id":"public/2017/08/31/2017-8-31-one/index.html","hash":"4c06f674decaed9079004b2cab46f87dacdd1e0b","modified":1517644648726},{"_id":"public/2017/08/12/2017-8-12-two/index.html","hash":"756bf9def44b23638a6ce30761456b452ef4c1be","modified":1517644648726},{"_id":"public/2017/08/12/2017-8-12-one/index.html","hash":"4c6d8f92a11a4a7f3da0ae16e15b10774e18181a","modified":1517644648726},{"_id":"public/2017/07/08/2017-7-8-two/index.html","hash":"a96c7c260096f7286d01cdfee2edbe41095f4bb2","modified":1517644648726},{"_id":"public/2017/07/08/2017-7-8-one/index.html","hash":"0dbd4b89fce8b74363e7f2fbe1bc9b60c9a8ccfc","modified":1517644648726},{"_id":"public/2017/07/03/2017-7-3-two/index.html","hash":"234f4998673cfab5f071172effb9f867028d0164","modified":1517644648726},{"_id":"public/2017/07/03/2017-7-3-one/index.html","hash":"cdae0815fc02d4600c83e3b57b43eec03f1086d1","modified":1517644648726},{"_id":"public/2017/06/30/2017-6-30-three/index.html","hash":"150f3620b77372541ecbb9c4e188c778e27a7393","modified":1517644648726},{"_id":"public/2017/06/30/2017-6-30-two/index.html","hash":"bf038f1106c2885fbfe3f2bafac28b908f107a61","modified":1517644648726},{"_id":"public/2017/06/30/2017-6-30-one/index.html","hash":"42e1bc67ea42859d45ac7301ec9d6bbdd997a97b","modified":1517644648726},{"_id":"public/2017/06/28/2017-6-28-two/index.html","hash":"7a13a61df8b1024f3686a94d86997f6b6c92c456","modified":1517644648726},{"_id":"public/2017/06/28/2017-6-28-one/index.html","hash":"0128b837746ec07678bcc027568c00b49dcd5d8b","modified":1517644648726},{"_id":"public/2017/06/27/2017-6-27-three/index.html","hash":"3a354d3909f3b8687488e0f560c069ccb84bf504","modified":1517644648726},{"_id":"public/2017/06/27/2017-6-27-two/index.html","hash":"044df75e91e2770a712da6fcad390d2b9301a627","modified":1517644648726},{"_id":"public/2017/06/27/2017-6-27-one/index.html","hash":"02138199e297dd83e9a7d07866704c397c7f5942","modified":1517644648726},{"_id":"public/2017/06/26/2017-6-26-two/index.html","hash":"9b5b54a1dfb574dfa16a1bb429f86be1f1539bfe","modified":1517644648726},{"_id":"public/2017/06/23/2017-6-23-three/index.html","hash":"8a61cab6c3da002be65c55235625d9fa86a19fa4","modified":1517644648726},{"_id":"public/2017/06/23/2017-6-23-two/index.html","hash":"8db69eb952331539b5ea700e4f16c6f68b0cebd7","modified":1517644648726},{"_id":"public/2017/06/21/2017-6-21-three/index.html","hash":"aef759e6774d41ec5fe18cfb5fa2a79fc2b57b28","modified":1517644648726},{"_id":"public/2017/06/21/2017-6-21-two/index.html","hash":"8ae8cd6a71da6c37dcc65f783e97f224d8fbc7ca","modified":1517644648726},{"_id":"public/2017/06/21/2017-6-21-one/index.html","hash":"27f726cb3ac81ad6103501baed9c1af98eaccbd5","modified":1517644648726},{"_id":"public/2017/06/15/2017-6-15-two/index.html","hash":"4e142e604d44aa4a8a8581b2d96c52b4d3b6db64","modified":1517644648726},{"_id":"public/2017/06/15/2017-6-15-one/index.html","hash":"03f4a7063a94b63e222bf3a7dc9015788b789acd","modified":1517644648726},{"_id":"public/2017/06/14/2017-6-14-one/index.html","hash":"1998c122e552ce73335969e1bb85f5cd48d3d460","modified":1517644648726},{"_id":"public/2017/06/14/flower/index.html","hash":"f42c9ef1e2593682bd37fec2ba5cd159a91517cf","modified":1517644648726},{"_id":"public/archives/index.html","hash":"090418657f180b1c3249e1f15c84f47ee2e827ed","modified":1517644648726},{"_id":"public/archives/page/2/index.html","hash":"23a6a253d0e747e4241c3d0cfc44fda061ab9102","modified":1517644648726},{"_id":"public/archives/page/3/index.html","hash":"eb68a5badad934712410e5a9609102ba7a14a196","modified":1517644648726},{"_id":"public/archives/page/4/index.html","hash":"5438871a8835475ddef169016c2ae62800002633","modified":1517644648726},{"_id":"public/archives/page/5/index.html","hash":"eaa1f25ac0d5b28700b15f77cd0f7f21e142d7af","modified":1517644648726},{"_id":"public/archives/2017/index.html","hash":"8cc9bbb1727fd2398851e436600dcbcaacfa763e","modified":1517644648726},{"_id":"public/archives/2017/page/2/index.html","hash":"ceefac30167bbfe1694f057f347a6e7d14ab805c","modified":1517644648726},{"_id":"public/archives/2017/page/3/index.html","hash":"6bc680c68e5f1aabc5d6b2d4784b008aaf197caf","modified":1517644648726},{"_id":"public/archives/2017/page/4/index.html","hash":"39356b1efc13370141f3477fa409ac9863649119","modified":1517644648726},{"_id":"public/archives/2017/06/index.html","hash":"59aa3554c334f57c98e062954b1bba5cbadb8f34","modified":1517644648726},{"_id":"public/archives/2017/06/page/2/index.html","hash":"a15b5b753df9d5f588b7290dac4b0fb61535bd9b","modified":1517644648726},{"_id":"public/archives/2017/06/page/3/index.html","hash":"1490ef6f55e49571a59a21b399b1da4cf0beb5a7","modified":1517644648726},{"_id":"public/archives/2017/07/index.html","hash":"0a0c506db75ec625a59a0b9388ff89041131e75a","modified":1517644648726},{"_id":"public/archives/2017/08/index.html","hash":"e2b065db0b1ccc302185b47cf19be2421886e3df","modified":1517644648726},{"_id":"public/archives/2017/09/index.html","hash":"c093ac901658da6c7b8af325c50a89b4809c55a8","modified":1517644648726},{"_id":"public/archives/2017/11/index.html","hash":"038424a61a465e6246ad170b7615c5b62c910cbd","modified":1517644648726},{"_id":"public/archives/2018/index.html","hash":"b7b30086b7a6dcf61164592d2e6885d8f8782433","modified":1517644648726},{"_id":"public/archives/2018/02/index.html","hash":"9872215859a04eed8f5921c415d4b12b9383a8b2","modified":1517644648726},{"_id":"public/page/5/index.html","hash":"243bb1a7382dcc47f073dcb22a769006613a3743","modified":1517644648726},{"_id":"public/tags/python/index.html","hash":"ed0460c00f6117dc0447ab935cb41c464bf19540","modified":1517644648726},{"_id":"public/tags/git/index.html","hash":"dc9387c12d65115a207a4f2954e71d8013c30fb5","modified":1517644648726},{"_id":"public/tags/LATEX/index.html","hash":"ecc6d3b97721cbc75b3e2a387f1c41591acfaff8","modified":1517644648726},{"_id":"public/tags/hexo/index.html","hash":"26d563d8d884eb125e18779db111c0491e0da559","modified":1517644648726},{"_id":"public/tags/github/index.html","hash":"dbbe43a1ba2af6ba4846c56a1107cae2a757ea15","modified":1517644648726},{"_id":"public/tags/机器学习/index.html","hash":"73deea8052bcf3936bede35e7a4a00bcde6894bb","modified":1517644648726},{"_id":"public/tags/机器学习/page/2/index.html","hash":"1a7340eff17f86c92cc7442b5f634d9aa22b3b79","modified":1517644648726},{"_id":"public/tags/机器学习/page/3/index.html","hash":"26bd6f68d1edf0f78c4698f1412358736307f3d2","modified":1517644648726},{"_id":"public/tags/BaiduYun/index.html","hash":"5ad0f642768adf99fd3f63e17d42b890ba00e052","modified":1517644648726},{"_id":"public/tags/Hexo/index.html","hash":"815a9e0350f6ef9cedaba272890c3d9d2f83b5d8","modified":1517644648726},{"_id":"public/tags/多肉植物/index.html","hash":"ee9401692397e3dc4e115e2ccd4ceaeaa8850c3a","modified":1517644648726},{"_id":"public/2017/09/18/2017-9-18-one/index.html","hash":"0db634db2e3048f967b3e37fba2dd1df3a3e611f","modified":1517644648726},{"_id":"public/2017/07/03/2017-7-3-three/index.html","hash":"9e9f1ff42be190ab75c552155a85987e1fdaa808","modified":1517644648726},{"_id":"public/2017/07/01/2017-7-1-one/index.html","hash":"ebd931701fc4891bc30efc126c230f3e55612186","modified":1517644648726},{"_id":"public/2017/06/27/2017-6-27-four/index.html","hash":"32bf8d54507b3d5e812f67eaa697009af38fb799","modified":1517644648726},{"_id":"public/2017/06/26/2016-6-26-one/index.html","hash":"4b514b72eabae13043c96ea8758aa1fe9defeb05","modified":1517644648726},{"_id":"public/2017/06/23/2017-6-23-one/index.html","hash":"bf4703bd1b77b1c781b939aa375043ec2cd480d9","modified":1517644648726},{"_id":"public/index.html","hash":"270649dd04ecec05c00dd27c972050a30f825488","modified":1517644648726},{"_id":"public/page/2/index.html","hash":"b5ac8ebab011438cf7460824a4e008c23cbfd4c1","modified":1517644648726},{"_id":"public/page/3/index.html","hash":"4769939f0d29d38db02c9f8e30925f122077c494","modified":1517644648726},{"_id":"public/page/4/index.html","hash":"4e574f3a3347e50910e6b9b3b115713140414bd7","modified":1517644648726},{"_id":"public/CNAME","hash":"dfe3d683d1e4b6cb30d40eee43eb08697bea3de4","modified":1517643691717},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1517643691717},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1517643691717},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1517643691717},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1517643691717},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1517643691732},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1517643691732},{"_id":"public/css/font/fontawesome-webfont.eot","hash":"d775f599ff3f23be082e6a9604b4898718923a37","modified":1517643691732},{"_id":"public/css/font/fontawesome-webfont.woff","hash":"0612cddf2f835cceffccc88fd194f97367d0b024","modified":1517643691732},{"_id":"public/css/images/favicon.ico","hash":"305f376268d162fae3a381e2878d6b99eb554ee3","modified":1517643691732},{"_id":"public/css/images/favicon1.ico","hash":"b5b7667c7358e7300c4772d481e556b003716dab","modified":1517643691732},{"_id":"public/2017/07/03/2017-7-3-two/1.PNG","hash":"5543400e97396a0bcdbe5564329144321c8bd4bf","modified":1517643691732},{"_id":"public/2017/09/21/2017-9-21-one/1.png","hash":"63eb6baa6aeb8861400a418780ff442494e1e31b","modified":1517643691732},{"_id":"public/2017/09/21/2017-9-21-two/1.jpg","hash":"14136903b379b6f0e022ca1df86c9f75a736878e","modified":1517643691732},{"_id":"public/2017/07/08/2017-7-8-two/1.png","hash":"fdacb4dbfc79bbef76236a50d2a0467ad6a23599","modified":1517643691732},{"_id":"public/2017/07/08/2017-7-8-two/2.png","hash":"173c4db001b631a0ec52de86c75dda3a49679db5","modified":1517643691732},{"_id":"public/2017/08/12/2017-8-12-one/2.png","hash":"471af56313ccc441cbe5db4f7aa548cf295c16b3","modified":1517643691732},{"_id":"public/2017/09/14/2017-9-14-one/1.png","hash":"bd5a75e07f9d1fa30b879bd891c2077c16709279","modified":1517643691732},{"_id":"public/2017/09/14/2017-9-14-one/2.jpg","hash":"d1ee6c1aeb11a88d3faa97ceac8ee71fd80a9b5d","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-three/1.png","hash":"4d14e33a769a13f54e59ad60a7b0eea0bdcc3de5","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-three/2.png","hash":"6b26ac7a96de69c1c0f87a92bbf7b37bf38ef414","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-three/3.jpg","hash":"e5b0f33cf251532c39f821db73046971047fd0e5","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-three/4.PNG","hash":"f1e70e9258cdc690394241936009cc0e19dff900","modified":1517643691732},{"_id":"public/2017/07/08/2017-7-8-one/1.png","hash":"6854bb0c58e676e9fb913825a8a7e6d9b89f0a7a","modified":1517643691732},{"_id":"public/2017/07/08/2017-7-8-one/2.png","hash":"7f74b93fee2d27fb699be759a337aae8dc4945e9","modified":1517643691732},{"_id":"public/2017/07/08/2017-7-8-one/3.png","hash":"af49a306c8f07026355820aaaca5f76d5972426d","modified":1517643691732},{"_id":"public/2017/06/28/2017-6-28-one/1.png","hash":"edfbbe0e595efa4aef2ae1b51b30c17423446f12","modified":1517643691732},{"_id":"public/2017/06/28/2017-6-28-one/2.png","hash":"77fecc336bbe81287e1d4dae186fe42750da829f","modified":1517643691732},{"_id":"public/2017/06/28/2017-6-28-one/3.png","hash":"532c0cfe37967c74509964ebaa4ef4997e7454b0","modified":1517643691732},{"_id":"public/2017/07/03/2017-7-3-one/1.png","hash":"f75692f985cc85617006a7d7314013e2fdb3e23e","modified":1517643691732},{"_id":"public/2017/07/03/2017-7-3-one/2.jpg","hash":"ff6352a0312ba2fea1edb4879671ee32f15a155f","modified":1517643691732},{"_id":"public/2017/07/03/2017-7-3-one/3.png","hash":"f75692f985cc85617006a7d7314013e2fdb3e23e","modified":1517643691732},{"_id":"public/2017/07/03/2017-7-3-one/4.png","hash":"cffccd3d2ae0e55a07eca9b7d75d00b8adae9261","modified":1517643691732},{"_id":"public/2017/07/03/2017-7-3-one/5.png","hash":"95012599ffbbd3adde15caf0d16ebafeb4207f9d","modified":1517643691732},{"_id":"public/2017/07/03/2017-7-3-one/6.png","hash":"1377ec4e871fe11da53982f627d61fe0251bceb8","modified":1517643691732},{"_id":"public/2017/06/27/2017-6-27-one/2.PNG","hash":"f76a880c3faeb66109802c6f0799a8401207e5fe","modified":1517643691732},{"_id":"public/2017/06/27/2017-6-27-one/3.PNG","hash":"c219b606b6ed275754624fb43d89a7f6a41855d4","modified":1517643691732},{"_id":"public/2017/06/27/2017-6-27-one/4.PNG","hash":"c870513166a2457bb1732769b802d0b6ca6d76bc","modified":1517643691732},{"_id":"public/2017/06/27/2017-6-27-one/6.PNG","hash":"fbc8cc835488c64ceb9265e2ddc1d349df0b0259","modified":1517643691732},{"_id":"public/2017/06/27/2017-6-27-one/5.PNG","hash":"3420ef55ec65e28ca213fb1c50e89aa8aeda9605","modified":1517643691732},{"_id":"public/2017/06/27/2017-6-27-one/7.PNG","hash":"1485d57143fb8e4312a4f26d6fb4eb176e358fd1","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-one/1.png","hash":"043fd7ce7d6bfdd4648444405f97d59443bedb15","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-one/2.png","hash":"4d14e33a769a13f54e59ad60a7b0eea0bdcc3de5","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-one/3.jpg","hash":"575980026ee1112f5481ebe5cdfe6eeed583e11d","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-one/4.jpg","hash":"c9ce5fb9ef42151cfafa6444b5a159d1f572f086","modified":1517643691732},{"_id":"public/2017/06/30/2017-6-30-one/5.png","hash":"c8e5c2817248d704b7827b473abbcc3205b42ca4","modified":1517643691732},{"_id":"public/2017/09/12/2017-9-12-one/1.png","hash":"1715f568a75cca2cc36db6ba352078b924105ce3","modified":1517643691732},{"_id":"public/2017/09/12/2017-9-12-one/2.png","hash":"7679549acfe19a03d3efa967b7d2889fd9da2b0d","modified":1517643691732},{"_id":"public/2017/09/12/2017-9-12-one/3.jpg","hash":"5c6ec262381980d564acf60b15a588bd95858a4b","modified":1517643691732},{"_id":"public/2017/09/12/2017-9-12-one/4.jpg","hash":"1e6fff1756ab99dd89849121c1455a67c556a8f0","modified":1517643691732},{"_id":"public/2017/09/12/2017-9-12-one/44.jpg","hash":"bd939fd81296b0cd4aa2f12a7844f5e9eed37de4","modified":1517643691732},{"_id":"public/2017/09/12/2017-9-12-one/5.jpg","hash":"0a347cfc939d6f9455428c501fcf929765efc5fa","modified":1517643691732},{"_id":"public/2017/09/12/2017-9-12-one/6.jpg","hash":"f7497eb1222cf9a25cf7d9e833c3e825ef91aa52","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/1.jpg","hash":"f7390514129e5779077ba1c2979246651f44fed0","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/2.jpg","hash":"f7390514129e5779077ba1c2979246651f44fed0","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/3.png","hash":"7a6a95e5b1a3f0261d912c17ce040483bddc50bc","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/4.png","hash":"a3b90348091900b010f55cb8aa6eb78c23788255","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/5.png","hash":"b8bd6c7c9c89df253f2d223477eceae47e2bb925","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/6.png","hash":"79b4ccc5c45b7d0d855ed1255db878fc316439f6","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/7.png","hash":"801188575a43eed2f37dfed8cd49011956292516","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/8.png","hash":"e32f84908c3fcdd4fbf9029be3c080411863bb6a","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/c1andc2.png","hash":"fbf7c11e82c5393c33bc5da9cd4ff7e3ffd14370","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/c2.png","hash":"48402638bab14d3a91d79b177549caca4dde6009","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/d0.png","hash":"086f15a55a19b7ddfbefdbd7b56d4f0232764681","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/d1.png","hash":"5ba4dafae1f08262b40e7a0d8deeb53a36d5689a","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/d2.png","hash":"1ee7f5aa0282ff5871238a222c6f1d3bd9bd6206","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/g0.png","hash":"cf791141f7f79ae0d82bac5855a7dfaa1f3eeffa","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/g1.png","hash":"4d0fb504d0b8096ce785bbd2dd8c1ef85ca873a4","modified":1517643691732},{"_id":"public/2017/09/15/2017-9-15-one/g2.png","hash":"9653978561fd5f4cb32b46094f9cb44afe456896","modified":1517643691732},{"_id":"public/css/font/fontawesome-webfont.ttf","hash":"a9468f6a1fe965fbcaf5a1bd6c11705e2fc5f84c","modified":1517643692048},{"_id":"public/css/font/fontawesome-webfont.svg","hash":"ff51bbb11dfe58345f41cead2c425d6e8be28176","modified":1517643692048},{"_id":"public/2017/06/21/2017-6-21-one/1.JPG","hash":"baee12e8d97b2f92f65537308e76b9b538bca796","modified":1517643692048},{"_id":"public/2017/06/28/2017-6-28-two/1.png","hash":"00b8f3041d68287270de25b560c0b08b7fd1c1a9","modified":1517643692048},{"_id":"public/2017/08/12/2017-8-12-one/1.png","hash":"434ae3e7eddbe334f6498add28125e2759946a65","modified":1517643692048},{"_id":"public/2017/07/08/2017-7-8-one/4.png","hash":"434ae3e7eddbe334f6498add28125e2759946a65","modified":1517643692048},{"_id":"public/2017/06/28/2017-6-28-one/4.png","hash":"dadb1d99824d11f20281fd6654916e0a1a95d360","modified":1517643692048},{"_id":"public/2017/06/27/2017-6-27-one/1.PNG","hash":"fac5831bbd063d2ac750f430cac5f51107d2d17b","modified":1517643692048},{"_id":"public/css/style.css","hash":"6022835ab3446328291ab8679694d5633d54807a","modified":1517643692048},{"_id":"public/fancybox/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1517643692048},{"_id":"public/js/gallery.js","hash":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed","modified":1517643692048},{"_id":"public/js/jquery.imagesloaded.min.js","hash":"4109837b1f6477bacc6b095a863b1b95b1b3693f","modified":1517643692048},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1517643692048},{"_id":"public/css/images/body.jpg","hash":"0e4ff7537e8d9cf759adda77ca03a11bdf133679","modified":1517643692048},{"_id":"public/css/images/body2.jpg","hash":"eeecad49947335286ed22fdf942fa99da32b41ca","modified":1517643692048},{"_id":"public/2017/11/10/2017-11-10-one/1.png","hash":"f0f0cf049cd43a95dd076e12c5b3acc572ba3374","modified":1517643692048},{"_id":"public/2018/02/03/2018-02-03-one/1.jpg","hash":"a7e0f350ce016ca6887e4425d919ea5157628cb1","modified":1517644648742},{"_id":"public/2017/06/28/2017-6-28-two/2.png","hash":"5f6c2e107d309cd28e3b4c1ba3415f63f7167f30","modified":1517643692048},{"_id":"public/2017/06/28/2017-6-28-one/5.png","hash":"e46959d09816d0e6a77f2f7376ddc93e70022562","modified":1517643692048},{"_id":"public/2017/06/14/flower/flower5.jpg","hash":"3f3fd2aa15d8cf55140a76ec9eee739d0ab9ec0e","modified":1517643692048},{"_id":"public/2017/06/30/2017-6-30-one/6.png","hash":"c294fd80cd53ca8a1be62bb760555bb3dd95e26e","modified":1517643692079},{"_id":"public/2017/06/14/flower/flower4.jpg","hash":"dc9808a905db7006032340d23f1ecb99adab84cf","modified":1517643692079},{"_id":"public/2017/06/14/flower/flower6.jpg","hash":"1610eeb598f124f0be5c878641188a37c06c6f26","modified":1517643692079},{"_id":"public/2017/06/30/2017-6-30-one/7.png","hash":"8997ce4e05c3324d4386255c169e23bd94b82e5c","modified":1517643692087},{"_id":"public/2017/06/14/flower/flower1.jpg","hash":"9b7552839d3fb89f43ce989c16c245a99ea7f57b","modified":1517643692130},{"_id":"public/2017/06/14/flower/flower3.jpg","hash":"fafbe510e0b77fd17fae5c9756b06b0aa182ec55","modified":1517643692130},{"_id":"public/2017/06/14/flower/flower2.jpg","hash":"4038e2a69621b0c76db8d57e9f3ccdf2ca44be7e","modified":1517643692146}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"Python学习笔记（五）","date":"2017-06-26T13:21:13.000Z","comments":1,"reward":true,"_content":"1. if 语句 \nif condition:\n     do something\nelif other_condition:\n     do something\n2. for 语句\n<!-- more -->\n``` bash\n# #if statement example\n# \n# number = 59\n# guess = int(input('Enter an integer : '))\n# \n# if guess == number:\n#     # New block starts here\n#     print('Bingo! you guessed it right.')\n#     print('(but you do not win any prizes!)')\n#     # New block ends here\n# elif guess < number:\n#     # Another block\n#     print('No, the number is higher than that')\n#     # You can do whatever you want in a block ...\n# else:\n#     print('No, the number is a  lower than that')\n#     # you must have guessed > number to reach here\n# \n# print('Done')\n# # This last statement is always executed,\n# # after the if statement is executed.\n#the for loop example\n# for i in range(1, 10):\n#     print(i)\n# else:\n#     print('The for loop is over')\n#     \n#     \n# a_list = [1, 3, 5, 7, 9]\n# for i in a_list:\n#     print(i)\n# \n# a_tuple = (1, 3, 5, 7, 9)\n# for i in a_tuple:\n#     print(i)\n#     \n# a_dict = {'Tom':'111', 'Jerry':'222', 'Cathy':'333'}\n# for ele in a_dict:\n#     print(ele)\n#     print(a_dict[ele])\n#     \n# for key, elem in a_dict.items():\n#     print(key, elem)\n```\n3. while语句 \n4. range语句\n``` bash\n#while example\n# number = 59\n# guess_flag = False\n# \n#  \n# while guess_flag == False:\n#     guess = int(input('Enter an integer : '))\n#     if guess == number:\n#         # New block starts here\n#         guess_flag = True\n# \n#         # New block ends here\n#     elif guess < number:\n#         # Another block\n#         print('No, the number is higher than that, keep guessing')\n#         # You can do whatever you want in a block ...\n#     else:\n#         print('No, the number is a  lower than that, keep guessing')\n#         # you must have guessed > number to reach here\n# \n# print('Bingo! you guessed it right.')\n# print('(but you do not win any prizes!)') \n# print('Done')\n#For example \nnumber = 59\nnum_chances = 3\nprint(\"you have only 3 chances to guess\")\nfor i in range(1, num_chances + 1):\n    print(\"chance \" + str(i))\n    guess = int(input('Enter an integer : '))\n    if guess == number:\n        # New block starts here\n        print('Bingo! you guessed it right.')\n        print('(but you do not win any prizes!)') \n        break\n        # New block ends here\n    elif guess < number:\n        # Another block\n        print('No, the number is higher than that, keep guessing, you have ' + str(num_chances - i) + ' chances left')\n        # You can do whatever you want in a block ...\n    else:\n        print('No, the number is lower than that, keep guessing, you have ' + str(num_chances - i) + ' chances left')\n        # you must have guessed > number to reach here\nprint('Done')\n```\n5. break \n6. continue\n7. pass\n``` bash\n#break & continue example\n# number = 59\n#  \n# while True:\n#     guess = int(input('Enter an integer : '))\n#     if guess == number:\n#         # New block starts here\n#         break\n#  \n#         # New block ends here\n#     if guess < number:\n#         # Another block\n#         print('No, the number is higher than that, keep guessing')\n#         continue\n#         # You can do whatever you want in a block ...\n#     else:\n#         print('No, the number is a  lower than that, keep guessing')\n#         continue\n#         # you must have guessed > number to reach here\n#  \n# print('Bingo! you guessed it right.')\n# print('(but you do not win any prizes!)') \n# print('Done')\n#continue and pass difference\n# a_list = [0, 1, 2]\n# \n# print(\"using continue:\")\n# for i in a_list:\n#     if not i:\n#         continue\n#     print(i)\n#     \n# print(\"using pass:\")    \n# for i in a_list:\n#     if not i:\n#         pass\n#     print(i) \n```","source":"_posts/2016-6-26-one.md","raw":"---\ntitle: Python学习笔记（五）\ndate: 2017-06-26 21:21:13\ncomments: true\nreward: true\ntags: \n - python\n---\n1. if 语句 \nif condition:\n     do something\nelif other_condition:\n     do something\n2. for 语句\n<!-- more -->\n``` bash\n# #if statement example\n# \n# number = 59\n# guess = int(input('Enter an integer : '))\n# \n# if guess == number:\n#     # New block starts here\n#     print('Bingo! you guessed it right.')\n#     print('(but you do not win any prizes!)')\n#     # New block ends here\n# elif guess < number:\n#     # Another block\n#     print('No, the number is higher than that')\n#     # You can do whatever you want in a block ...\n# else:\n#     print('No, the number is a  lower than that')\n#     # you must have guessed > number to reach here\n# \n# print('Done')\n# # This last statement is always executed,\n# # after the if statement is executed.\n#the for loop example\n# for i in range(1, 10):\n#     print(i)\n# else:\n#     print('The for loop is over')\n#     \n#     \n# a_list = [1, 3, 5, 7, 9]\n# for i in a_list:\n#     print(i)\n# \n# a_tuple = (1, 3, 5, 7, 9)\n# for i in a_tuple:\n#     print(i)\n#     \n# a_dict = {'Tom':'111', 'Jerry':'222', 'Cathy':'333'}\n# for ele in a_dict:\n#     print(ele)\n#     print(a_dict[ele])\n#     \n# for key, elem in a_dict.items():\n#     print(key, elem)\n```\n3. while语句 \n4. range语句\n``` bash\n#while example\n# number = 59\n# guess_flag = False\n# \n#  \n# while guess_flag == False:\n#     guess = int(input('Enter an integer : '))\n#     if guess == number:\n#         # New block starts here\n#         guess_flag = True\n# \n#         # New block ends here\n#     elif guess < number:\n#         # Another block\n#         print('No, the number is higher than that, keep guessing')\n#         # You can do whatever you want in a block ...\n#     else:\n#         print('No, the number is a  lower than that, keep guessing')\n#         # you must have guessed > number to reach here\n# \n# print('Bingo! you guessed it right.')\n# print('(but you do not win any prizes!)') \n# print('Done')\n#For example \nnumber = 59\nnum_chances = 3\nprint(\"you have only 3 chances to guess\")\nfor i in range(1, num_chances + 1):\n    print(\"chance \" + str(i))\n    guess = int(input('Enter an integer : '))\n    if guess == number:\n        # New block starts here\n        print('Bingo! you guessed it right.')\n        print('(but you do not win any prizes!)') \n        break\n        # New block ends here\n    elif guess < number:\n        # Another block\n        print('No, the number is higher than that, keep guessing, you have ' + str(num_chances - i) + ' chances left')\n        # You can do whatever you want in a block ...\n    else:\n        print('No, the number is lower than that, keep guessing, you have ' + str(num_chances - i) + ' chances left')\n        # you must have guessed > number to reach here\nprint('Done')\n```\n5. break \n6. continue\n7. pass\n``` bash\n#break & continue example\n# number = 59\n#  \n# while True:\n#     guess = int(input('Enter an integer : '))\n#     if guess == number:\n#         # New block starts here\n#         break\n#  \n#         # New block ends here\n#     if guess < number:\n#         # Another block\n#         print('No, the number is higher than that, keep guessing')\n#         continue\n#         # You can do whatever you want in a block ...\n#     else:\n#         print('No, the number is a  lower than that, keep guessing')\n#         continue\n#         # you must have guessed > number to reach here\n#  \n# print('Bingo! you guessed it right.')\n# print('(but you do not win any prizes!)') \n# print('Done')\n#continue and pass difference\n# a_list = [0, 1, 2]\n# \n# print(\"using continue:\")\n# for i in a_list:\n#     if not i:\n#         continue\n#     print(i)\n#     \n# print(\"using pass:\")    \n# for i in a_list:\n#     if not i:\n#         pass\n#     print(i) \n```","slug":"2016-6-26-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va1c0000ycvjlsuel1e4","content":"<ol>\n<li>if 语句<br>if condition:<br>  do something<br>elif other_condition:<br>  do something</li>\n<li><p>for 语句</p>\n<a id=\"more\"></a>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># #if statement example</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># number = 59</span></span><br><span class=\"line\"><span class=\"comment\"># guess = int(input('Enter an integer : '))</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># if guess == number:</span></span><br><span class=\"line\"><span class=\"comment\">#     # New block starts here</span></span><br><span class=\"line\"><span class=\"comment\">#     print('Bingo! you guessed it right.')</span></span><br><span class=\"line\"><span class=\"comment\">#     print('(but you do not win any prizes!)')</span></span><br><span class=\"line\"><span class=\"comment\">#     # New block ends here</span></span><br><span class=\"line\"><span class=\"comment\"># elif guess &lt; number:</span></span><br><span class=\"line\"><span class=\"comment\">#     # Another block</span></span><br><span class=\"line\"><span class=\"comment\">#     print('No, the number is higher than that')</span></span><br><span class=\"line\"><span class=\"comment\">#     # You can do whatever you want in a block ...</span></span><br><span class=\"line\"><span class=\"comment\"># else:</span></span><br><span class=\"line\"><span class=\"comment\">#     print('No, the number is a  lower than that')</span></span><br><span class=\"line\"><span class=\"comment\">#     # you must have guessed &gt; number to reach here</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># print('Done')</span></span><br><span class=\"line\"><span class=\"comment\"># # This last statement is always executed,</span></span><br><span class=\"line\"><span class=\"comment\"># # after the if statement is executed.</span></span><br><span class=\"line\"><span class=\"comment\">#the for loop example</span></span><br><span class=\"line\"><span class=\"comment\"># for i in range(1, 10):</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br><span class=\"line\"><span class=\"comment\"># else:</span></span><br><span class=\"line\"><span class=\"comment\">#     print('The for loop is over')</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># a_list = [1, 3, 5, 7, 9]</span></span><br><span class=\"line\"><span class=\"comment\"># for i in a_list:</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># a_tuple = (1, 3, 5, 7, 9)</span></span><br><span class=\"line\"><span class=\"comment\"># for i in a_tuple:</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># a_dict = &#123;'Tom':'111', 'Jerry':'222', 'Cathy':'333'&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># for ele in a_dict:</span></span><br><span class=\"line\"><span class=\"comment\">#     print(ele)</span></span><br><span class=\"line\"><span class=\"comment\">#     print(a_dict[ele])</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># for key, elem in a_dict.items():</span></span><br><span class=\"line\"><span class=\"comment\">#     print(key, elem)</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>while语句 </p>\n</li>\n<li><p>range语句</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#while example</span></span><br><span class=\"line\"><span class=\"comment\"># number = 59</span></span><br><span class=\"line\"><span class=\"comment\"># guess_flag = False</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># while guess_flag == False:</span></span><br><span class=\"line\"><span class=\"comment\">#     guess = int(input('Enter an integer : '))</span></span><br><span class=\"line\"><span class=\"comment\">#     if guess == number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # New block starts here</span></span><br><span class=\"line\"><span class=\"comment\">#         guess_flag = True</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#         # New block ends here</span></span><br><span class=\"line\"><span class=\"comment\">#     elif guess &lt; number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # Another block</span></span><br><span class=\"line\"><span class=\"comment\">#         print('No, the number is higher than that, keep guessing')</span></span><br><span class=\"line\"><span class=\"comment\">#         # You can do whatever you want in a block ...</span></span><br><span class=\"line\"><span class=\"comment\">#     else:</span></span><br><span class=\"line\"><span class=\"comment\">#         print('No, the number is a  lower than that, keep guessing')</span></span><br><span class=\"line\"><span class=\"comment\">#         # you must have guessed &gt; number to reach here</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># print('Bingo! you guessed it right.')</span></span><br><span class=\"line\"><span class=\"comment\"># print('(but you do not win any prizes!)') </span></span><br><span class=\"line\"><span class=\"comment\"># print('Done')</span></span><br><span class=\"line\"><span class=\"comment\">#For example </span></span><br><span class=\"line\">number = 59</span><br><span class=\"line\">num_chances = 3</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"you have only 3 chances to guess\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1, num_chances + 1):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"chance \"</span> + str(i))</span><br><span class=\"line\">    guess = int(input(<span class=\"string\">'Enter an integer : '</span>))</span><br><span class=\"line\">    <span class=\"keyword\">if</span> guess == number:</span><br><span class=\"line\">        <span class=\"comment\"># New block starts here</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'Bingo! you guessed it right.'</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'(but you do not win any prizes!)'</span>) </span><br><span class=\"line\">        <span class=\"built_in\">break</span></span><br><span class=\"line\">        <span class=\"comment\"># New block ends here</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> guess &lt; number:</span><br><span class=\"line\">        <span class=\"comment\"># Another block</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'No, the number is higher than that, keep guessing, you have '</span> + str(num_chances - i) + <span class=\"string\">' chances left'</span>)</span><br><span class=\"line\">        <span class=\"comment\"># You can do whatever you want in a block ...</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'No, the number is lower than that, keep guessing, you have '</span> + str(num_chances - i) + <span class=\"string\">' chances left'</span>)</span><br><span class=\"line\">        <span class=\"comment\"># you must have guessed &gt; number to reach here</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Done'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>break </p>\n</li>\n<li>continue</li>\n<li>pass<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#break &amp; continue example</span></span><br><span class=\"line\"><span class=\"comment\"># number = 59</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># while True:</span></span><br><span class=\"line\"><span class=\"comment\">#     guess = int(input('Enter an integer : '))</span></span><br><span class=\"line\"><span class=\"comment\">#     if guess == number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # New block starts here</span></span><br><span class=\"line\"><span class=\"comment\">#         break</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\">#         # New block ends here</span></span><br><span class=\"line\"><span class=\"comment\">#     if guess &lt; number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # Another block</span></span><br><span class=\"line\"><span class=\"comment\">#         print('No, the number is higher than that, keep guessing')</span></span><br><span class=\"line\"><span class=\"comment\">#         continue</span></span><br><span class=\"line\"><span class=\"comment\">#         # You can do whatever you want in a block ...</span></span><br><span class=\"line\"><span class=\"comment\">#     else:</span></span><br><span class=\"line\"><span class=\"comment\">#         print('No, the number is a  lower than that, keep guessing')</span></span><br><span class=\"line\"><span class=\"comment\">#         continue</span></span><br><span class=\"line\"><span class=\"comment\">#         # you must have guessed &gt; number to reach here</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># print('Bingo! you guessed it right.')</span></span><br><span class=\"line\"><span class=\"comment\"># print('(but you do not win any prizes!)') </span></span><br><span class=\"line\"><span class=\"comment\"># print('Done')</span></span><br><span class=\"line\"><span class=\"comment\">#continue and pass difference</span></span><br><span class=\"line\"><span class=\"comment\"># a_list = [0, 1, 2]</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># print(\"using continue:\")</span></span><br><span class=\"line\"><span class=\"comment\"># for i in a_list:</span></span><br><span class=\"line\"><span class=\"comment\">#     if not i:</span></span><br><span class=\"line\"><span class=\"comment\">#         continue</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># print(\"using pass:\")    </span></span><br><span class=\"line\"><span class=\"comment\"># for i in a_list:</span></span><br><span class=\"line\"><span class=\"comment\">#     if not i:</span></span><br><span class=\"line\"><span class=\"comment\">#         pass</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br></pre></td></tr></table></figure></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>if 语句<br>if condition:<br>  do something<br>elif other_condition:<br>  do something</li>\n<li><p>for 语句</p></li></ol>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># #if statement example</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># number = 59</span></span><br><span class=\"line\"><span class=\"comment\"># guess = int(input('Enter an integer : '))</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># if guess == number:</span></span><br><span class=\"line\"><span class=\"comment\">#     # New block starts here</span></span><br><span class=\"line\"><span class=\"comment\">#     print('Bingo! you guessed it right.')</span></span><br><span class=\"line\"><span class=\"comment\">#     print('(but you do not win any prizes!)')</span></span><br><span class=\"line\"><span class=\"comment\">#     # New block ends here</span></span><br><span class=\"line\"><span class=\"comment\"># elif guess &lt; number:</span></span><br><span class=\"line\"><span class=\"comment\">#     # Another block</span></span><br><span class=\"line\"><span class=\"comment\">#     print('No, the number is higher than that')</span></span><br><span class=\"line\"><span class=\"comment\">#     # You can do whatever you want in a block ...</span></span><br><span class=\"line\"><span class=\"comment\"># else:</span></span><br><span class=\"line\"><span class=\"comment\">#     print('No, the number is a  lower than that')</span></span><br><span class=\"line\"><span class=\"comment\">#     # you must have guessed &gt; number to reach here</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># print('Done')</span></span><br><span class=\"line\"><span class=\"comment\"># # This last statement is always executed,</span></span><br><span class=\"line\"><span class=\"comment\"># # after the if statement is executed.</span></span><br><span class=\"line\"><span class=\"comment\">#the for loop example</span></span><br><span class=\"line\"><span class=\"comment\"># for i in range(1, 10):</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br><span class=\"line\"><span class=\"comment\"># else:</span></span><br><span class=\"line\"><span class=\"comment\">#     print('The for loop is over')</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># a_list = [1, 3, 5, 7, 9]</span></span><br><span class=\"line\"><span class=\"comment\"># for i in a_list:</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># a_tuple = (1, 3, 5, 7, 9)</span></span><br><span class=\"line\"><span class=\"comment\"># for i in a_tuple:</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># a_dict = &#123;'Tom':'111', 'Jerry':'222', 'Cathy':'333'&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># for ele in a_dict:</span></span><br><span class=\"line\"><span class=\"comment\">#     print(ele)</span></span><br><span class=\"line\"><span class=\"comment\">#     print(a_dict[ele])</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># for key, elem in a_dict.items():</span></span><br><span class=\"line\"><span class=\"comment\">#     print(key, elem)</span></span><br></pre></td></tr></table></figure>\n\n<li><p>while语句 </p>\n</li>\n<li><p>range语句</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#while example</span></span><br><span class=\"line\"><span class=\"comment\"># number = 59</span></span><br><span class=\"line\"><span class=\"comment\"># guess_flag = False</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># while guess_flag == False:</span></span><br><span class=\"line\"><span class=\"comment\">#     guess = int(input('Enter an integer : '))</span></span><br><span class=\"line\"><span class=\"comment\">#     if guess == number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # New block starts here</span></span><br><span class=\"line\"><span class=\"comment\">#         guess_flag = True</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#         # New block ends here</span></span><br><span class=\"line\"><span class=\"comment\">#     elif guess &lt; number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # Another block</span></span><br><span class=\"line\"><span class=\"comment\">#         print('No, the number is higher than that, keep guessing')</span></span><br><span class=\"line\"><span class=\"comment\">#         # You can do whatever you want in a block ...</span></span><br><span class=\"line\"><span class=\"comment\">#     else:</span></span><br><span class=\"line\"><span class=\"comment\">#         print('No, the number is a  lower than that, keep guessing')</span></span><br><span class=\"line\"><span class=\"comment\">#         # you must have guessed &gt; number to reach here</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># print('Bingo! you guessed it right.')</span></span><br><span class=\"line\"><span class=\"comment\"># print('(but you do not win any prizes!)') </span></span><br><span class=\"line\"><span class=\"comment\"># print('Done')</span></span><br><span class=\"line\"><span class=\"comment\">#For example </span></span><br><span class=\"line\">number = 59</span><br><span class=\"line\">num_chances = 3</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"you have only 3 chances to guess\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1, num_chances + 1):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"chance \"</span> + str(i))</span><br><span class=\"line\">    guess = int(input(<span class=\"string\">'Enter an integer : '</span>))</span><br><span class=\"line\">    <span class=\"keyword\">if</span> guess == number:</span><br><span class=\"line\">        <span class=\"comment\"># New block starts here</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'Bingo! you guessed it right.'</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'(but you do not win any prizes!)'</span>) </span><br><span class=\"line\">        <span class=\"built_in\">break</span></span><br><span class=\"line\">        <span class=\"comment\"># New block ends here</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> guess &lt; number:</span><br><span class=\"line\">        <span class=\"comment\"># Another block</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'No, the number is higher than that, keep guessing, you have '</span> + str(num_chances - i) + <span class=\"string\">' chances left'</span>)</span><br><span class=\"line\">        <span class=\"comment\"># You can do whatever you want in a block ...</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'No, the number is lower than that, keep guessing, you have '</span> + str(num_chances - i) + <span class=\"string\">' chances left'</span>)</span><br><span class=\"line\">        <span class=\"comment\"># you must have guessed &gt; number to reach here</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Done'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>break </p>\n</li>\n<li>continue</li>\n<li>pass<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#break &amp; continue example</span></span><br><span class=\"line\"><span class=\"comment\"># number = 59</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># while True:</span></span><br><span class=\"line\"><span class=\"comment\">#     guess = int(input('Enter an integer : '))</span></span><br><span class=\"line\"><span class=\"comment\">#     if guess == number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # New block starts here</span></span><br><span class=\"line\"><span class=\"comment\">#         break</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\">#         # New block ends here</span></span><br><span class=\"line\"><span class=\"comment\">#     if guess &lt; number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # Another block</span></span><br><span class=\"line\"><span class=\"comment\">#         print('No, the number is higher than that, keep guessing')</span></span><br><span class=\"line\"><span class=\"comment\">#         continue</span></span><br><span class=\"line\"><span class=\"comment\">#         # You can do whatever you want in a block ...</span></span><br><span class=\"line\"><span class=\"comment\">#     else:</span></span><br><span class=\"line\"><span class=\"comment\">#         print('No, the number is a  lower than that, keep guessing')</span></span><br><span class=\"line\"><span class=\"comment\">#         continue</span></span><br><span class=\"line\"><span class=\"comment\">#         # you must have guessed &gt; number to reach here</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># print('Bingo! you guessed it right.')</span></span><br><span class=\"line\"><span class=\"comment\"># print('(but you do not win any prizes!)') </span></span><br><span class=\"line\"><span class=\"comment\"># print('Done')</span></span><br><span class=\"line\"><span class=\"comment\">#continue and pass difference</span></span><br><span class=\"line\"><span class=\"comment\"># a_list = [0, 1, 2]</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># print(\"using continue:\")</span></span><br><span class=\"line\"><span class=\"comment\"># for i in a_list:</span></span><br><span class=\"line\"><span class=\"comment\">#     if not i:</span></span><br><span class=\"line\"><span class=\"comment\">#         continue</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># print(\"using pass:\")    </span></span><br><span class=\"line\"><span class=\"comment\"># for i in a_list:</span></span><br><span class=\"line\"><span class=\"comment\">#     if not i:</span></span><br><span class=\"line\"><span class=\"comment\">#         pass</span></span><br><span class=\"line\"><span class=\"comment\">#     print(i)</span></span><br></pre></td></tr></table></figure></li>\n"},{"title":"LATEX学习笔记","date":"2017-06-15T02:59:38.000Z","reward":true,"comments":1,"_content":"首先给上一篇自己写的小短文各项内容基本都有\n``` bash\n\\documentclass[UTF-8]{ctexart}\n\\usepackage{graphicx}\n\\usepackage{float}\n\\title {杂谈勾股定理}\n\\author{张三}\n\\date{\\today}\n\\bibliographystyle{plain}\n```\n<!-- more -->\n``` bash\n\\begin{document}\n\\maketitle\n\\begin{abstract}\n这是一篇关于勾股定理的小短文。\n\\end{abstract}\n\\tableofcontents\n\\newtheorem{thm}{定理}\n\\section{勾股定理在古代}\n西方称勾股定理为毕达哥拉斯定理，将勾股定理的发现归功于公元前 6 世纪的\n毕达哥拉斯学派。该学派得到了一个法则，可以求出可排成直角三角形三边的三\n元数组。毕达哥拉斯学派没有书面著作，该定理的严格表述和证明则见于欧几里\n德\\footnote{欧几里德,约公元前330--225年。}《几何原本》的命题 47：“直角三角形斜边上的正方形等于丙直角边上的两\n个正方形之和。”证明是用\\emph{面积}做的。\n我国《周神算经》栽商高(约公元前 12 世圮)答周公问:\n\\begin{quote}\n    \\zihao{-5}\\kaishu 勾三股四弦定五。\n\\end{quote}\n\\begin{table}[h]\n    \\centering\n    \\begin{tabular}{rrr}\n    \\hline\n    直角边$a$ & 直角边$b$ & 直角边$c$\\\\\n    \\hline\n    3 & 4 & 5 \\\\\n    5 & 12 & 13\\\\\n    \\hline\n    \\end{tabular}\n\\qquad\n$a^2+b^2=c^2$\n\\end{table}\n图\\ref{fig:xiantu}是我国古代对勾股定理的一种证明。\n\\begin{figure}[ht]\n    \\centering\n    \\includegraphics[scale=0.6]{11.png}\n    \\caption {宋赵爽在《周神算经》注中作的弦图(仿制)，该图给出了勾股定理的一个极具对称美的证明。}\n    \\lable{fig:xiantu}\n\\end{figure}\n\n\\begin{thm}[勾股定理]\n    直角三角形的平方等于两腰的平方和。\n    可以用符号语言表述为:设直角三角形$ABC$,其中$\\angle C=90^\\circ$,则有\n    \\begin{equation}\n        AB^2=BC^2+AC^2\n    \\end{equation}\n\\end{thm}\n\\section{勾股定理的近代形式}\n\\bibliography{math}\n\\end{document}\n```\n左对齐命令\n``` bash\n{\\raggedright\n内容\n}\n```\n花括号\n``` bash\n\\begin{eqnarray}\nx'_{sj}(k)=\n\\begin{cases}\n-1&\\text{$u'_{sj}(k)<-1$}\\\\\nu'_{sj}(k)&\\text{$-1\\le u'_{sj}(k)\\le 1$}\\\\\n1&\\text{$u'_{sj}(k)>1$}\n\\end{cases}\n\\end{eqnarray}\n```\n图片插入\n.eps图片: 将word图片转为pdf ,再由pdf 转为ps的eps格式然后输入代码\n``` bash\n\\begin{center}\n\\includegraphics [scale=0.8,trim=0 0 0 0]{2.eps}\\\\\n\\label{Fig2}\n{\\fontsize{9.3pt}{11.6pt}\\selectfont 图~2~~水下航行器垂直面受力示意图\\\\\nFig.~2~~Schematic diagram of force in vertical plane of underwater vehicle}\n\\end{center}\n```\n截断命令\n在文章中加入以下命令将文章截断显示在主页\n``` bash\n<!-- more -->\n```\n\n\n","source":"_posts/2017-6-15-one.md","raw":"---\ntitle: LATEX学习笔记\ndate: 2017-06-15 10:59:38\ntags:\n\t- LATEX\nreward: true\ncomments: true\n---\n首先给上一篇自己写的小短文各项内容基本都有\n``` bash\n\\documentclass[UTF-8]{ctexart}\n\\usepackage{graphicx}\n\\usepackage{float}\n\\title {杂谈勾股定理}\n\\author{张三}\n\\date{\\today}\n\\bibliographystyle{plain}\n```\n<!-- more -->\n``` bash\n\\begin{document}\n\\maketitle\n\\begin{abstract}\n这是一篇关于勾股定理的小短文。\n\\end{abstract}\n\\tableofcontents\n\\newtheorem{thm}{定理}\n\\section{勾股定理在古代}\n西方称勾股定理为毕达哥拉斯定理，将勾股定理的发现归功于公元前 6 世纪的\n毕达哥拉斯学派。该学派得到了一个法则，可以求出可排成直角三角形三边的三\n元数组。毕达哥拉斯学派没有书面著作，该定理的严格表述和证明则见于欧几里\n德\\footnote{欧几里德,约公元前330--225年。}《几何原本》的命题 47：“直角三角形斜边上的正方形等于丙直角边上的两\n个正方形之和。”证明是用\\emph{面积}做的。\n我国《周神算经》栽商高(约公元前 12 世圮)答周公问:\n\\begin{quote}\n    \\zihao{-5}\\kaishu 勾三股四弦定五。\n\\end{quote}\n\\begin{table}[h]\n    \\centering\n    \\begin{tabular}{rrr}\n    \\hline\n    直角边$a$ & 直角边$b$ & 直角边$c$\\\\\n    \\hline\n    3 & 4 & 5 \\\\\n    5 & 12 & 13\\\\\n    \\hline\n    \\end{tabular}\n\\qquad\n$a^2+b^2=c^2$\n\\end{table}\n图\\ref{fig:xiantu}是我国古代对勾股定理的一种证明。\n\\begin{figure}[ht]\n    \\centering\n    \\includegraphics[scale=0.6]{11.png}\n    \\caption {宋赵爽在《周神算经》注中作的弦图(仿制)，该图给出了勾股定理的一个极具对称美的证明。}\n    \\lable{fig:xiantu}\n\\end{figure}\n\n\\begin{thm}[勾股定理]\n    直角三角形的平方等于两腰的平方和。\n    可以用符号语言表述为:设直角三角形$ABC$,其中$\\angle C=90^\\circ$,则有\n    \\begin{equation}\n        AB^2=BC^2+AC^2\n    \\end{equation}\n\\end{thm}\n\\section{勾股定理的近代形式}\n\\bibliography{math}\n\\end{document}\n```\n左对齐命令\n``` bash\n{\\raggedright\n内容\n}\n```\n花括号\n``` bash\n\\begin{eqnarray}\nx'_{sj}(k)=\n\\begin{cases}\n-1&\\text{$u'_{sj}(k)<-1$}\\\\\nu'_{sj}(k)&\\text{$-1\\le u'_{sj}(k)\\le 1$}\\\\\n1&\\text{$u'_{sj}(k)>1$}\n\\end{cases}\n\\end{eqnarray}\n```\n图片插入\n.eps图片: 将word图片转为pdf ,再由pdf 转为ps的eps格式然后输入代码\n``` bash\n\\begin{center}\n\\includegraphics [scale=0.8,trim=0 0 0 0]{2.eps}\\\\\n\\label{Fig2}\n{\\fontsize{9.3pt}{11.6pt}\\selectfont 图~2~~水下航行器垂直面受力示意图\\\\\nFig.~2~~Schematic diagram of force in vertical plane of underwater vehicle}\n\\end{center}\n```\n截断命令\n在文章中加入以下命令将文章截断显示在主页\n``` bash\n<!-- more -->\n```\n\n\n","slug":"2017-6-15-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va1u0001ycvjo7s3chx6","content":"<p>首先给上一篇自己写的小短文各项内容基本都有<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\documentclass[UTF-8]&#123;ctexart&#125;</span><br><span class=\"line\">\\usepackage&#123;graphicx&#125;</span><br><span class=\"line\">\\usepackage&#123;<span class=\"built_in\">float</span>&#125;</span><br><span class=\"line\">\\title &#123;杂谈勾股定理&#125;</span><br><span class=\"line\">\\author&#123;张三&#125;</span><br><span class=\"line\">\\date&#123;\\today&#125;</span><br><span class=\"line\">\\bibliographystyle&#123;plain&#125;</span><br></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\begin&#123;document&#125;</span><br><span class=\"line\">\\maketitle</span><br><span class=\"line\">\\begin&#123;abstract&#125;</span><br><span class=\"line\">这是一篇关于勾股定理的小短文。</span><br><span class=\"line\">\\end&#123;abstract&#125;</span><br><span class=\"line\">\\tableofcontents</span><br><span class=\"line\">\\newtheorem&#123;thm&#125;&#123;定理&#125;</span><br><span class=\"line\">\\section&#123;勾股定理在古代&#125;</span><br><span class=\"line\">西方称勾股定理为毕达哥拉斯定理，将勾股定理的发现归功于公元前 6 世纪的</span><br><span class=\"line\">毕达哥拉斯学派。该学派得到了一个法则，可以求出可排成直角三角形三边的三</span><br><span class=\"line\">元数组。毕达哥拉斯学派没有书面著作，该定理的严格表述和证明则见于欧几里</span><br><span class=\"line\">德\\footnote&#123;欧几里德,约公元前330--225年。&#125;《几何原本》的命题 47：“直角三角形斜边上的正方形等于丙直角边上的两</span><br><span class=\"line\">个正方形之和。”证明是用\\emph&#123;面积&#125;做的。</span><br><span class=\"line\">我国《周神算经》栽商高(约公元前 12 世圮)答周公问:</span><br><span class=\"line\">\\begin&#123;quote&#125;</span><br><span class=\"line\">    \\zihao&#123;-5&#125;\\kaishu 勾三股四弦定五。</span><br><span class=\"line\">\\end&#123;quote&#125;</span><br><span class=\"line\">\\begin&#123;table&#125;[h]</span><br><span class=\"line\">    \\centering</span><br><span class=\"line\">    \\begin&#123;tabular&#125;&#123;rrr&#125;</span><br><span class=\"line\">    \\hline</span><br><span class=\"line\">    直角边<span class=\"variable\">$a</span>$ &amp; 直角边<span class=\"variable\">$b</span>$ &amp; 直角边<span class=\"variable\">$c</span>$\\\\</span><br><span class=\"line\">    \\hline</span><br><span class=\"line\">    3 &amp; 4 &amp; 5 \\\\</span><br><span class=\"line\">    5 &amp; 12 &amp; 13\\\\</span><br><span class=\"line\">    \\hline</span><br><span class=\"line\">    \\end&#123;tabular&#125;</span><br><span class=\"line\">\\qquad</span><br><span class=\"line\"><span class=\"variable\">$a</span>^2+b^2=c^2$</span><br><span class=\"line\">\\end&#123;table&#125;</span><br><span class=\"line\">图\\ref&#123;fig:xiantu&#125;是我国古代对勾股定理的一种证明。</span><br><span class=\"line\">\\begin&#123;figure&#125;[ht]</span><br><span class=\"line\">    \\centering</span><br><span class=\"line\">    \\includegraphics[scale=0.6]&#123;11.png&#125;</span><br><span class=\"line\">    \\caption &#123;宋赵爽在《周神算经》注中作的弦图(仿制)，该图给出了勾股定理的一个极具对称美的证明。&#125;</span><br><span class=\"line\">    \\lable&#123;fig:xiantu&#125;</span><br><span class=\"line\">\\end&#123;figure&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\\begin&#123;thm&#125;[勾股定理]</span><br><span class=\"line\">    直角三角形的平方等于两腰的平方和。</span><br><span class=\"line\">    可以用符号语言表述为:设直角三角形<span class=\"variable\">$ABC</span>$,其中$\\angle C=90^\\circ$,则有</span><br><span class=\"line\">    \\begin&#123;equation&#125;</span><br><span class=\"line\">        AB^2=BC^2+AC^2</span><br><span class=\"line\">    \\end&#123;equation&#125;</span><br><span class=\"line\">\\end&#123;thm&#125;</span><br><span class=\"line\">\\section&#123;勾股定理的近代形式&#125;</span><br><span class=\"line\">\\bibliography&#123;math&#125;</span><br><span class=\"line\">\\end&#123;document&#125;</span><br></pre></td></tr></table></figure>\n<p>左对齐命令<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;\\raggedright</span><br><span class=\"line\">内容</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>花括号<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\begin&#123;eqnarray&#125;</span><br><span class=\"line\">x<span class=\"string\">'_&#123;sj&#125;(k)=</span></span><br><span class=\"line\"><span class=\"string\">\\begin&#123;cases&#125;</span></span><br><span class=\"line\"><span class=\"string\">-1&amp;\\text&#123;$u'</span>_&#123;sj&#125;(k)&lt;-1$&#125;\\\\</span><br><span class=\"line\">u<span class=\"string\">'_&#123;sj&#125;(k)&amp;\\text&#123;$-1\\le u'</span>_&#123;sj&#125;(k)\\le 1$&#125;\\\\</span><br><span class=\"line\">1&amp;\\text&#123;<span class=\"variable\">$u</span><span class=\"string\">'_&#123;sj&#125;(k)&gt;1$&#125;</span></span><br><span class=\"line\"><span class=\"string\">\\end&#123;cases&#125;</span></span><br><span class=\"line\"><span class=\"string\">\\end&#123;eqnarray&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>图片插入<br>.eps图片: 将word图片转为pdf ,再由pdf 转为ps的eps格式然后输入代码<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\begin&#123;center&#125;</span><br><span class=\"line\">\\includegraphics [scale=0.8,trim=0 0 0 0]&#123;2.eps&#125;\\\\</span><br><span class=\"line\">\\label&#123;Fig2&#125;</span><br><span class=\"line\">&#123;\\fontsize&#123;9.3pt&#125;&#123;11.6pt&#125;\\selectfont 图~2~~水下航行器垂直面受力示意图\\\\</span><br><span class=\"line\">Fig.~2~~Schematic diagram of force <span class=\"keyword\">in</span> vertical plane of underwater vehicle&#125;</span><br><span class=\"line\">\\end&#123;center&#125;</span><br></pre></td></tr></table></figure></p>\n<p>截断命令<br>在文章中加入以下命令将文章截断显示在主页<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!-- more --&gt;</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>首先给上一篇自己写的小短文各项内容基本都有<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\documentclass[UTF-8]&#123;ctexart&#125;</span><br><span class=\"line\">\\usepackage&#123;graphicx&#125;</span><br><span class=\"line\">\\usepackage&#123;<span class=\"built_in\">float</span>&#125;</span><br><span class=\"line\">\\title &#123;杂谈勾股定理&#125;</span><br><span class=\"line\">\\author&#123;张三&#125;</span><br><span class=\"line\">\\date&#123;\\today&#125;</span><br><span class=\"line\">\\bibliographystyle&#123;plain&#125;</span><br></pre></td></tr></table></figure></p>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\begin&#123;document&#125;</span><br><span class=\"line\">\\maketitle</span><br><span class=\"line\">\\begin&#123;abstract&#125;</span><br><span class=\"line\">这是一篇关于勾股定理的小短文。</span><br><span class=\"line\">\\end&#123;abstract&#125;</span><br><span class=\"line\">\\tableofcontents</span><br><span class=\"line\">\\newtheorem&#123;thm&#125;&#123;定理&#125;</span><br><span class=\"line\">\\section&#123;勾股定理在古代&#125;</span><br><span class=\"line\">西方称勾股定理为毕达哥拉斯定理，将勾股定理的发现归功于公元前 6 世纪的</span><br><span class=\"line\">毕达哥拉斯学派。该学派得到了一个法则，可以求出可排成直角三角形三边的三</span><br><span class=\"line\">元数组。毕达哥拉斯学派没有书面著作，该定理的严格表述和证明则见于欧几里</span><br><span class=\"line\">德\\footnote&#123;欧几里德,约公元前330--225年。&#125;《几何原本》的命题 47：“直角三角形斜边上的正方形等于丙直角边上的两</span><br><span class=\"line\">个正方形之和。”证明是用\\emph&#123;面积&#125;做的。</span><br><span class=\"line\">我国《周神算经》栽商高(约公元前 12 世圮)答周公问:</span><br><span class=\"line\">\\begin&#123;quote&#125;</span><br><span class=\"line\">    \\zihao&#123;-5&#125;\\kaishu 勾三股四弦定五。</span><br><span class=\"line\">\\end&#123;quote&#125;</span><br><span class=\"line\">\\begin&#123;table&#125;[h]</span><br><span class=\"line\">    \\centering</span><br><span class=\"line\">    \\begin&#123;tabular&#125;&#123;rrr&#125;</span><br><span class=\"line\">    \\hline</span><br><span class=\"line\">    直角边<span class=\"variable\">$a</span>$ &amp; 直角边<span class=\"variable\">$b</span>$ &amp; 直角边<span class=\"variable\">$c</span>$\\\\</span><br><span class=\"line\">    \\hline</span><br><span class=\"line\">    3 &amp; 4 &amp; 5 \\\\</span><br><span class=\"line\">    5 &amp; 12 &amp; 13\\\\</span><br><span class=\"line\">    \\hline</span><br><span class=\"line\">    \\end&#123;tabular&#125;</span><br><span class=\"line\">\\qquad</span><br><span class=\"line\"><span class=\"variable\">$a</span>^2+b^2=c^2$</span><br><span class=\"line\">\\end&#123;table&#125;</span><br><span class=\"line\">图\\ref&#123;fig:xiantu&#125;是我国古代对勾股定理的一种证明。</span><br><span class=\"line\">\\begin&#123;figure&#125;[ht]</span><br><span class=\"line\">    \\centering</span><br><span class=\"line\">    \\includegraphics[scale=0.6]&#123;11.png&#125;</span><br><span class=\"line\">    \\caption &#123;宋赵爽在《周神算经》注中作的弦图(仿制)，该图给出了勾股定理的一个极具对称美的证明。&#125;</span><br><span class=\"line\">    \\lable&#123;fig:xiantu&#125;</span><br><span class=\"line\">\\end&#123;figure&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\\begin&#123;thm&#125;[勾股定理]</span><br><span class=\"line\">    直角三角形的平方等于两腰的平方和。</span><br><span class=\"line\">    可以用符号语言表述为:设直角三角形<span class=\"variable\">$ABC</span>$,其中$\\angle C=90^\\circ$,则有</span><br><span class=\"line\">    \\begin&#123;equation&#125;</span><br><span class=\"line\">        AB^2=BC^2+AC^2</span><br><span class=\"line\">    \\end&#123;equation&#125;</span><br><span class=\"line\">\\end&#123;thm&#125;</span><br><span class=\"line\">\\section&#123;勾股定理的近代形式&#125;</span><br><span class=\"line\">\\bibliography&#123;math&#125;</span><br><span class=\"line\">\\end&#123;document&#125;</span><br></pre></td></tr></table></figure>\n<p>左对齐命令<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;\\raggedright</span><br><span class=\"line\">内容</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>花括号<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\begin&#123;eqnarray&#125;</span><br><span class=\"line\">x<span class=\"string\">'_&#123;sj&#125;(k)=</span></span><br><span class=\"line\"><span class=\"string\">\\begin&#123;cases&#125;</span></span><br><span class=\"line\"><span class=\"string\">-1&amp;\\text&#123;$u'</span>_&#123;sj&#125;(k)&lt;-1$&#125;\\\\</span><br><span class=\"line\">u<span class=\"string\">'_&#123;sj&#125;(k)&amp;\\text&#123;$-1\\le u'</span>_&#123;sj&#125;(k)\\le 1$&#125;\\\\</span><br><span class=\"line\">1&amp;\\text&#123;<span class=\"variable\">$u</span><span class=\"string\">'_&#123;sj&#125;(k)&gt;1$&#125;</span></span><br><span class=\"line\"><span class=\"string\">\\end&#123;cases&#125;</span></span><br><span class=\"line\"><span class=\"string\">\\end&#123;eqnarray&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>图片插入<br>.eps图片: 将word图片转为pdf ,再由pdf 转为ps的eps格式然后输入代码<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\begin&#123;center&#125;</span><br><span class=\"line\">\\includegraphics [scale=0.8,trim=0 0 0 0]&#123;2.eps&#125;\\\\</span><br><span class=\"line\">\\label&#123;Fig2&#125;</span><br><span class=\"line\">&#123;\\fontsize&#123;9.3pt&#125;&#123;11.6pt&#125;\\selectfont 图~2~~水下航行器垂直面受力示意图\\\\</span><br><span class=\"line\">Fig.~2~~Schematic diagram of force <span class=\"keyword\">in</span> vertical plane of underwater vehicle&#125;</span><br><span class=\"line\">\\end&#123;center&#125;</span><br></pre></td></tr></table></figure></p>\n<p>截断命令<br>在文章中加入以下命令将文章截断显示在主页<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!-- more --&gt;</span><br></pre></td></tr></table></figure></p>"},{"title":"git学习笔记","date":"2017-11-10T09:02:57.000Z","comments":1,"reward":true,"mathjax":true,"_content":"ubuntu下用hexo写博客,借机学习了一下git,感觉还是很强大的管理系统,这里记录一下git常用的基础命令,随时添加.\n<!-- more -->\n工作区 暂存区 仓库关系\n![](2017-11-10-one/1.png) \n``` bash\n//初始化git\ngit init \n//添加文件到暂存区\ngit add.\n//提交文件到仓库\ngit commit -m \"x\"\n//查看工作状态\ngit status\n//比较不同\ngit diff\n//查看日志\ngit log\ngit log --pretty=oneline\n//回退一个版本\ngit reset --hard HEAD^\n//回退版本 编号 3628164\ngit reset --hard 3628164\n//命令记录\ngit reflog\n//创建SSH Key id_rsa.pub公钥\nssh-keygen -t rsa -C \"youremail@example.com\"\n//关联远程仓库\ngit remote add origin git@github.com:michaelliao/learngit.git\n//推送master到origin\ngit push origin master\n//同步远程到master\ngit pull origin master\n//同步到本地\ngit clone git@github.com:michaelliao/gitskills.git\n//创建+切换分支\ngit checkout -b <name>\n//查看分支\ngit branch\n//切换分支\ngit checkout <name>\n``` \n\n","source":"_posts/2017-11-10-one.md","raw":"---\ntitle: git学习笔记\ndate: 2017-11-10 17:02:57\ncomments: true\nreward: true\nmathjax: true\ntags: \n - git\n---\nubuntu下用hexo写博客,借机学习了一下git,感觉还是很强大的管理系统,这里记录一下git常用的基础命令,随时添加.\n<!-- more -->\n工作区 暂存区 仓库关系\n![](2017-11-10-one/1.png) \n``` bash\n//初始化git\ngit init \n//添加文件到暂存区\ngit add.\n//提交文件到仓库\ngit commit -m \"x\"\n//查看工作状态\ngit status\n//比较不同\ngit diff\n//查看日志\ngit log\ngit log --pretty=oneline\n//回退一个版本\ngit reset --hard HEAD^\n//回退版本 编号 3628164\ngit reset --hard 3628164\n//命令记录\ngit reflog\n//创建SSH Key id_rsa.pub公钥\nssh-keygen -t rsa -C \"youremail@example.com\"\n//关联远程仓库\ngit remote add origin git@github.com:michaelliao/learngit.git\n//推送master到origin\ngit push origin master\n//同步远程到master\ngit pull origin master\n//同步到本地\ngit clone git@github.com:michaelliao/gitskills.git\n//创建+切换分支\ngit checkout -b <name>\n//查看分支\ngit branch\n//切换分支\ngit checkout <name>\n``` \n\n","slug":"2017-11-10-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va1y0003ycvjzulhiz8j","content":"<p>ubuntu下用hexo写博客,借机学习了一下git,感觉还是很强大的管理系统,这里记录一下git常用的基础命令,随时添加.<br><a id=\"more\"></a><br>工作区 暂存区 仓库关系<br><img src=\"/2017/11/10/2017-11-10-one/1.png\" alt=\"\"> </p>\n<pre><code class=\"bash\">//初始化git\ngit init \n//添加文件到暂存区\ngit add.\n//提交文件到仓库\ngit commit -m <span class=\"string\">\"x\"</span>\n//查看工作状态\ngit status\n//比较不同\ngit diff\n//查看日志\ngit <span class=\"built_in\">log</span>\ngit <span class=\"built_in\">log</span> --pretty=oneline\n//回退一个版本\ngit reset --hard HEAD^\n//回退版本 编号 3628164\ngit reset --hard 3628164\n//命令记录\ngit reflog\n//创建SSH Key id_rsa.pub公钥\nssh-keygen -t rsa -C <span class=\"string\">\"youremail@example.com\"</span>\n//关联远程仓库\ngit remote add origin git@github.com:michaelliao/learngit.git\n//推送master到origin\ngit push origin master\n//同步远程到master\ngit pull origin master\n//同步到本地\ngit <span class=\"built_in\">clone</span> git@github.com:michaelliao/gitskills.git\n//创建+切换分支\ngit checkout -b &lt;name&gt;\n//查看分支\ngit branch\n//切换分支\ngit checkout &lt;name&gt;\n</code></pre>\n","site":{"data":{}},"excerpt":"<p>ubuntu下用hexo写博客,借机学习了一下git,感觉还是很强大的管理系统,这里记录一下git常用的基础命令,随时添加.<br></p>","more":"<br>工作区 暂存区 仓库关系<br><img src=\"/2017/11/10/2017-11-10-one/1.png\" alt=\"\"> <p></p>\n<pre><code class=\"bash\">//初始化git\ngit init \n//添加文件到暂存区\ngit add.\n//提交文件到仓库\ngit commit -m <span class=\"string\">\"x\"</span>\n//查看工作状态\ngit status\n//比较不同\ngit diff\n//查看日志\ngit <span class=\"built_in\">log</span>\ngit <span class=\"built_in\">log</span> --pretty=oneline\n//回退一个版本\ngit reset --hard HEAD^\n//回退版本 编号 3628164\ngit reset --hard 3628164\n//命令记录\ngit reflog\n//创建SSH Key id_rsa.pub公钥\nssh-keygen -t rsa -C <span class=\"string\">\"youremail@example.com\"</span>\n//关联远程仓库\ngit remote add origin git@github.com:michaelliao/learngit.git\n//推送master到origin\ngit push origin master\n//同步远程到master\ngit pull origin master\n//同步到本地\ngit <span class=\"built_in\">clone</span> git@github.com:michaelliao/gitskills.git\n//创建+切换分支\ngit checkout -b &lt;name&gt;\n//查看分支\ngit branch\n//切换分支\ngit checkout &lt;name&gt;\n</code></pre>"},{"title":"Hexo+github+个人域名搭建个人博客","date":"2017-06-14T08:40:58.000Z","reward":true,"_content":"Begin:\n主要参考:\n1、http://opiece.me/2015/04/09/hexo-guide/\n参照这篇搭建基本环境，第一种方式不知道为什么挂掉，直接采用第二种方式SSH连接github\nSSH需要在github中设置一下\n2、http://jingyan.baidu.com/article/dca1fa6fa1e403f1a5405262.html\n参照这个教程链接个人域名和github，基本上就是解析一下域名，填上github的IP，本地创建CNAME文件，编译更新上传到github就OK \n嗯，懒得手打教程所以有现成的全部搬过来，整个搭建过程很顺利没什么难点\nEnd","source":"_posts/2017-6-14-one.md","raw":"---\ntitle: Hexo+github+个人域名搭建个人博客\ndate: 2017-06-14 16:40:58\ntags:\n\t- hexo\n\t- github\nreward: true\n---\nBegin:\n主要参考:\n1、http://opiece.me/2015/04/09/hexo-guide/\n参照这篇搭建基本环境，第一种方式不知道为什么挂掉，直接采用第二种方式SSH连接github\nSSH需要在github中设置一下\n2、http://jingyan.baidu.com/article/dca1fa6fa1e403f1a5405262.html\n参照这个教程链接个人域名和github，基本上就是解析一下域名，填上github的IP，本地创建CNAME文件，编译更新上传到github就OK \n嗯，懒得手打教程所以有现成的全部搬过来，整个搭建过程很顺利没什么难点\nEnd","slug":"2017-6-14-one","published":1,"updated":"2018-01-13T08:07:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjd71va200004ycvjt7kjxk1b","content":"<p>Begin:<br>主要参考:<br>1、<a href=\"http://opiece.me/2015/04/09/hexo-guide/\" target=\"_blank\" rel=\"noopener\">http://opiece.me/2015/04/09/hexo-guide/</a><br>参照这篇搭建基本环境，第一种方式不知道为什么挂掉，直接采用第二种方式SSH连接github<br>SSH需要在github中设置一下<br>2、<a href=\"http://jingyan.baidu.com/article/dca1fa6fa1e403f1a5405262.html\" target=\"_blank\" rel=\"noopener\">http://jingyan.baidu.com/article/dca1fa6fa1e403f1a5405262.html</a><br>参照这个教程链接个人域名和github，基本上就是解析一下域名，填上github的IP，本地创建CNAME文件，编译更新上传到github就OK<br>嗯，懒得手打教程所以有现成的全部搬过来，整个搭建过程很顺利没什么难点<br>End</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Begin:<br>主要参考:<br>1、<a href=\"http://opiece.me/2015/04/09/hexo-guide/\" target=\"_blank\" rel=\"noopener\">http://opiece.me/2015/04/09/hexo-guide/</a><br>参照这篇搭建基本环境，第一种方式不知道为什么挂掉，直接采用第二种方式SSH连接github<br>SSH需要在github中设置一下<br>2、<a href=\"http://jingyan.baidu.com/article/dca1fa6fa1e403f1a5405262.html\" target=\"_blank\" rel=\"noopener\">http://jingyan.baidu.com/article/dca1fa6fa1e403f1a5405262.html</a><br>参照这个教程链接个人域名和github，基本上就是解析一下域名，填上github的IP，本地创建CNAME文件，编译更新上传到github就OK<br>嗯，懒得手打教程所以有现成的全部搬过来，整个搭建过程很顺利没什么难点<br>End</p>\n"},{"title":"hexo+网易云跟帖+自定义打赏设置","date":"2017-06-15T04:40:45.000Z","comments":1,"reward":true,"_content":"折腾了半天终于可以设置评论了，由于本微博采用的是小众主题，之前折腾了半天也不能评论，这里记录一下网易云跟帖的设置方法\n``` bash\n<div id=\"cloud-tie-wrapper\" class=\"cloud-tie-wrapper\"></div>\n<script src=\"https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js\"></script>\n<script>\nvar cloudTieConfig = {\nurl: document.location.href, \n\tsourceId: \"\",\n\tproductKey: \"d8314b41ee2d4bbe9df7fa62fa36989e\",\n\ttarget: \"cloud-tie-wrapper\"\n};\nvar yunManualLoad = true;\nTie.loader(\"aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s\", true);\n</script>\n``` \n<!-- more -->\n然后编译调试即可通过，将youyan.ejs文件section替换并没有重新建立文件\n在总设置中打开友言评论，文章中设置comments: true属性即可\n打赏设置，这里主题中有bug,反复调试后才得以发现\n``` bash\n <% if ((theme.reward_type === 2 || (theme.reward_type === 1 && post.reward)) && !index){ %>\n        <div class=\"page-reward\">\n          <p><a href=\"javascript:void(0)\" onclick=\"dashangToggle()\" class=\"dashang\">赏</a></p>\n          <div class=\"hide_box\"></div>\n          <div class=\"shang_box\">\n            <a class=\"shang_close\" href=\"javascript:void(0)\" onclick=\"dashangToggle()\">×</a>\n            <div class=\"shang_tit\">\n              <p><%= theme.reward_wording1%></p>\n            </div>\n            <div class=\"shang_payimg\">\n              <img src=\"/img/alipayimg.jpg\" alt=\"扫码支持\" title=\"扫一扫\" />\n            </div>\n              <div class=\"pay_explain\"><%= theme.reward_wording2%></div>\n            <div class=\"shang_payselect\">\n              <% if(theme.alipay) {%>\n                <div class=\"pay_item checked\" data-id=\"alipay\">\n                  <span class=\"radiobox\"></span>\n                  <span class=\"pay_logo\"><img src=\"<%= theme.alipay%>\" alt=\"支付宝\" /></span>\n                </div>\n              <% } %>\n              <% if(theme.weixin) {%>\n                <div class=\"pay_item\" data-id=\"wechat\">\n                  <span class=\"radiobox\"></span>\n                  <span class=\"pay_logo\"><img src=\"<%= theme.weixin%>\" alt=\"微信\" /></span>\n                </div>\n              <% } %>\n            </div>\n            <div class=\"shang_info\">\n              <p>打开<span id=\"shang_pay_txt\">支付宝</span>扫一扫，即可进行扫码打赏哦</p>\n            </div>\n          </div>\n        </div>\n        <script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js\"></script>\n        <script type=\"text/javascript\">\n          $(\".pay_item\").click(function(){\n            $(this).addClass('checked').siblings('.pay_item').removeClass('checked');\n            var dataid=$(this).attr('data-id');\n            $(\".shang_payimg img\").attr(\"src\",\"/img/\"+dataid+\"img.jpg\");\n            $(\"#shang_pay_txt\").text(dataid==\"alipay\"?\"支付宝\":\"微信\");\n          });\n          function dashangToggle(){\n            \n            $(\".hide_box\").fadeToggle();\n            $(\".shang_box\").fadeToggle();\n          }\n        </script>\n      <% } %>\n ``` \n bug出现在post.reward上，原主题中写的是post.toc\n 主题设置中reward_type设置为1,文章reward: true则可以实现打赏，没有此属性无打赏功能","source":"_posts/2017-6-15-two.md","raw":"---\ntitle: hexo+网易云跟帖+自定义打赏设置\ndate: 2017-06-15 12:40:45\ntags:\n- hexo\ncomments:\n true\nreward: \n true \n---\n折腾了半天终于可以设置评论了，由于本微博采用的是小众主题，之前折腾了半天也不能评论，这里记录一下网易云跟帖的设置方法\n``` bash\n<div id=\"cloud-tie-wrapper\" class=\"cloud-tie-wrapper\"></div>\n<script src=\"https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js\"></script>\n<script>\nvar cloudTieConfig = {\nurl: document.location.href, \n\tsourceId: \"\",\n\tproductKey: \"d8314b41ee2d4bbe9df7fa62fa36989e\",\n\ttarget: \"cloud-tie-wrapper\"\n};\nvar yunManualLoad = true;\nTie.loader(\"aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s\", true);\n</script>\n``` \n<!-- more -->\n然后编译调试即可通过，将youyan.ejs文件section替换并没有重新建立文件\n在总设置中打开友言评论，文章中设置comments: true属性即可\n打赏设置，这里主题中有bug,反复调试后才得以发现\n``` bash\n <% if ((theme.reward_type === 2 || (theme.reward_type === 1 && post.reward)) && !index){ %>\n        <div class=\"page-reward\">\n          <p><a href=\"javascript:void(0)\" onclick=\"dashangToggle()\" class=\"dashang\">赏</a></p>\n          <div class=\"hide_box\"></div>\n          <div class=\"shang_box\">\n            <a class=\"shang_close\" href=\"javascript:void(0)\" onclick=\"dashangToggle()\">×</a>\n            <div class=\"shang_tit\">\n              <p><%= theme.reward_wording1%></p>\n            </div>\n            <div class=\"shang_payimg\">\n              <img src=\"/img/alipayimg.jpg\" alt=\"扫码支持\" title=\"扫一扫\" />\n            </div>\n              <div class=\"pay_explain\"><%= theme.reward_wording2%></div>\n            <div class=\"shang_payselect\">\n              <% if(theme.alipay) {%>\n                <div class=\"pay_item checked\" data-id=\"alipay\">\n                  <span class=\"radiobox\"></span>\n                  <span class=\"pay_logo\"><img src=\"<%= theme.alipay%>\" alt=\"支付宝\" /></span>\n                </div>\n              <% } %>\n              <% if(theme.weixin) {%>\n                <div class=\"pay_item\" data-id=\"wechat\">\n                  <span class=\"radiobox\"></span>\n                  <span class=\"pay_logo\"><img src=\"<%= theme.weixin%>\" alt=\"微信\" /></span>\n                </div>\n              <% } %>\n            </div>\n            <div class=\"shang_info\">\n              <p>打开<span id=\"shang_pay_txt\">支付宝</span>扫一扫，即可进行扫码打赏哦</p>\n            </div>\n          </div>\n        </div>\n        <script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js\"></script>\n        <script type=\"text/javascript\">\n          $(\".pay_item\").click(function(){\n            $(this).addClass('checked').siblings('.pay_item').removeClass('checked');\n            var dataid=$(this).attr('data-id');\n            $(\".shang_payimg img\").attr(\"src\",\"/img/\"+dataid+\"img.jpg\");\n            $(\"#shang_pay_txt\").text(dataid==\"alipay\"?\"支付宝\":\"微信\");\n          });\n          function dashangToggle(){\n            \n            $(\".hide_box\").fadeToggle();\n            $(\".shang_box\").fadeToggle();\n          }\n        </script>\n      <% } %>\n ``` \n bug出现在post.reward上，原主题中写的是post.toc\n 主题设置中reward_type设置为1,文章reward: true则可以实现打赏，没有此属性无打赏功能","slug":"2017-6-15-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va230005ycvjdcvz5wr9","content":"<p>折腾了半天终于可以设置评论了，由于本微博采用的是小众主题，之前折腾了半天也不能评论，这里记录一下网易云跟帖的设置方法</p>\n<pre><code class=\"bash\">&lt;div id=<span class=\"string\">\"cloud-tie-wrapper\"</span> class=<span class=\"string\">\"cloud-tie-wrapper\"</span>&gt;&lt;/div&gt;\n&lt;script src=<span class=\"string\">\"https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js\"</span>&gt;&lt;/script&gt;\n&lt;script&gt;\nvar cloudTieConfig = {\nurl: document.location.href, \n    sourceId: <span class=\"string\">\"\"</span>,\n    productKey: <span class=\"string\">\"d8314b41ee2d4bbe9df7fa62fa36989e\"</span>,\n    target: <span class=\"string\">\"cloud-tie-wrapper\"</span>\n};\nvar yunManualLoad = <span class=\"literal\">true</span>;\nTie.loader(<span class=\"string\">\"aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s\"</span>, <span class=\"literal\">true</span>);\n&lt;/script&gt;\n</code></pre>\n<a id=\"more\"></a>\n<p>然后编译调试即可通过，将youyan.ejs文件section替换并没有重新建立文件<br>在总设置中打开友言评论，文章中设置comments: true属性即可<br>打赏设置，这里主题中有bug,反复调试后才得以发现</p>\n<pre><code class=\"bash\">&lt;% <span class=\"keyword\">if</span> ((theme.reward_type === 2 || (theme.reward_type === 1 &amp;&amp; post.reward)) &amp;&amp; !index){ %&gt;\n       &lt;div class=<span class=\"string\">\"page-reward\"</span>&gt;\n         &lt;p&gt;&lt;a href=<span class=\"string\">\"javascript:void(0)\"</span> onclick=<span class=\"string\">\"dashangToggle()\"</span> class=<span class=\"string\">\"dashang\"</span>&gt;赏&lt;/a&gt;&lt;/p&gt;\n         &lt;div class=<span class=\"string\">\"hide_box\"</span>&gt;&lt;/div&gt;\n         &lt;div class=<span class=\"string\">\"shang_box\"</span>&gt;\n           &lt;a class=<span class=\"string\">\"shang_close\"</span> href=<span class=\"string\">\"javascript:void(0)\"</span> onclick=<span class=\"string\">\"dashangToggle()\"</span>&gt;×&lt;/a&gt;\n           &lt;div class=<span class=\"string\">\"shang_tit\"</span>&gt;\n             &lt;p&gt;&lt;%= theme.reward_wording1%&gt;&lt;/p&gt;\n           &lt;/div&gt;\n           &lt;div class=<span class=\"string\">\"shang_payimg\"</span>&gt;\n             &lt;img src=<span class=\"string\">\"/img/alipayimg.jpg\"</span> alt=<span class=\"string\">\"扫码支持\"</span> title=<span class=\"string\">\"扫一扫\"</span> /&gt;\n           &lt;/div&gt;\n             &lt;div class=<span class=\"string\">\"pay_explain\"</span>&gt;&lt;%= theme.reward_wording2%&gt;&lt;/div&gt;\n           &lt;div class=<span class=\"string\">\"shang_payselect\"</span>&gt;\n             &lt;% <span class=\"keyword\">if</span>(theme.alipay) {%&gt;\n               &lt;div class=<span class=\"string\">\"pay_item checked\"</span> data-id=<span class=\"string\">\"alipay\"</span>&gt;\n                 &lt;span class=<span class=\"string\">\"radiobox\"</span>&gt;&lt;/span&gt;\n                 &lt;span class=<span class=\"string\">\"pay_logo\"</span>&gt;&lt;img src=<span class=\"string\">\"&lt;%= theme.alipay%&gt;\"</span> alt=<span class=\"string\">\"支付宝\"</span> /&gt;&lt;/span&gt;\n               &lt;/div&gt;\n             &lt;% } %&gt;\n             &lt;% <span class=\"keyword\">if</span>(theme.weixin) {%&gt;\n               &lt;div class=<span class=\"string\">\"pay_item\"</span> data-id=<span class=\"string\">\"wechat\"</span>&gt;\n                 &lt;span class=<span class=\"string\">\"radiobox\"</span>&gt;&lt;/span&gt;\n                 &lt;span class=<span class=\"string\">\"pay_logo\"</span>&gt;&lt;img src=<span class=\"string\">\"&lt;%= theme.weixin%&gt;\"</span> alt=<span class=\"string\">\"微信\"</span> /&gt;&lt;/span&gt;\n               &lt;/div&gt;\n             &lt;% } %&gt;\n           &lt;/div&gt;\n           &lt;div class=<span class=\"string\">\"shang_info\"</span>&gt;\n             &lt;p&gt;打开&lt;span id=<span class=\"string\">\"shang_pay_txt\"</span>&gt;支付宝&lt;/span&gt;扫一扫，即可进行扫码打赏哦&lt;/p&gt;\n           &lt;/div&gt;\n         &lt;/div&gt;\n       &lt;/div&gt;\n       &lt;script <span class=\"built_in\">type</span>=<span class=\"string\">\"text/javascript\"</span> src=<span class=\"string\">\"https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js\"</span>&gt;&lt;/script&gt;\n       &lt;script <span class=\"built_in\">type</span>=<span class=\"string\">\"text/javascript\"</span>&gt;\n         $(<span class=\"string\">\".pay_item\"</span>).click(<span class=\"function\"><span class=\"title\">function</span></span>(){\n           $(this).addClass(<span class=\"string\">'checked'</span>).siblings(<span class=\"string\">'.pay_item'</span>).removeClass(<span class=\"string\">'checked'</span>);\n           var dataid=$(this).attr(<span class=\"string\">'data-id'</span>);\n           $(<span class=\"string\">\".shang_payimg img\"</span>).attr(<span class=\"string\">\"src\"</span>,<span class=\"string\">\"/img/\"</span>+dataid+<span class=\"string\">\"img.jpg\"</span>);\n           $(<span class=\"string\">\"#shang_pay_txt\"</span>).text(dataid==<span class=\"string\">\"alipay\"</span>?<span class=\"string\">\"支付宝\"</span>:<span class=\"string\">\"微信\"</span>);\n         });\n         <span class=\"keyword\">function</span> <span class=\"function\"><span class=\"title\">dashangToggle</span></span>(){\n\n           $(<span class=\"string\">\".hide_box\"</span>).fadeToggle();\n           $(<span class=\"string\">\".shang_box\"</span>).fadeToggle();\n         }\n       &lt;/script&gt;\n     &lt;% } %&gt;\n</code></pre>\n<p> bug出现在post.reward上，原主题中写的是post.toc<br> 主题设置中reward_type设置为1,文章reward: true则可以实现打赏，没有此属性无打赏功能</p>\n","site":{"data":{}},"excerpt":"<p>折腾了半天终于可以设置评论了，由于本微博采用的是小众主题，之前折腾了半天也不能评论，这里记录一下网易云跟帖的设置方法</p>\n<pre><code class=\"bash\">&lt;div id=<span class=\"string\">\"cloud-tie-wrapper\"</span> class=<span class=\"string\">\"cloud-tie-wrapper\"</span>&gt;&lt;/div&gt;\n&lt;script src=<span class=\"string\">\"https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js\"</span>&gt;&lt;/script&gt;\n&lt;script&gt;\nvar cloudTieConfig = {\nurl: document.location.href, \n    sourceId: <span class=\"string\">\"\"</span>,\n    productKey: <span class=\"string\">\"d8314b41ee2d4bbe9df7fa62fa36989e\"</span>,\n    target: <span class=\"string\">\"cloud-tie-wrapper\"</span>\n};\nvar yunManualLoad = <span class=\"literal\">true</span>;\nTie.loader(<span class=\"string\">\"aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s\"</span>, <span class=\"literal\">true</span>);\n&lt;/script&gt;\n</code></pre>","more":"<p>然后编译调试即可通过，将youyan.ejs文件section替换并没有重新建立文件<br>在总设置中打开友言评论，文章中设置comments: true属性即可<br>打赏设置，这里主题中有bug,反复调试后才得以发现</p>\n<pre><code class=\"bash\">&lt;% <span class=\"keyword\">if</span> ((theme.reward_type === 2 || (theme.reward_type === 1 &amp;&amp; post.reward)) &amp;&amp; !index){ %&gt;\n       &lt;div class=<span class=\"string\">\"page-reward\"</span>&gt;\n         &lt;p&gt;&lt;a href=<span class=\"string\">\"javascript:void(0)\"</span> onclick=<span class=\"string\">\"dashangToggle()\"</span> class=<span class=\"string\">\"dashang\"</span>&gt;赏&lt;/a&gt;&lt;/p&gt;\n         &lt;div class=<span class=\"string\">\"hide_box\"</span>&gt;&lt;/div&gt;\n         &lt;div class=<span class=\"string\">\"shang_box\"</span>&gt;\n           &lt;a class=<span class=\"string\">\"shang_close\"</span> href=<span class=\"string\">\"javascript:void(0)\"</span> onclick=<span class=\"string\">\"dashangToggle()\"</span>&gt;×&lt;/a&gt;\n           &lt;div class=<span class=\"string\">\"shang_tit\"</span>&gt;\n             &lt;p&gt;&lt;%= theme.reward_wording1%&gt;&lt;/p&gt;\n           &lt;/div&gt;\n           &lt;div class=<span class=\"string\">\"shang_payimg\"</span>&gt;\n             &lt;img src=<span class=\"string\">\"/img/alipayimg.jpg\"</span> alt=<span class=\"string\">\"扫码支持\"</span> title=<span class=\"string\">\"扫一扫\"</span> /&gt;\n           &lt;/div&gt;\n             &lt;div class=<span class=\"string\">\"pay_explain\"</span>&gt;&lt;%= theme.reward_wording2%&gt;&lt;/div&gt;\n           &lt;div class=<span class=\"string\">\"shang_payselect\"</span>&gt;\n             &lt;% <span class=\"keyword\">if</span>(theme.alipay) {%&gt;\n               &lt;div class=<span class=\"string\">\"pay_item checked\"</span> data-id=<span class=\"string\">\"alipay\"</span>&gt;\n                 &lt;span class=<span class=\"string\">\"radiobox\"</span>&gt;&lt;/span&gt;\n                 &lt;span class=<span class=\"string\">\"pay_logo\"</span>&gt;&lt;img src=<span class=\"string\">\"&lt;%= theme.alipay%&gt;\"</span> alt=<span class=\"string\">\"支付宝\"</span> /&gt;&lt;/span&gt;\n               &lt;/div&gt;\n             &lt;% } %&gt;\n             &lt;% <span class=\"keyword\">if</span>(theme.weixin) {%&gt;\n               &lt;div class=<span class=\"string\">\"pay_item\"</span> data-id=<span class=\"string\">\"wechat\"</span>&gt;\n                 &lt;span class=<span class=\"string\">\"radiobox\"</span>&gt;&lt;/span&gt;\n                 &lt;span class=<span class=\"string\">\"pay_logo\"</span>&gt;&lt;img src=<span class=\"string\">\"&lt;%= theme.weixin%&gt;\"</span> alt=<span class=\"string\">\"微信\"</span> /&gt;&lt;/span&gt;\n               &lt;/div&gt;\n             &lt;% } %&gt;\n           &lt;/div&gt;\n           &lt;div class=<span class=\"string\">\"shang_info\"</span>&gt;\n             &lt;p&gt;打开&lt;span id=<span class=\"string\">\"shang_pay_txt\"</span>&gt;支付宝&lt;/span&gt;扫一扫，即可进行扫码打赏哦&lt;/p&gt;\n           &lt;/div&gt;\n         &lt;/div&gt;\n       &lt;/div&gt;\n       &lt;script <span class=\"built_in\">type</span>=<span class=\"string\">\"text/javascript\"</span> src=<span class=\"string\">\"https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js\"</span>&gt;&lt;/script&gt;\n       &lt;script <span class=\"built_in\">type</span>=<span class=\"string\">\"text/javascript\"</span>&gt;\n         $(<span class=\"string\">\".pay_item\"</span>).click(<span class=\"function\"><span class=\"title\">function</span></span>(){\n           $(this).addClass(<span class=\"string\">'checked'</span>).siblings(<span class=\"string\">'.pay_item'</span>).removeClass(<span class=\"string\">'checked'</span>);\n           var dataid=$(this).attr(<span class=\"string\">'data-id'</span>);\n           $(<span class=\"string\">\".shang_payimg img\"</span>).attr(<span class=\"string\">\"src\"</span>,<span class=\"string\">\"/img/\"</span>+dataid+<span class=\"string\">\"img.jpg\"</span>);\n           $(<span class=\"string\">\"#shang_pay_txt\"</span>).text(dataid==<span class=\"string\">\"alipay\"</span>?<span class=\"string\">\"支付宝\"</span>:<span class=\"string\">\"微信\"</span>);\n         });\n         <span class=\"keyword\">function</span> <span class=\"function\"><span class=\"title\">dashangToggle</span></span>(){\n\n           $(<span class=\"string\">\".hide_box\"</span>).fadeToggle();\n           $(<span class=\"string\">\".shang_box\"</span>).fadeToggle();\n         }\n       &lt;/script&gt;\n     &lt;% } %&gt;\n</code></pre>\n<p> bug出现在post.reward上，原主题中写的是post.toc<br> 主题设置中reward_type设置为1,文章reward: true则可以实现打赏，没有此属性无打赏功能</p>"},{"title":"Python环境配置(Eclipse+Anaconda)","date":"2017-06-21T08:42:27.000Z","comments":1,"reward":true,"_content":"本着开始学习深度学习和神经网络相关知识开始搭建python环境，按照顺序安装jre-8u101-windows，anaconda，eclipse文件，然后在eclipse中添加anacoda作为python的解释器。\neclipse设置过程\n1.在eclipse的help->Eclipse Marketsplace中，输入PyDev，进行安装，\n2.PyDev安装完成后，点击eclipse中的windows->Preferences->PyDev->Interpreter-Python进行配置\n3.点击按钮new，找到Anaconda的安装目录中的python.exe，添加进去。\n<!-- more -->\n![](2017-6-21-one/1.jpg)\nFile new ->PyDev Module\n惯例Helloworld脚本\n``` bash\n#coding=gbk\n'''\nCreated on 2017年6月21日\n@author: Administrator\n'''\nprint('Hello World!');\n```\n由于注释中有时间汉字给出gbk编码环境，否则会报错.","source":"_posts/2017-6-21-one.md","raw":"---\ntitle: Python环境配置(Eclipse+Anaconda)\ndate: 2017-06-21 16:42:27\ncomments: true\nreward: true\ntags: \n - python\n---\n本着开始学习深度学习和神经网络相关知识开始搭建python环境，按照顺序安装jre-8u101-windows，anaconda，eclipse文件，然后在eclipse中添加anacoda作为python的解释器。\neclipse设置过程\n1.在eclipse的help->Eclipse Marketsplace中，输入PyDev，进行安装，\n2.PyDev安装完成后，点击eclipse中的windows->Preferences->PyDev->Interpreter-Python进行配置\n3.点击按钮new，找到Anaconda的安装目录中的python.exe，添加进去。\n<!-- more -->\n![](2017-6-21-one/1.jpg)\nFile new ->PyDev Module\n惯例Helloworld脚本\n``` bash\n#coding=gbk\n'''\nCreated on 2017年6月21日\n@author: Administrator\n'''\nprint('Hello World!');\n```\n由于注释中有时间汉字给出gbk编码环境，否则会报错.","slug":"2017-6-21-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va280008ycvjxdf6itu0","content":"<p>本着开始学习深度学习和神经网络相关知识开始搭建python环境，按照顺序安装jre-8u101-windows，anaconda，eclipse文件，然后在eclipse中添加anacoda作为python的解释器。<br>eclipse设置过程<br>1.在eclipse的help-&gt;Eclipse Marketsplace中，输入PyDev，进行安装，<br>2.PyDev安装完成后，点击eclipse中的windows-&gt;Preferences-&gt;PyDev-&gt;Interpreter-Python进行配置<br>3.点击按钮new，找到Anaconda的安装目录中的python.exe，添加进去。<br><a id=\"more\"></a><br><img src=\"/2017/06/21/2017-6-21-one/1.jpg\" alt=\"\"><br>File new -&gt;PyDev Module<br>惯例Helloworld脚本<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#coding=gbk</span></span><br><span class=\"line\"><span class=\"string\">''</span><span class=\"string\">'</span></span><br><span class=\"line\"><span class=\"string\">Created on 2017年6月21日</span></span><br><span class=\"line\"><span class=\"string\">@author: Administrator</span></span><br><span class=\"line\"><span class=\"string\">'</span><span class=\"string\">''</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Hello World!'</span>);</span><br></pre></td></tr></table></figure></p>\n<p>由于注释中有时间汉字给出gbk编码环境，否则会报错.</p>\n","site":{"data":{}},"excerpt":"<p>本着开始学习深度学习和神经网络相关知识开始搭建python环境，按照顺序安装jre-8u101-windows，anaconda，eclipse文件，然后在eclipse中添加anacoda作为python的解释器。<br>eclipse设置过程<br>1.在eclipse的help-&gt;Eclipse Marketsplace中，输入PyDev，进行安装，<br>2.PyDev安装完成后，点击eclipse中的windows-&gt;Preferences-&gt;PyDev-&gt;Interpreter-Python进行配置<br>3.点击按钮new，找到Anaconda的安装目录中的python.exe，添加进去。<br></p>","more":"<br><img src=\"/2017/06/21/2017-6-21-one/1.jpg\" alt=\"\"><br>File new -&gt;PyDev Module<br>惯例Helloworld脚本<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#coding=gbk</span></span><br><span class=\"line\"><span class=\"string\">''</span><span class=\"string\">'</span></span><br><span class=\"line\"><span class=\"string\">Created on 2017年6月21日</span></span><br><span class=\"line\"><span class=\"string\">@author: Administrator</span></span><br><span class=\"line\"><span class=\"string\">'</span><span class=\"string\">''</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Hello World!'</span>);</span><br></pre></td></tr></table></figure><p></p>\n<p>由于注释中有时间汉字给出gbk编码环境，否则会报错.</p>"},{"title":"Python学习笔记（一）","date":"2017-06-21T12:21:05.000Z","comments":1,"reward":true,"_content":"1、Package分为内部Package和外部Package，内部Package直接可以import,外部package需要pip install安装包再进行import\n2、Python数据类型\n总体：numerics, sequences, mappings, classes, instances, and exceptions\nNumeric Types: int (包含boolean), float, complex\nint: unlimited length; float: 实现用double in C, 可查看 sys.float_info; complex: real(实部) & imaginary(虚部）,用z.real 和 z.imag来取两部分\n具体运算以及法则参见：https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex\n例子\n<!-- more -->\n``` bash\nimport sys\na = 3\nb = 4\nc = 5.66\nd = 8.0\ne = complex(c, d)\nf = complex(float(a), float(b))\nprint (\"a is type\" , type(a))\nprint (\"b is type\" , type(b))\nprint (\"c is type\" , type(c))\nprint (\"d is type\" , type(d))\nprint (\"e is type\" , type(e))\nprint (\"f is type\" , type(f))\nprint(a + b)\nprint(d / c)\nprint (b / a)\nprint (b // a)\nprint (e)\nprint (e + f)\nprint (\"e's real part is: \" , e.real)\nprint (\"e's imaginary part is: \" , e.imag)\nprint (sys.float_info)\n```\n输出结果为\n``` bash\na is type <class 'int'>\nb is type <class 'int'>\nc is type <class 'float'>\nd is type <class 'float'>\ne is type <class 'complex'>\nf is type <class 'complex'>\n7\n1.4134275618374559\n1.3333333333333333\n1\n(5.66+8j)\n(8.66+12j)\ne's real part is:  5.66\ne's imaginary part is:  8.0\nsys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n```\nPS:编译快捷键Ctrl+F11\n","source":"_posts/2017-6-21-two.md","raw":"---\ntitle: Python学习笔记（一）\ndate: 2017-06-21 20:21:05\ncomments: true\nreward: true\ntags: \n - python\n---\n1、Package分为内部Package和外部Package，内部Package直接可以import,外部package需要pip install安装包再进行import\n2、Python数据类型\n总体：numerics, sequences, mappings, classes, instances, and exceptions\nNumeric Types: int (包含boolean), float, complex\nint: unlimited length; float: 实现用double in C, 可查看 sys.float_info; complex: real(实部) & imaginary(虚部）,用z.real 和 z.imag来取两部分\n具体运算以及法则参见：https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex\n例子\n<!-- more -->\n``` bash\nimport sys\na = 3\nb = 4\nc = 5.66\nd = 8.0\ne = complex(c, d)\nf = complex(float(a), float(b))\nprint (\"a is type\" , type(a))\nprint (\"b is type\" , type(b))\nprint (\"c is type\" , type(c))\nprint (\"d is type\" , type(d))\nprint (\"e is type\" , type(e))\nprint (\"f is type\" , type(f))\nprint(a + b)\nprint(d / c)\nprint (b / a)\nprint (b // a)\nprint (e)\nprint (e + f)\nprint (\"e's real part is: \" , e.real)\nprint (\"e's imaginary part is: \" , e.imag)\nprint (sys.float_info)\n```\n输出结果为\n``` bash\na is type <class 'int'>\nb is type <class 'int'>\nc is type <class 'float'>\nd is type <class 'float'>\ne is type <class 'complex'>\nf is type <class 'complex'>\n7\n1.4134275618374559\n1.3333333333333333\n1\n(5.66+8j)\n(8.66+12j)\ne's real part is:  5.66\ne's imaginary part is:  8.0\nsys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n```\nPS:编译快捷键Ctrl+F11\n","slug":"2017-6-21-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2b0009ycvj2x0trmcq","content":"<p>1、Package分为内部Package和外部Package，内部Package直接可以import,外部package需要pip install安装包再进行import<br>2、Python数据类型<br>总体：numerics, sequences, mappings, classes, instances, and exceptions<br>Numeric Types: int (包含boolean), float, complex<br>int: unlimited length; float: 实现用double in C, 可查看 sys.float_info; complex: real(实部) &amp; imaginary(虚部）,用z.real 和 z.imag来取两部分<br>具体运算以及法则参见：<a href=\"https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex\" target=\"_blank\" rel=\"noopener\">https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex</a><br>例子<br><a id=\"more\"></a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import sys</span><br><span class=\"line\">a = 3</span><br><span class=\"line\">b = 4</span><br><span class=\"line\">c = 5.66</span><br><span class=\"line\">d = 8.0</span><br><span class=\"line\">e = complex(c, d)</span><br><span class=\"line\">f = complex(<span class=\"built_in\">float</span>(a), <span class=\"built_in\">float</span>(b))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"a is type\"</span> , <span class=\"built_in\">type</span>(a))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"b is type\"</span> , <span class=\"built_in\">type</span>(b))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"c is type\"</span> , <span class=\"built_in\">type</span>(c))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"d is type\"</span> , <span class=\"built_in\">type</span>(d))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"e is type\"</span> , <span class=\"built_in\">type</span>(e))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"f is type\"</span> , <span class=\"built_in\">type</span>(f))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a + b)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(d / c)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (b / a)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (b // a)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (e)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (e + f)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"e's real part is: \"</span> , e.real)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"e's imaginary part is: \"</span> , e.imag)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (sys.float_info)</span><br></pre></td></tr></table></figure></p>\n<p>输出结果为<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'int'</span>&gt;</span><br><span class=\"line\">b is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'int'</span>&gt;</span><br><span class=\"line\">c is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'float'</span>&gt;</span><br><span class=\"line\">d is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'float'</span>&gt;</span><br><span class=\"line\">e is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'complex'</span>&gt;</span><br><span class=\"line\">f is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'complex'</span>&gt;</span><br><span class=\"line\">7</span><br><span class=\"line\">1.4134275618374559</span><br><span class=\"line\">1.3333333333333333</span><br><span class=\"line\">1</span><br><span class=\"line\">(5.66+8j)</span><br><span class=\"line\">(8.66+12j)</span><br><span class=\"line\">e<span class=\"string\">'s real part is:  5.66</span></span><br><span class=\"line\"><span class=\"string\">e'</span>s imaginary part is:  8.0</span><br><span class=\"line\">sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)</span><br></pre></td></tr></table></figure></p>\n<p>PS:编译快捷键Ctrl+F11</p>\n","site":{"data":{}},"excerpt":"<p>1、Package分为内部Package和外部Package，内部Package直接可以import,外部package需要pip install安装包再进行import<br>2、Python数据类型<br>总体：numerics, sequences, mappings, classes, instances, and exceptions<br>Numeric Types: int (包含boolean), float, complex<br>int: unlimited length; float: 实现用double in C, 可查看 sys.float_info; complex: real(实部) &amp; imaginary(虚部）,用z.real 和 z.imag来取两部分<br>具体运算以及法则参见：<a href=\"https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex\" target=\"_blank\" rel=\"noopener\">https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex</a><br>例子<br></p>","more":"<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import sys</span><br><span class=\"line\">a = 3</span><br><span class=\"line\">b = 4</span><br><span class=\"line\">c = 5.66</span><br><span class=\"line\">d = 8.0</span><br><span class=\"line\">e = complex(c, d)</span><br><span class=\"line\">f = complex(<span class=\"built_in\">float</span>(a), <span class=\"built_in\">float</span>(b))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"a is type\"</span> , <span class=\"built_in\">type</span>(a))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"b is type\"</span> , <span class=\"built_in\">type</span>(b))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"c is type\"</span> , <span class=\"built_in\">type</span>(c))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"d is type\"</span> , <span class=\"built_in\">type</span>(d))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"e is type\"</span> , <span class=\"built_in\">type</span>(e))</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"f is type\"</span> , <span class=\"built_in\">type</span>(f))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a + b)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(d / c)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (b / a)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (b // a)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (e)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (e + f)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"e's real part is: \"</span> , e.real)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">\"e's imaginary part is: \"</span> , e.imag)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (sys.float_info)</span><br></pre></td></tr></table></figure><p></p>\n<p>输出结果为<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'int'</span>&gt;</span><br><span class=\"line\">b is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'int'</span>&gt;</span><br><span class=\"line\">c is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'float'</span>&gt;</span><br><span class=\"line\">d is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'float'</span>&gt;</span><br><span class=\"line\">e is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'complex'</span>&gt;</span><br><span class=\"line\">f is <span class=\"built_in\">type</span> &lt;class <span class=\"string\">'complex'</span>&gt;</span><br><span class=\"line\">7</span><br><span class=\"line\">1.4134275618374559</span><br><span class=\"line\">1.3333333333333333</span><br><span class=\"line\">1</span><br><span class=\"line\">(5.66+8j)</span><br><span class=\"line\">(8.66+12j)</span><br><span class=\"line\">e<span class=\"string\">'s real part is:  5.66</span></span><br><span class=\"line\"><span class=\"string\">e'</span>s imaginary part is:  8.0</span><br><span class=\"line\">sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)</span><br></pre></td></tr></table></figure></p>\n<p>PS:编译快捷键Ctrl+F11</p>"},{"title":"Python学习笔记（二）","date":"2017-06-21T12:28:05.000Z","comments":1,"reward":true,"_content":"1. 字符串：\n一串字符\n显示或者打印出来文字信息\n导出\n编码：# -*- coding: utf-8 -*-\n单引号，双引号，三引号\n不可变（immutable)\nFormat字符串\nage = 3\nname = \"Tom\"\nprint(\"{0} was {1} years old\".format(name, age))\n<!-- more -->\n联合：+: print(name + \" was \" + str(age) + \" years old\")\n换行符: print(\"What's your name? \\nTom\")\n2. 字面常量（literal constant):\n可以直接以字面的意义使用它们：\n如：6，2.24，3.45e-3, \"This is a string\"\n常量：不会被改变\n3. 变量：\n储存信息\n属于identifier\nidentifier命名规则：\n第一个字符必须是字母或者下划线\n其余字符可以是字母，数字，或者下划线\n区分大小写\n如：合法：i, name_3_4, big_bang\n不合法：2people, this is tom, my-name, >123b_c2\n4. 注释： # \n5. 缩进(Indentation)\n6. 列表相关\n直接给出代码 以后参考备用\n``` bash\n#coding=utf-8\n'''\nCreated on 2017.6.21\n\n@author: Administrator\n'''\n# -*- coding: utf-8 -*-\n#创建一个列表\nnumber_list = [1, 3, 5, 7, 9]\nstring_list = [\"abc\", \"bbc\", \"python\"]\nmixed_list = ['python', 'java', 3, 12]\n#访问列表中的值\nsecond_num = number_list[1]\nthird_string = string_list[2]\nfourth_mix = mixed_list[3]\nprint(\"second_num: {0} third_string: {1} fourth_mix: {2}\".format(second_num, third_string, fourth_mix))\n#更新列表\nprint(\"number_list before: \" + str(number_list))\nnumber_list[1] = 30\nprint(\"number_list after: \" + str(number_list))\n#删除列表元素\nprint(\"mixed_list before delete: \" + str(mixed_list))\ndel mixed_list[2]\nprint(\"mixed_list after delete: \" + str(mixed_list))\n#Python脚本语言\nprint(len([1,2,3])) #长度\nprint([1,2,3] + [4,5,6]) #组合\nprint(['Hello'] * 4) #重复\nprint(3 in [1,2,3]) #某元素是否在列表中\n#列表的截取\nabcdlist=['a','b','c','d']\nprint(abcdlist[1])\nprint(abcdlist[-2])\nprint(abcdlist[1:])\n# 列表操作包含以下函数:\n# 1、cmp(list1, list2)：比较两个列表的元素 \n# 2、len(list)：列表元素个数 \n# 3、max(list)：返回列表元素最大值 \n# 4、min(list)：返回列表元素最小值 \n# 5、list(seq)：将元组转换为列表 \n# 列表操作包含以下方法:\n# 1、list.append(obj)：在列表末尾添加新的对象\n# 2、list.count(obj)：统计某个元素在列表中出现的次数\n# 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）\n# 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置\n# 5、list.insert(index, obj)：将对象插入列表\n# 6、list.pop(obj=list[-1])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值\n# 7、list.remove(obj)：移除列表中某个值的第一个匹配项\n# 8、list.reverse()：反向列表中元素\n# 9、list.sort([func])：对原列表进行排序\n```\n结果\n``` bash\nsecond_num: 3 third_string: python fourth_mix: 12\nnumber_list before: [1, 3, 5, 7, 9]\nnumber_list after: [1, 30, 5, 7, 9]\nmixed_list before delete: ['python', 'java', 3, 12]\nmixed_list after delete: ['python', 'java', 12]\n3\n[1, 2, 3, 4, 5, 6]\n['Hello', 'Hello', 'Hello', 'Hello']\nTrue\nb\nc\n['b', 'c', 'd']\n```","source":"_posts/2017-6-21-three.md","raw":"---\ntitle: Python学习笔记（二）\ndate: 2017-06-21 20:28:05\ncomments: true\nreward: true\ntags: \n - python\n---\n1. 字符串：\n一串字符\n显示或者打印出来文字信息\n导出\n编码：# -*- coding: utf-8 -*-\n单引号，双引号，三引号\n不可变（immutable)\nFormat字符串\nage = 3\nname = \"Tom\"\nprint(\"{0} was {1} years old\".format(name, age))\n<!-- more -->\n联合：+: print(name + \" was \" + str(age) + \" years old\")\n换行符: print(\"What's your name? \\nTom\")\n2. 字面常量（literal constant):\n可以直接以字面的意义使用它们：\n如：6，2.24，3.45e-3, \"This is a string\"\n常量：不会被改变\n3. 变量：\n储存信息\n属于identifier\nidentifier命名规则：\n第一个字符必须是字母或者下划线\n其余字符可以是字母，数字，或者下划线\n区分大小写\n如：合法：i, name_3_4, big_bang\n不合法：2people, this is tom, my-name, >123b_c2\n4. 注释： # \n5. 缩进(Indentation)\n6. 列表相关\n直接给出代码 以后参考备用\n``` bash\n#coding=utf-8\n'''\nCreated on 2017.6.21\n\n@author: Administrator\n'''\n# -*- coding: utf-8 -*-\n#创建一个列表\nnumber_list = [1, 3, 5, 7, 9]\nstring_list = [\"abc\", \"bbc\", \"python\"]\nmixed_list = ['python', 'java', 3, 12]\n#访问列表中的值\nsecond_num = number_list[1]\nthird_string = string_list[2]\nfourth_mix = mixed_list[3]\nprint(\"second_num: {0} third_string: {1} fourth_mix: {2}\".format(second_num, third_string, fourth_mix))\n#更新列表\nprint(\"number_list before: \" + str(number_list))\nnumber_list[1] = 30\nprint(\"number_list after: \" + str(number_list))\n#删除列表元素\nprint(\"mixed_list before delete: \" + str(mixed_list))\ndel mixed_list[2]\nprint(\"mixed_list after delete: \" + str(mixed_list))\n#Python脚本语言\nprint(len([1,2,3])) #长度\nprint([1,2,3] + [4,5,6]) #组合\nprint(['Hello'] * 4) #重复\nprint(3 in [1,2,3]) #某元素是否在列表中\n#列表的截取\nabcdlist=['a','b','c','d']\nprint(abcdlist[1])\nprint(abcdlist[-2])\nprint(abcdlist[1:])\n# 列表操作包含以下函数:\n# 1、cmp(list1, list2)：比较两个列表的元素 \n# 2、len(list)：列表元素个数 \n# 3、max(list)：返回列表元素最大值 \n# 4、min(list)：返回列表元素最小值 \n# 5、list(seq)：将元组转换为列表 \n# 列表操作包含以下方法:\n# 1、list.append(obj)：在列表末尾添加新的对象\n# 2、list.count(obj)：统计某个元素在列表中出现的次数\n# 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）\n# 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置\n# 5、list.insert(index, obj)：将对象插入列表\n# 6、list.pop(obj=list[-1])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值\n# 7、list.remove(obj)：移除列表中某个值的第一个匹配项\n# 8、list.reverse()：反向列表中元素\n# 9、list.sort([func])：对原列表进行排序\n```\n结果\n``` bash\nsecond_num: 3 third_string: python fourth_mix: 12\nnumber_list before: [1, 3, 5, 7, 9]\nnumber_list after: [1, 30, 5, 7, 9]\nmixed_list before delete: ['python', 'java', 3, 12]\nmixed_list after delete: ['python', 'java', 12]\n3\n[1, 2, 3, 4, 5, 6]\n['Hello', 'Hello', 'Hello', 'Hello']\nTrue\nb\nc\n['b', 'c', 'd']\n```","slug":"2017-6-21-three","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2f000cycvj89pslo2x","content":"<ol>\n<li>字符串：<br>一串字符<br>显示或者打印出来文字信息<br>导出<br>编码：# -<em>- coding: utf-8 -</em>-<br>单引号，双引号，三引号<br>不可变（immutable)<br>Format字符串<br>age = 3<br>name = “Tom”<br>print(“{0} was {1} years old”.format(name, age))<a id=\"more\"></a>\n联合：+: print(name + “ was “ + str(age) + “ years old”)<br>换行符: print(“What’s your name? \\nTom”)</li>\n<li>字面常量（literal constant):<br>可以直接以字面的意义使用它们：<br>如：6，2.24，3.45e-3, “This is a string”<br>常量：不会被改变</li>\n<li>变量：<br>储存信息<br>属于identifier<br>identifier命名规则：<br>第一个字符必须是字母或者下划线<br>其余字符可以是字母，数字，或者下划线<br>区分大小写<br>如：合法：i, name_3_4, big_bang<br>不合法：2people, this is tom, my-name, &gt;123b_c2</li>\n<li>注释： # </li>\n<li>缩进(Indentation)</li>\n<li>列表相关<br>直接给出代码 以后参考备用<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#coding=utf-8</span></span><br><span class=\"line\"><span class=\"string\">''</span><span class=\"string\">'</span></span><br><span class=\"line\"><span class=\"string\">Created on 2017.6.21</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">@author: Administrator</span></span><br><span class=\"line\"><span class=\"string\">'</span><span class=\"string\">''</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\">#创建一个列表</span></span><br><span class=\"line\">number_list = [1, 3, 5, 7, 9]</span><br><span class=\"line\">string_list = [<span class=\"string\">\"abc\"</span>, <span class=\"string\">\"bbc\"</span>, <span class=\"string\">\"python\"</span>]</span><br><span class=\"line\">mixed_list = [<span class=\"string\">'python'</span>, <span class=\"string\">'java'</span>, 3, 12]</span><br><span class=\"line\"><span class=\"comment\">#访问列表中的值</span></span><br><span class=\"line\">second_num = number_list[1]</span><br><span class=\"line\">third_string = string_list[2]</span><br><span class=\"line\">fourth_mix = mixed_list[3]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"second_num: &#123;0&#125; third_string: &#123;1&#125; fourth_mix: &#123;2&#125;\"</span>.format(second_num, third_string, fourth_mix))</span><br><span class=\"line\"><span class=\"comment\">#更新列表</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"number_list before: \"</span> + str(number_list))</span><br><span class=\"line\">number_list[1] = 30</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"number_list after: \"</span> + str(number_list))</span><br><span class=\"line\"><span class=\"comment\">#删除列表元素</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"mixed_list before delete: \"</span> + str(mixed_list))</span><br><span class=\"line\">del mixed_list[2]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"mixed_list after delete: \"</span> + str(mixed_list))</span><br><span class=\"line\"><span class=\"comment\">#Python脚本语言</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(len([1,2,3])) <span class=\"comment\">#长度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>([1,2,3] + [4,5,6]) <span class=\"comment\">#组合</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>([<span class=\"string\">'Hello'</span>] * 4) <span class=\"comment\">#重复</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(3 <span class=\"keyword\">in</span> [1,2,3]) <span class=\"comment\">#某元素是否在列表中</span></span><br><span class=\"line\"><span class=\"comment\">#列表的截取</span></span><br><span class=\"line\">abcdlist=[<span class=\"string\">'a'</span>,<span class=\"string\">'b'</span>,<span class=\"string\">'c'</span>,<span class=\"string\">'d'</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(abcdlist[1])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(abcdlist[-2])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(abcdlist[1:])</span><br><span class=\"line\"><span class=\"comment\"># 列表操作包含以下函数:</span></span><br><span class=\"line\"><span class=\"comment\"># 1、cmp(list1, list2)：比较两个列表的元素 </span></span><br><span class=\"line\"><span class=\"comment\"># 2、len(list)：列表元素个数 </span></span><br><span class=\"line\"><span class=\"comment\"># 3、max(list)：返回列表元素最大值 </span></span><br><span class=\"line\"><span class=\"comment\"># 4、min(list)：返回列表元素最小值 </span></span><br><span class=\"line\"><span class=\"comment\"># 5、list(seq)：将元组转换为列表 </span></span><br><span class=\"line\"><span class=\"comment\"># 列表操作包含以下方法:</span></span><br><span class=\"line\"><span class=\"comment\"># 1、list.append(obj)：在列表末尾添加新的对象</span></span><br><span class=\"line\"><span class=\"comment\"># 2、list.count(obj)：统计某个元素在列表中出现的次数</span></span><br><span class=\"line\"><span class=\"comment\"># 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）</span></span><br><span class=\"line\"><span class=\"comment\"># 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置</span></span><br><span class=\"line\"><span class=\"comment\"># 5、list.insert(index, obj)：将对象插入列表</span></span><br><span class=\"line\"><span class=\"comment\"># 6、list.pop(obj=list[-1])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值</span></span><br><span class=\"line\"><span class=\"comment\"># 7、list.remove(obj)：移除列表中某个值的第一个匹配项</span></span><br><span class=\"line\"><span class=\"comment\"># 8、list.reverse()：反向列表中元素</span></span><br><span class=\"line\"><span class=\"comment\"># 9、list.sort([func])：对原列表进行排序</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>结果<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">second_num: 3 third_string: python fourth_mix: 12</span><br><span class=\"line\">number_list before: [1, 3, 5, 7, 9]</span><br><span class=\"line\">number_list after: [1, 30, 5, 7, 9]</span><br><span class=\"line\">mixed_list before delete: [<span class=\"string\">'python'</span>, <span class=\"string\">'java'</span>, 3, 12]</span><br><span class=\"line\">mixed_list after delete: [<span class=\"string\">'python'</span>, <span class=\"string\">'java'</span>, 12]</span><br><span class=\"line\">3</span><br><span class=\"line\">[1, 2, 3, 4, 5, 6]</span><br><span class=\"line\">[<span class=\"string\">'Hello'</span>, <span class=\"string\">'Hello'</span>, <span class=\"string\">'Hello'</span>, <span class=\"string\">'Hello'</span>]</span><br><span class=\"line\">True</span><br><span class=\"line\">b</span><br><span class=\"line\">c</span><br><span class=\"line\">[<span class=\"string\">'b'</span>, <span class=\"string\">'c'</span>, <span class=\"string\">'d'</span>]</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<ol>\n<li>字符串：<br>一串字符<br>显示或者打印出来文字信息<br>导出<br>编码：# -<em>- coding: utf-8 -</em>-<br>单引号，双引号，三引号<br>不可变（immutable)<br>Format字符串<br>age = 3<br>name = “Tom”<br>print(“{0} was {1} years old”.format(name, age))</li></ol>","more":"联合：+: print(name + “ was “ + str(age) + “ years old”)<br>换行符: print(“What’s your name? \\nTom”)\n<li>字面常量（literal constant):<br>可以直接以字面的意义使用它们：<br>如：6，2.24，3.45e-3, “This is a string”<br>常量：不会被改变</li>\n<li>变量：<br>储存信息<br>属于identifier<br>identifier命名规则：<br>第一个字符必须是字母或者下划线<br>其余字符可以是字母，数字，或者下划线<br>区分大小写<br>如：合法：i, name_3_4, big_bang<br>不合法：2people, this is tom, my-name, &gt;123b_c2</li>\n<li>注释： # </li>\n<li>缩进(Indentation)</li>\n<li>列表相关<br>直接给出代码 以后参考备用<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#coding=utf-8</span></span><br><span class=\"line\"><span class=\"string\">''</span><span class=\"string\">'</span></span><br><span class=\"line\"><span class=\"string\">Created on 2017.6.21</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">@author: Administrator</span></span><br><span class=\"line\"><span class=\"string\">'</span><span class=\"string\">''</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\">#创建一个列表</span></span><br><span class=\"line\">number_list = [1, 3, 5, 7, 9]</span><br><span class=\"line\">string_list = [<span class=\"string\">\"abc\"</span>, <span class=\"string\">\"bbc\"</span>, <span class=\"string\">\"python\"</span>]</span><br><span class=\"line\">mixed_list = [<span class=\"string\">'python'</span>, <span class=\"string\">'java'</span>, 3, 12]</span><br><span class=\"line\"><span class=\"comment\">#访问列表中的值</span></span><br><span class=\"line\">second_num = number_list[1]</span><br><span class=\"line\">third_string = string_list[2]</span><br><span class=\"line\">fourth_mix = mixed_list[3]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"second_num: &#123;0&#125; third_string: &#123;1&#125; fourth_mix: &#123;2&#125;\"</span>.format(second_num, third_string, fourth_mix))</span><br><span class=\"line\"><span class=\"comment\">#更新列表</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"number_list before: \"</span> + str(number_list))</span><br><span class=\"line\">number_list[1] = 30</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"number_list after: \"</span> + str(number_list))</span><br><span class=\"line\"><span class=\"comment\">#删除列表元素</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"mixed_list before delete: \"</span> + str(mixed_list))</span><br><span class=\"line\">del mixed_list[2]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"mixed_list after delete: \"</span> + str(mixed_list))</span><br><span class=\"line\"><span class=\"comment\">#Python脚本语言</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(len([1,2,3])) <span class=\"comment\">#长度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>([1,2,3] + [4,5,6]) <span class=\"comment\">#组合</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>([<span class=\"string\">'Hello'</span>] * 4) <span class=\"comment\">#重复</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(3 <span class=\"keyword\">in</span> [1,2,3]) <span class=\"comment\">#某元素是否在列表中</span></span><br><span class=\"line\"><span class=\"comment\">#列表的截取</span></span><br><span class=\"line\">abcdlist=[<span class=\"string\">'a'</span>,<span class=\"string\">'b'</span>,<span class=\"string\">'c'</span>,<span class=\"string\">'d'</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(abcdlist[1])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(abcdlist[-2])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(abcdlist[1:])</span><br><span class=\"line\"><span class=\"comment\"># 列表操作包含以下函数:</span></span><br><span class=\"line\"><span class=\"comment\"># 1、cmp(list1, list2)：比较两个列表的元素 </span></span><br><span class=\"line\"><span class=\"comment\"># 2、len(list)：列表元素个数 </span></span><br><span class=\"line\"><span class=\"comment\"># 3、max(list)：返回列表元素最大值 </span></span><br><span class=\"line\"><span class=\"comment\"># 4、min(list)：返回列表元素最小值 </span></span><br><span class=\"line\"><span class=\"comment\"># 5、list(seq)：将元组转换为列表 </span></span><br><span class=\"line\"><span class=\"comment\"># 列表操作包含以下方法:</span></span><br><span class=\"line\"><span class=\"comment\"># 1、list.append(obj)：在列表末尾添加新的对象</span></span><br><span class=\"line\"><span class=\"comment\"># 2、list.count(obj)：统计某个元素在列表中出现的次数</span></span><br><span class=\"line\"><span class=\"comment\"># 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）</span></span><br><span class=\"line\"><span class=\"comment\"># 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置</span></span><br><span class=\"line\"><span class=\"comment\"># 5、list.insert(index, obj)：将对象插入列表</span></span><br><span class=\"line\"><span class=\"comment\"># 6、list.pop(obj=list[-1])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值</span></span><br><span class=\"line\"><span class=\"comment\"># 7、list.remove(obj)：移除列表中某个值的第一个匹配项</span></span><br><span class=\"line\"><span class=\"comment\"># 8、list.reverse()：反向列表中元素</span></span><br><span class=\"line\"><span class=\"comment\"># 9、list.sort([func])：对原列表进行排序</span></span><br></pre></td></tr></table></figure>\n</li>\n\n<p>结果<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">second_num: 3 third_string: python fourth_mix: 12</span><br><span class=\"line\">number_list before: [1, 3, 5, 7, 9]</span><br><span class=\"line\">number_list after: [1, 30, 5, 7, 9]</span><br><span class=\"line\">mixed_list before delete: [<span class=\"string\">'python'</span>, <span class=\"string\">'java'</span>, 3, 12]</span><br><span class=\"line\">mixed_list after delete: [<span class=\"string\">'python'</span>, <span class=\"string\">'java'</span>, 12]</span><br><span class=\"line\">3</span><br><span class=\"line\">[1, 2, 3, 4, 5, 6]</span><br><span class=\"line\">[<span class=\"string\">'Hello'</span>, <span class=\"string\">'Hello'</span>, <span class=\"string\">'Hello'</span>, <span class=\"string\">'Hello'</span>]</span><br><span class=\"line\">True</span><br><span class=\"line\">b</span><br><span class=\"line\">c</span><br><span class=\"line\">[<span class=\"string\">'b'</span>, <span class=\"string\">'c'</span>, <span class=\"string\">'d'</span>]</span><br></pre></td></tr></table></figure></p>"},{"title":"Python学习笔记（三）","date":"2017-06-23T01:11:37.000Z","comments":1,"reward":true,"_content":"1、元组（tuple）\n不可删除其中的元素可以整个删除，不可以更新，用（）创建，其余用法与list相同，有以下需要注意\n#创建只有一个元素的tuple，需要用逗号结尾消除歧义\na_tuple = (2,)\n#tuple中的list\nmixed_tuple = (1, 2, ['a', 'b'])\nprint(\"mixed_tuple: \" + str(mixed_tuple))\nmixed_tuple[2][0] = 'c'\nmixed_tuple[2][1] = 'd'\nprint(\"mixed_tuple: \" + str(mixed_tuple))\nTuple 是不可变 list。 一旦创建了一个 tuple 就不能以任何方式改变它。\n<!-- more -->\n2、Tuple 与 list 的相同之处\n定义 tuple 与定义 list 的方式相同, 除了整个元素集是用小括号包围的而不是方括号。\nTuple 的元素与 list 一样按定义的次序进行排序。 Tuples 的索引与 list 一样从 0 开始, 所以一个非空 tuple 的第一个元素总是 t[0]。\n负数索引与 list 一样从 tuple 的尾部开始计数。\n与 list 一样分片 (slice) 也可以使用。注意当分割一个 list 时, 会得到一个新的 list ；当分割一个 tuple 时, 会得到一个新的 tuple。\n3、Tuple 不存在的方法\n您不能向 tuple 增加元素。Tuple 没有 append 或 extend 方法。\n您不能从 tuple 删除元素。Tuple 没有 remove 或 pop 方法。\n然而, 您可以使用 in 来查看一个元素是否存在于 tuple 中。\n4、用 Tuple 的好处\nTuple 比 list 操作速度快。如果您定义了一个值的常量集，并且唯一要用它做的是不断地遍历它，请使用 tuple 代替 list。\n如果对不需要修改的数据进行 “写保护”，可以使代码更安全。使用 tuple 而不是 list 如同拥有一个隐含的 assert 语句，说明这一数据是常量。如果必须要改变这些值，则需要执行 tuple 到 list 的转换。\n5、Tuple 与 list 的转换\nTuple 可以转换成 list，反之亦然。内置的 tuple 函数接收一个 list，并返回一个有着相同元素的 tuple。而 list 函数接收一个 tuple 返回一个 list。从效果上看，tuple 冻结一个 list，而 list 解冻一个 tuple。\n6、Tuple 的其他应用\n一次赋多值\nv = ('a', 'b', 'e')\n(x, y, z) = v\n解释：v 是一个三元素的 tuple, 并且 (x, y, z) 是一个三变量的 tuple。将一个 tuple 赋值给另一个 tuple, 会按顺序将 v  的每个值赋值给每个变量。\n7、词典\n键(key)，对应值(value) \n``` bash\n直接给出代码\n# -*- coding: utf-8 -*-\n#创建一个词典\nphone_book = {'Tom': 123, \"Jerry\": 456, 'Kim': 789}\nmixed_dict = {\"Tom\": 'boy', 11: 23.5}\n#访问词典里的值\nprint(\"Tom's number is \" + str(phone_book['Tom']))\nprint('Tom is a ' + mixed_dict['Tom'])\n#修改词典\nphone_book['Tom'] = 999\nphone_book['Heath'] = 888\nprint(\"phone_book: \" + str(phone_book)) \nphone_book.update({'Ling':159, 'Lili':247})\nprint(\"updated phone_book: \" + str(phone_book)) \n#删除词典元素以及词典本身\ndel phone_book['Tom']\nprint(\"phone_book after deleting Tom: \" + str(phone_book)) \n#清空词典\nphone_book.clear()\nprint(\"after clear: \" + str(phone_book))\n#删除词典\ndel phone_book\n# print(\"after del: \" + str(phone_book))\n#不允许同一个键出现两次\nrep_test = {'Name': 'aa', 'age':5, 'Name': 'bb'}\nprint(\"rep_test: \" + str(rep_test))\n#键必须不可变，所以可以用书，字符串或者元组充当，列表不行\nlist_dict = {['Name']: 'John', 'Age':13}\nlist_dict = {('Name'): 'John', 'Age':13}\n# 字典内置函数&方法\n# Python字典包含了以下内置函数：\n# 1、cmp(dict1, dict2)：比较两个字典元素。\n# 2、len(dict)：计算字典元素个数，即键的总数。\n# 3、str(dict)：输出字典可打印的字符串表示。\n# 4、type(variable)：返回输入的变量类型，如果变量是字典就返回字典类型。\n# Python字典包含了以下内置方法：\n# 1、radiansdict.clear()：删除字典内所有元素\n# 2、radiansdict.copy()：返回一个字典的浅复制\n# 3、radiansdict.fromkeys()：创建一个新字典，以序列seq中元素做字典的键，val为字典所有键对应的初始值\n# 4、radiansdict.get(key, default=None)：返回指定键的值，如果值不在字典中返回default值\n# 5、radiansdict.has_key(key)：如果键在字典dict里返回true，否则返回false\n# 6、radiansdict.items()：以列表返回可遍历的(键, 值) 元组数组\n# 7、radiansdict.keys()：以列表返回一个字典所有的键\n# 8、radiansdict.setdefault(key, default=None)：和get()类似, 但如果键不已经存在于字典中，将会添加键并将值设为default\n# 9、radiansdict.update(dict2)：把字典dict2的键/值对更新到dict里\n# 10、radiansdict.values()：以列表返回字典中的所有值\n```\n结果\n``` bash\nTraceback (most recent call last):\n  File \"C:\\Users\\Administrator\\workspace\\TeachingPython\\TestBuildinPack.py\", line 27, in <module>\n    list_dict = {['Name']: 'John', 'Age':13}\nTypeError: unhashable type: 'list'\nTom's number is 123\nTom is a boy\nphone_book: {'Tom': 999, 'Jerry': 456, 'Kim': 789, 'Heath': 888}\nupdated phone_book: {'Tom': 999, 'Jerry': 456, 'Kim': 789, 'Heath': 888, 'Ling': 159, 'Lili': 247}\nphone_book after deleting Tom: {'Jerry': 456, 'Kim': 789, 'Heath': 888, 'Ling': 159, 'Lili': 247}\nafter clear: {}\nrep_test: {'Name': 'bb', 'age': 5}\n```\nPS:此处error是因为list_dict = {['Name']: 'John', 'Age':13}引起，key的值应该为常量 而list是变量所以提示TypeError 将list换为tuple就没有报错","source":"_posts/2017-6-23-one.md","raw":"---\ntitle: Python学习笔记（三）\ndate: 2017-06-23 09:11:37\ncomments: true\nreward: true\ntags: \n - python\n---\n1、元组（tuple）\n不可删除其中的元素可以整个删除，不可以更新，用（）创建，其余用法与list相同，有以下需要注意\n#创建只有一个元素的tuple，需要用逗号结尾消除歧义\na_tuple = (2,)\n#tuple中的list\nmixed_tuple = (1, 2, ['a', 'b'])\nprint(\"mixed_tuple: \" + str(mixed_tuple))\nmixed_tuple[2][0] = 'c'\nmixed_tuple[2][1] = 'd'\nprint(\"mixed_tuple: \" + str(mixed_tuple))\nTuple 是不可变 list。 一旦创建了一个 tuple 就不能以任何方式改变它。\n<!-- more -->\n2、Tuple 与 list 的相同之处\n定义 tuple 与定义 list 的方式相同, 除了整个元素集是用小括号包围的而不是方括号。\nTuple 的元素与 list 一样按定义的次序进行排序。 Tuples 的索引与 list 一样从 0 开始, 所以一个非空 tuple 的第一个元素总是 t[0]。\n负数索引与 list 一样从 tuple 的尾部开始计数。\n与 list 一样分片 (slice) 也可以使用。注意当分割一个 list 时, 会得到一个新的 list ；当分割一个 tuple 时, 会得到一个新的 tuple。\n3、Tuple 不存在的方法\n您不能向 tuple 增加元素。Tuple 没有 append 或 extend 方法。\n您不能从 tuple 删除元素。Tuple 没有 remove 或 pop 方法。\n然而, 您可以使用 in 来查看一个元素是否存在于 tuple 中。\n4、用 Tuple 的好处\nTuple 比 list 操作速度快。如果您定义了一个值的常量集，并且唯一要用它做的是不断地遍历它，请使用 tuple 代替 list。\n如果对不需要修改的数据进行 “写保护”，可以使代码更安全。使用 tuple 而不是 list 如同拥有一个隐含的 assert 语句，说明这一数据是常量。如果必须要改变这些值，则需要执行 tuple 到 list 的转换。\n5、Tuple 与 list 的转换\nTuple 可以转换成 list，反之亦然。内置的 tuple 函数接收一个 list，并返回一个有着相同元素的 tuple。而 list 函数接收一个 tuple 返回一个 list。从效果上看，tuple 冻结一个 list，而 list 解冻一个 tuple。\n6、Tuple 的其他应用\n一次赋多值\nv = ('a', 'b', 'e')\n(x, y, z) = v\n解释：v 是一个三元素的 tuple, 并且 (x, y, z) 是一个三变量的 tuple。将一个 tuple 赋值给另一个 tuple, 会按顺序将 v  的每个值赋值给每个变量。\n7、词典\n键(key)，对应值(value) \n``` bash\n直接给出代码\n# -*- coding: utf-8 -*-\n#创建一个词典\nphone_book = {'Tom': 123, \"Jerry\": 456, 'Kim': 789}\nmixed_dict = {\"Tom\": 'boy', 11: 23.5}\n#访问词典里的值\nprint(\"Tom's number is \" + str(phone_book['Tom']))\nprint('Tom is a ' + mixed_dict['Tom'])\n#修改词典\nphone_book['Tom'] = 999\nphone_book['Heath'] = 888\nprint(\"phone_book: \" + str(phone_book)) \nphone_book.update({'Ling':159, 'Lili':247})\nprint(\"updated phone_book: \" + str(phone_book)) \n#删除词典元素以及词典本身\ndel phone_book['Tom']\nprint(\"phone_book after deleting Tom: \" + str(phone_book)) \n#清空词典\nphone_book.clear()\nprint(\"after clear: \" + str(phone_book))\n#删除词典\ndel phone_book\n# print(\"after del: \" + str(phone_book))\n#不允许同一个键出现两次\nrep_test = {'Name': 'aa', 'age':5, 'Name': 'bb'}\nprint(\"rep_test: \" + str(rep_test))\n#键必须不可变，所以可以用书，字符串或者元组充当，列表不行\nlist_dict = {['Name']: 'John', 'Age':13}\nlist_dict = {('Name'): 'John', 'Age':13}\n# 字典内置函数&方法\n# Python字典包含了以下内置函数：\n# 1、cmp(dict1, dict2)：比较两个字典元素。\n# 2、len(dict)：计算字典元素个数，即键的总数。\n# 3、str(dict)：输出字典可打印的字符串表示。\n# 4、type(variable)：返回输入的变量类型，如果变量是字典就返回字典类型。\n# Python字典包含了以下内置方法：\n# 1、radiansdict.clear()：删除字典内所有元素\n# 2、radiansdict.copy()：返回一个字典的浅复制\n# 3、radiansdict.fromkeys()：创建一个新字典，以序列seq中元素做字典的键，val为字典所有键对应的初始值\n# 4、radiansdict.get(key, default=None)：返回指定键的值，如果值不在字典中返回default值\n# 5、radiansdict.has_key(key)：如果键在字典dict里返回true，否则返回false\n# 6、radiansdict.items()：以列表返回可遍历的(键, 值) 元组数组\n# 7、radiansdict.keys()：以列表返回一个字典所有的键\n# 8、radiansdict.setdefault(key, default=None)：和get()类似, 但如果键不已经存在于字典中，将会添加键并将值设为default\n# 9、radiansdict.update(dict2)：把字典dict2的键/值对更新到dict里\n# 10、radiansdict.values()：以列表返回字典中的所有值\n```\n结果\n``` bash\nTraceback (most recent call last):\n  File \"C:\\Users\\Administrator\\workspace\\TeachingPython\\TestBuildinPack.py\", line 27, in <module>\n    list_dict = {['Name']: 'John', 'Age':13}\nTypeError: unhashable type: 'list'\nTom's number is 123\nTom is a boy\nphone_book: {'Tom': 999, 'Jerry': 456, 'Kim': 789, 'Heath': 888}\nupdated phone_book: {'Tom': 999, 'Jerry': 456, 'Kim': 789, 'Heath': 888, 'Ling': 159, 'Lili': 247}\nphone_book after deleting Tom: {'Jerry': 456, 'Kim': 789, 'Heath': 888, 'Ling': 159, 'Lili': 247}\nafter clear: {}\nrep_test: {'Name': 'bb', 'age': 5}\n```\nPS:此处error是因为list_dict = {['Name']: 'John', 'Age':13}引起，key的值应该为常量 而list是变量所以提示TypeError 将list换为tuple就没有报错","slug":"2017-6-23-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2j000eycvji2660wyi","content":"<p>1、元组（tuple）<br>不可删除其中的元素可以整个删除，不可以更新，用（）创建，其余用法与list相同，有以下需要注意</p>\n<p>#创建只有一个元素的tuple，需要用逗号结尾消除歧义<br>a_tuple = (2,)</p>\n<p>#tuple中的list<br>mixed_tuple = (1, 2, [‘a’, ‘b’])<br>print(“mixed_tuple: “ + str(mixed_tuple))<br>mixed_tuple[2][0] = ‘c’<br>mixed_tuple[2][1] = ‘d’<br>print(“mixed_tuple: “ + str(mixed_tuple))<br>Tuple 是不可变 list。 一旦创建了一个 tuple 就不能以任何方式改变它。<br><a id=\"more\"></a><br>2、Tuple 与 list 的相同之处<br>定义 tuple 与定义 list 的方式相同, 除了整个元素集是用小括号包围的而不是方括号。<br>Tuple 的元素与 list 一样按定义的次序进行排序。 Tuples 的索引与 list 一样从 0 开始, 所以一个非空 tuple 的第一个元素总是 t[0]。<br>负数索引与 list 一样从 tuple 的尾部开始计数。<br>与 list 一样分片 (slice) 也可以使用。注意当分割一个 list 时, 会得到一个新的 list ；当分割一个 tuple 时, 会得到一个新的 tuple。<br>3、Tuple 不存在的方法<br>您不能向 tuple 增加元素。Tuple 没有 append 或 extend 方法。<br>您不能从 tuple 删除元素。Tuple 没有 remove 或 pop 方法。<br>然而, 您可以使用 in 来查看一个元素是否存在于 tuple 中。<br>4、用 Tuple 的好处<br>Tuple 比 list 操作速度快。如果您定义了一个值的常量集，并且唯一要用它做的是不断地遍历它，请使用 tuple 代替 list。<br>如果对不需要修改的数据进行 “写保护”，可以使代码更安全。使用 tuple 而不是 list 如同拥有一个隐含的 assert 语句，说明这一数据是常量。如果必须要改变这些值，则需要执行 tuple 到 list 的转换。<br>5、Tuple 与 list 的转换<br>Tuple 可以转换成 list，反之亦然。内置的 tuple 函数接收一个 list，并返回一个有着相同元素的 tuple。而 list 函数接收一个 tuple 返回一个 list。从效果上看，tuple 冻结一个 list，而 list 解冻一个 tuple。<br>6、Tuple 的其他应用<br>一次赋多值<br>v = (‘a’, ‘b’, ‘e’)<br>(x, y, z) = v<br>解释：v 是一个三元素的 tuple, 并且 (x, y, z) 是一个三变量的 tuple。将一个 tuple 赋值给另一个 tuple, 会按顺序将 v  的每个值赋值给每个变量。<br>7、词典<br>键(key)，对应值(value)<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">直接给出代码</span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\">#创建一个词典</span></span><br><span class=\"line\">phone_book = &#123;<span class=\"string\">'Tom'</span>: 123, <span class=\"string\">\"Jerry\"</span>: 456, <span class=\"string\">'Kim'</span>: 789&#125;</span><br><span class=\"line\">mixed_dict = &#123;<span class=\"string\">\"Tom\"</span>: <span class=\"string\">'boy'</span>, 11: 23.5&#125;</span><br><span class=\"line\"><span class=\"comment\">#访问词典里的值</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Tom's number is \"</span> + str(phone_book[<span class=\"string\">'Tom'</span>]))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Tom is a '</span> + mixed_dict[<span class=\"string\">'Tom'</span>])</span><br><span class=\"line\"><span class=\"comment\">#修改词典</span></span><br><span class=\"line\">phone_book[<span class=\"string\">'Tom'</span>] = 999</span><br><span class=\"line\">phone_book[<span class=\"string\">'Heath'</span>] = 888</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"phone_book: \"</span> + str(phone_book)) </span><br><span class=\"line\">phone_book.update(&#123;<span class=\"string\">'Ling'</span>:159, <span class=\"string\">'Lili'</span>:247&#125;)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"updated phone_book: \"</span> + str(phone_book)) </span><br><span class=\"line\"><span class=\"comment\">#删除词典元素以及词典本身</span></span><br><span class=\"line\">del phone_book[<span class=\"string\">'Tom'</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"phone_book after deleting Tom: \"</span> + str(phone_book)) </span><br><span class=\"line\"><span class=\"comment\">#清空词典</span></span><br><span class=\"line\">phone_book.clear()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"after clear: \"</span> + str(phone_book))</span><br><span class=\"line\"><span class=\"comment\">#删除词典</span></span><br><span class=\"line\">del phone_book</span><br><span class=\"line\"><span class=\"comment\"># print(\"after del: \" + str(phone_book))</span></span><br><span class=\"line\"><span class=\"comment\">#不允许同一个键出现两次</span></span><br><span class=\"line\">rep_test = &#123;<span class=\"string\">'Name'</span>: <span class=\"string\">'aa'</span>, <span class=\"string\">'age'</span>:5, <span class=\"string\">'Name'</span>: <span class=\"string\">'bb'</span>&#125;</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"rep_test: \"</span> + str(rep_test))</span><br><span class=\"line\"><span class=\"comment\">#键必须不可变，所以可以用书，字符串或者元组充当，列表不行</span></span><br><span class=\"line\">list_dict = &#123;[<span class=\"string\">'Name'</span>]: <span class=\"string\">'John'</span>, <span class=\"string\">'Age'</span>:13&#125;</span><br><span class=\"line\">list_dict = &#123;(<span class=\"string\">'Name'</span>): <span class=\"string\">'John'</span>, <span class=\"string\">'Age'</span>:13&#125;</span><br><span class=\"line\"><span class=\"comment\"># 字典内置函数&amp;方法</span></span><br><span class=\"line\"><span class=\"comment\"># Python字典包含了以下内置函数：</span></span><br><span class=\"line\"><span class=\"comment\"># 1、cmp(dict1, dict2)：比较两个字典元素。</span></span><br><span class=\"line\"><span class=\"comment\"># 2、len(dict)：计算字典元素个数，即键的总数。</span></span><br><span class=\"line\"><span class=\"comment\"># 3、str(dict)：输出字典可打印的字符串表示。</span></span><br><span class=\"line\"><span class=\"comment\"># 4、type(variable)：返回输入的变量类型，如果变量是字典就返回字典类型。</span></span><br><span class=\"line\"><span class=\"comment\"># Python字典包含了以下内置方法：</span></span><br><span class=\"line\"><span class=\"comment\"># 1、radiansdict.clear()：删除字典内所有元素</span></span><br><span class=\"line\"><span class=\"comment\"># 2、radiansdict.copy()：返回一个字典的浅复制</span></span><br><span class=\"line\"><span class=\"comment\"># 3、radiansdict.fromkeys()：创建一个新字典，以序列seq中元素做字典的键，val为字典所有键对应的初始值</span></span><br><span class=\"line\"><span class=\"comment\"># 4、radiansdict.get(key, default=None)：返回指定键的值，如果值不在字典中返回default值</span></span><br><span class=\"line\"><span class=\"comment\"># 5、radiansdict.has_key(key)：如果键在字典dict里返回true，否则返回false</span></span><br><span class=\"line\"><span class=\"comment\"># 6、radiansdict.items()：以列表返回可遍历的(键, 值) 元组数组</span></span><br><span class=\"line\"><span class=\"comment\"># 7、radiansdict.keys()：以列表返回一个字典所有的键</span></span><br><span class=\"line\"><span class=\"comment\"># 8、radiansdict.setdefault(key, default=None)：和get()类似, 但如果键不已经存在于字典中，将会添加键并将值设为default</span></span><br><span class=\"line\"><span class=\"comment\"># 9、radiansdict.update(dict2)：把字典dict2的键/值对更新到dict里</span></span><br><span class=\"line\"><span class=\"comment\"># 10、radiansdict.values()：以列表返回字典中的所有值</span></span><br></pre></td></tr></table></figure></p>\n<p>结果<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"C:\\Users\\Administrator\\workspace\\TeachingPython\\TestBuildinPack.py\"</span>, line 27, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    list_dict = &#123;[<span class=\"string\">'Name'</span>]: <span class=\"string\">'John'</span>, <span class=\"string\">'Age'</span>:13&#125;</span><br><span class=\"line\">TypeError: unhashable <span class=\"built_in\">type</span>: <span class=\"string\">'list'</span></span><br><span class=\"line\">Tom<span class=\"string\">'s number is 123</span></span><br><span class=\"line\"><span class=\"string\">Tom is a boy</span></span><br><span class=\"line\"><span class=\"string\">phone_book: &#123;'</span>Tom<span class=\"string\">': 999, '</span>Jerry<span class=\"string\">': 456, '</span>Kim<span class=\"string\">': 789, '</span>Heath<span class=\"string\">': 888&#125;</span></span><br><span class=\"line\"><span class=\"string\">updated phone_book: &#123;'</span>Tom<span class=\"string\">': 999, '</span>Jerry<span class=\"string\">': 456, '</span>Kim<span class=\"string\">': 789, '</span>Heath<span class=\"string\">': 888, '</span>Ling<span class=\"string\">': 159, '</span>Lili<span class=\"string\">': 247&#125;</span></span><br><span class=\"line\"><span class=\"string\">phone_book after deleting Tom: &#123;'</span>Jerry<span class=\"string\">': 456, '</span>Kim<span class=\"string\">': 789, '</span>Heath<span class=\"string\">': 888, '</span>Ling<span class=\"string\">': 159, '</span>Lili<span class=\"string\">': 247&#125;</span></span><br><span class=\"line\"><span class=\"string\">after clear: &#123;&#125;</span></span><br><span class=\"line\"><span class=\"string\">rep_test: &#123;'</span>Name<span class=\"string\">': '</span>bb<span class=\"string\">', '</span>age<span class=\"string\">': 5&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>PS:此处error是因为list_dict = {[‘Name’]: ‘John’, ‘Age’:13}引起，key的值应该为常量 而list是变量所以提示TypeError 将list换为tuple就没有报错</p>\n","site":{"data":{}},"excerpt":"<p>1、元组（tuple）<br>不可删除其中的元素可以整个删除，不可以更新，用（）创建，其余用法与list相同，有以下需要注意</p>\n<p>#创建只有一个元素的tuple，需要用逗号结尾消除歧义<br>a_tuple = (2,)</p>\n<p>#tuple中的list<br>mixed_tuple = (1, 2, [‘a’, ‘b’])<br>print(“mixed_tuple: “ + str(mixed_tuple))<br>mixed_tuple[2][0] = ‘c’<br>mixed_tuple[2][1] = ‘d’<br>print(“mixed_tuple: “ + str(mixed_tuple))<br>Tuple 是不可变 list。 一旦创建了一个 tuple 就不能以任何方式改变它。<br></p>","more":"<br>2、Tuple 与 list 的相同之处<br>定义 tuple 与定义 list 的方式相同, 除了整个元素集是用小括号包围的而不是方括号。<br>Tuple 的元素与 list 一样按定义的次序进行排序。 Tuples 的索引与 list 一样从 0 开始, 所以一个非空 tuple 的第一个元素总是 t[0]。<br>负数索引与 list 一样从 tuple 的尾部开始计数。<br>与 list 一样分片 (slice) 也可以使用。注意当分割一个 list 时, 会得到一个新的 list ；当分割一个 tuple 时, 会得到一个新的 tuple。<br>3、Tuple 不存在的方法<br>您不能向 tuple 增加元素。Tuple 没有 append 或 extend 方法。<br>您不能从 tuple 删除元素。Tuple 没有 remove 或 pop 方法。<br>然而, 您可以使用 in 来查看一个元素是否存在于 tuple 中。<br>4、用 Tuple 的好处<br>Tuple 比 list 操作速度快。如果您定义了一个值的常量集，并且唯一要用它做的是不断地遍历它，请使用 tuple 代替 list。<br>如果对不需要修改的数据进行 “写保护”，可以使代码更安全。使用 tuple 而不是 list 如同拥有一个隐含的 assert 语句，说明这一数据是常量。如果必须要改变这些值，则需要执行 tuple 到 list 的转换。<br>5、Tuple 与 list 的转换<br>Tuple 可以转换成 list，反之亦然。内置的 tuple 函数接收一个 list，并返回一个有着相同元素的 tuple。而 list 函数接收一个 tuple 返回一个 list。从效果上看，tuple 冻结一个 list，而 list 解冻一个 tuple。<br>6、Tuple 的其他应用<br>一次赋多值<br>v = (‘a’, ‘b’, ‘e’)<br>(x, y, z) = v<br>解释：v 是一个三元素的 tuple, 并且 (x, y, z) 是一个三变量的 tuple。将一个 tuple 赋值给另一个 tuple, 会按顺序将 v  的每个值赋值给每个变量。<br>7、词典<br>键(key)，对应值(value)<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">直接给出代码</span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\">#创建一个词典</span></span><br><span class=\"line\">phone_book = &#123;<span class=\"string\">'Tom'</span>: 123, <span class=\"string\">\"Jerry\"</span>: 456, <span class=\"string\">'Kim'</span>: 789&#125;</span><br><span class=\"line\">mixed_dict = &#123;<span class=\"string\">\"Tom\"</span>: <span class=\"string\">'boy'</span>, 11: 23.5&#125;</span><br><span class=\"line\"><span class=\"comment\">#访问词典里的值</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Tom's number is \"</span> + str(phone_book[<span class=\"string\">'Tom'</span>]))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Tom is a '</span> + mixed_dict[<span class=\"string\">'Tom'</span>])</span><br><span class=\"line\"><span class=\"comment\">#修改词典</span></span><br><span class=\"line\">phone_book[<span class=\"string\">'Tom'</span>] = 999</span><br><span class=\"line\">phone_book[<span class=\"string\">'Heath'</span>] = 888</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"phone_book: \"</span> + str(phone_book)) </span><br><span class=\"line\">phone_book.update(&#123;<span class=\"string\">'Ling'</span>:159, <span class=\"string\">'Lili'</span>:247&#125;)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"updated phone_book: \"</span> + str(phone_book)) </span><br><span class=\"line\"><span class=\"comment\">#删除词典元素以及词典本身</span></span><br><span class=\"line\">del phone_book[<span class=\"string\">'Tom'</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"phone_book after deleting Tom: \"</span> + str(phone_book)) </span><br><span class=\"line\"><span class=\"comment\">#清空词典</span></span><br><span class=\"line\">phone_book.clear()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"after clear: \"</span> + str(phone_book))</span><br><span class=\"line\"><span class=\"comment\">#删除词典</span></span><br><span class=\"line\">del phone_book</span><br><span class=\"line\"><span class=\"comment\"># print(\"after del: \" + str(phone_book))</span></span><br><span class=\"line\"><span class=\"comment\">#不允许同一个键出现两次</span></span><br><span class=\"line\">rep_test = &#123;<span class=\"string\">'Name'</span>: <span class=\"string\">'aa'</span>, <span class=\"string\">'age'</span>:5, <span class=\"string\">'Name'</span>: <span class=\"string\">'bb'</span>&#125;</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"rep_test: \"</span> + str(rep_test))</span><br><span class=\"line\"><span class=\"comment\">#键必须不可变，所以可以用书，字符串或者元组充当，列表不行</span></span><br><span class=\"line\">list_dict = &#123;[<span class=\"string\">'Name'</span>]: <span class=\"string\">'John'</span>, <span class=\"string\">'Age'</span>:13&#125;</span><br><span class=\"line\">list_dict = &#123;(<span class=\"string\">'Name'</span>): <span class=\"string\">'John'</span>, <span class=\"string\">'Age'</span>:13&#125;</span><br><span class=\"line\"><span class=\"comment\"># 字典内置函数&amp;方法</span></span><br><span class=\"line\"><span class=\"comment\"># Python字典包含了以下内置函数：</span></span><br><span class=\"line\"><span class=\"comment\"># 1、cmp(dict1, dict2)：比较两个字典元素。</span></span><br><span class=\"line\"><span class=\"comment\"># 2、len(dict)：计算字典元素个数，即键的总数。</span></span><br><span class=\"line\"><span class=\"comment\"># 3、str(dict)：输出字典可打印的字符串表示。</span></span><br><span class=\"line\"><span class=\"comment\"># 4、type(variable)：返回输入的变量类型，如果变量是字典就返回字典类型。</span></span><br><span class=\"line\"><span class=\"comment\"># Python字典包含了以下内置方法：</span></span><br><span class=\"line\"><span class=\"comment\"># 1、radiansdict.clear()：删除字典内所有元素</span></span><br><span class=\"line\"><span class=\"comment\"># 2、radiansdict.copy()：返回一个字典的浅复制</span></span><br><span class=\"line\"><span class=\"comment\"># 3、radiansdict.fromkeys()：创建一个新字典，以序列seq中元素做字典的键，val为字典所有键对应的初始值</span></span><br><span class=\"line\"><span class=\"comment\"># 4、radiansdict.get(key, default=None)：返回指定键的值，如果值不在字典中返回default值</span></span><br><span class=\"line\"><span class=\"comment\"># 5、radiansdict.has_key(key)：如果键在字典dict里返回true，否则返回false</span></span><br><span class=\"line\"><span class=\"comment\"># 6、radiansdict.items()：以列表返回可遍历的(键, 值) 元组数组</span></span><br><span class=\"line\"><span class=\"comment\"># 7、radiansdict.keys()：以列表返回一个字典所有的键</span></span><br><span class=\"line\"><span class=\"comment\"># 8、radiansdict.setdefault(key, default=None)：和get()类似, 但如果键不已经存在于字典中，将会添加键并将值设为default</span></span><br><span class=\"line\"><span class=\"comment\"># 9、radiansdict.update(dict2)：把字典dict2的键/值对更新到dict里</span></span><br><span class=\"line\"><span class=\"comment\"># 10、radiansdict.values()：以列表返回字典中的所有值</span></span><br></pre></td></tr></table></figure><p></p>\n<p>结果<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">\"C:\\Users\\Administrator\\workspace\\TeachingPython\\TestBuildinPack.py\"</span>, line 27, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    list_dict = &#123;[<span class=\"string\">'Name'</span>]: <span class=\"string\">'John'</span>, <span class=\"string\">'Age'</span>:13&#125;</span><br><span class=\"line\">TypeError: unhashable <span class=\"built_in\">type</span>: <span class=\"string\">'list'</span></span><br><span class=\"line\">Tom<span class=\"string\">'s number is 123</span></span><br><span class=\"line\"><span class=\"string\">Tom is a boy</span></span><br><span class=\"line\"><span class=\"string\">phone_book: &#123;'</span>Tom<span class=\"string\">': 999, '</span>Jerry<span class=\"string\">': 456, '</span>Kim<span class=\"string\">': 789, '</span>Heath<span class=\"string\">': 888&#125;</span></span><br><span class=\"line\"><span class=\"string\">updated phone_book: &#123;'</span>Tom<span class=\"string\">': 999, '</span>Jerry<span class=\"string\">': 456, '</span>Kim<span class=\"string\">': 789, '</span>Heath<span class=\"string\">': 888, '</span>Ling<span class=\"string\">': 159, '</span>Lili<span class=\"string\">': 247&#125;</span></span><br><span class=\"line\"><span class=\"string\">phone_book after deleting Tom: &#123;'</span>Jerry<span class=\"string\">': 456, '</span>Kim<span class=\"string\">': 789, '</span>Heath<span class=\"string\">': 888, '</span>Ling<span class=\"string\">': 159, '</span>Lili<span class=\"string\">': 247&#125;</span></span><br><span class=\"line\"><span class=\"string\">after clear: &#123;&#125;</span></span><br><span class=\"line\"><span class=\"string\">rep_test: &#123;'</span>Name<span class=\"string\">': '</span>bb<span class=\"string\">', '</span>age<span class=\"string\">': 5&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>PS:此处error是因为list_dict = {[‘Name’]: ‘John’, ‘Age’:13}引起，key的值应该为常量 而list是变量所以提示TypeError 将list换为tuple就没有报错</p>"},{"title":"Python学习笔记（四）","date":"2017-06-23T13:29:41.000Z","comments":1,"reward":true,"_content":"函数：程序中可重复使用的程序段 \n给一段程程序起一个名字，用这个名字来执行一段程序，反复使用 （调用函数）\n用关键字 ‘def' 来定义，identifier(参数)\nidentifier \n参数list\nreturn statement\n局部变量 vs 全局变量\n<!-- more -->\n``` bash\n#-*- coding: utf-8 -*-\n#没有参数和返回的函数\n# def say_hi():\n#     print(\" hi!\")\n#     \n# say_hi()\n# say_hi()\n#    \n#    \n#有参数，无返回值\n# def print_sum_two(a, b):\n#     c = a + b\n#     print(c)\n#     \n# print_sum_two(3, 6)\n    \n# def hello_some(str):\n#     print(\"hello \" + str + \"!\")\n#         \n# hello_some(\"China\")\n# hello_some(\"Python\")\n \n#有参数，有返回值\n# def repeat_str(str, times):\n#     repeated_strs = str * times\n#     return repeated_strs\n# \n# \n# repeated_strings = repeat_str(\"Happy Birthday!\", 4)\n# print(repeated_strings)\n   \n#全局变量与局部 变量\n# x = 60\n# \n# def foo(x):\n#     print(\"x is: \" + str(x))\n#     x = 3\n#     print(\"change local x to \" + str(x))\n# \n# foo(x)\n# print('x is still', str(x))\nx = 60\ndef foo():\n    global x\n    print(\"x is: \" + str(x))\n    x = 3\n    print(\"change local x to \" + str(x))\nfoo()\nprint('value of x is' , str(x))\n```\n默认参数\n关键字参数\nVarArgs参数\n``` bash\n#-*- coding: utf-8 -*-\n# 默认参数\ndef repeat_str(s, times = 1):\n    repeated_strs = s * times\n    return repeated_strs\nrepeated_strings = repeat_str(\"Happy Birthday!\")\nprint(repeated_strings)\nrepeated_strings_2 = repeat_str(\"Happy Birthday!\" , 4)\nprint(repeated_strings_2)\n#不能在有默认参数后面跟随没有默认参数\n#f(a, b =2)合法\n#f(a = 2, b)非法\n#关键字参数: 调用函数时，选择性的传入部分参数\ndef func(a, b = 4, c = 8):\n    print('a is', a, 'and b is', b, 'and c is', c)\nfunc(13, 17)\nfunc(125, c = 24)\nfunc(c = 40, a = 80)\n#VarArgs参数\ndef print_paras(fpara, *nums, **words):\n    print(\"fpara: \" + str(fpara))\n    print(\"nums: \" + str(nums))\n    print(\"words: \" + str(words))  \nprint_paras(\"hello\", 1, 3, 5, 7, word = \"python\", anohter_word = \"java\")\n```","source":"_posts/2017-6-23-three.md","raw":"---\ntitle: Python学习笔记（四）\ndate: 2017-06-23 21:29:41\ncomments: true\nreward: true\ntags: \n - python\n---\n函数：程序中可重复使用的程序段 \n给一段程程序起一个名字，用这个名字来执行一段程序，反复使用 （调用函数）\n用关键字 ‘def' 来定义，identifier(参数)\nidentifier \n参数list\nreturn statement\n局部变量 vs 全局变量\n<!-- more -->\n``` bash\n#-*- coding: utf-8 -*-\n#没有参数和返回的函数\n# def say_hi():\n#     print(\" hi!\")\n#     \n# say_hi()\n# say_hi()\n#    \n#    \n#有参数，无返回值\n# def print_sum_two(a, b):\n#     c = a + b\n#     print(c)\n#     \n# print_sum_two(3, 6)\n    \n# def hello_some(str):\n#     print(\"hello \" + str + \"!\")\n#         \n# hello_some(\"China\")\n# hello_some(\"Python\")\n \n#有参数，有返回值\n# def repeat_str(str, times):\n#     repeated_strs = str * times\n#     return repeated_strs\n# \n# \n# repeated_strings = repeat_str(\"Happy Birthday!\", 4)\n# print(repeated_strings)\n   \n#全局变量与局部 变量\n# x = 60\n# \n# def foo(x):\n#     print(\"x is: \" + str(x))\n#     x = 3\n#     print(\"change local x to \" + str(x))\n# \n# foo(x)\n# print('x is still', str(x))\nx = 60\ndef foo():\n    global x\n    print(\"x is: \" + str(x))\n    x = 3\n    print(\"change local x to \" + str(x))\nfoo()\nprint('value of x is' , str(x))\n```\n默认参数\n关键字参数\nVarArgs参数\n``` bash\n#-*- coding: utf-8 -*-\n# 默认参数\ndef repeat_str(s, times = 1):\n    repeated_strs = s * times\n    return repeated_strs\nrepeated_strings = repeat_str(\"Happy Birthday!\")\nprint(repeated_strings)\nrepeated_strings_2 = repeat_str(\"Happy Birthday!\" , 4)\nprint(repeated_strings_2)\n#不能在有默认参数后面跟随没有默认参数\n#f(a, b =2)合法\n#f(a = 2, b)非法\n#关键字参数: 调用函数时，选择性的传入部分参数\ndef func(a, b = 4, c = 8):\n    print('a is', a, 'and b is', b, 'and c is', c)\nfunc(13, 17)\nfunc(125, c = 24)\nfunc(c = 40, a = 80)\n#VarArgs参数\ndef print_paras(fpara, *nums, **words):\n    print(\"fpara: \" + str(fpara))\n    print(\"nums: \" + str(nums))\n    print(\"words: \" + str(words))  \nprint_paras(\"hello\", 1, 3, 5, 7, word = \"python\", anohter_word = \"java\")\n```","slug":"2017-6-23-three","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2l000hycvjl31aoihz","content":"<p>函数：程序中可重复使用的程序段<br>给一段程程序起一个名字，用这个名字来执行一段程序，反复使用 （调用函数）<br>用关键字 ‘def’ 来定义，identifier(参数)<br>identifier<br>参数list<br>return statement<br>局部变量 vs 全局变量<br><a id=\"more\"></a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#-*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\">#没有参数和返回的函数</span></span><br><span class=\"line\"><span class=\"comment\"># def say_hi():</span></span><br><span class=\"line\"><span class=\"comment\">#     print(\" hi!\")</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># say_hi()</span></span><br><span class=\"line\"><span class=\"comment\"># say_hi()</span></span><br><span class=\"line\"><span class=\"comment\">#    </span></span><br><span class=\"line\"><span class=\"comment\">#    </span></span><br><span class=\"line\"><span class=\"comment\">#有参数，无返回值</span></span><br><span class=\"line\"><span class=\"comment\"># def print_sum_two(a, b):</span></span><br><span class=\"line\"><span class=\"comment\">#     c = a + b</span></span><br><span class=\"line\"><span class=\"comment\">#     print(c)</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># print_sum_two(3, 6)</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># def hello_some(str):</span></span><br><span class=\"line\"><span class=\"comment\">#     print(\"hello \" + str + \"!\")</span></span><br><span class=\"line\"><span class=\"comment\">#         </span></span><br><span class=\"line\"><span class=\"comment\"># hello_some(\"China\")</span></span><br><span class=\"line\"><span class=\"comment\"># hello_some(\"Python\")</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">#有参数，有返回值</span></span><br><span class=\"line\"><span class=\"comment\"># def repeat_str(str, times):</span></span><br><span class=\"line\"><span class=\"comment\">#     repeated_strs = str * times</span></span><br><span class=\"line\"><span class=\"comment\">#     return repeated_strs</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># repeated_strings = repeat_str(\"Happy Birthday!\", 4)</span></span><br><span class=\"line\"><span class=\"comment\"># print(repeated_strings)</span></span><br><span class=\"line\">   </span><br><span class=\"line\"><span class=\"comment\">#全局变量与局部 变量</span></span><br><span class=\"line\"><span class=\"comment\"># x = 60</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># def foo(x):</span></span><br><span class=\"line\"><span class=\"comment\">#     print(\"x is: \" + str(x))</span></span><br><span class=\"line\"><span class=\"comment\">#     x = 3</span></span><br><span class=\"line\"><span class=\"comment\">#     print(\"change local x to \" + str(x))</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># foo(x)</span></span><br><span class=\"line\"><span class=\"comment\"># print('x is still', str(x))</span></span><br><span class=\"line\">x = 60</span><br><span class=\"line\">def foo():</span><br><span class=\"line\">    global x</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"x is: \"</span> + str(x))</span><br><span class=\"line\">    x = 3</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"change local x to \"</span> + str(x))</span><br><span class=\"line\">foo()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'value of x is'</span> , str(x))</span><br></pre></td></tr></table></figure></p>\n<p>默认参数<br>关键字参数<br>VarArgs参数<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#-*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># 默认参数</span></span><br><span class=\"line\">def repeat_str(s, <span class=\"built_in\">times</span> = 1):</span><br><span class=\"line\">    repeated_strs = s * <span class=\"built_in\">times</span></span><br><span class=\"line\">    <span class=\"built_in\">return</span> repeated_strs</span><br><span class=\"line\">repeated_strings = repeat_str(<span class=\"string\">\"Happy Birthday!\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(repeated_strings)</span><br><span class=\"line\">repeated_strings_2 = repeat_str(<span class=\"string\">\"Happy Birthday!\"</span> , 4)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(repeated_strings_2)</span><br><span class=\"line\"><span class=\"comment\">#不能在有默认参数后面跟随没有默认参数</span></span><br><span class=\"line\"><span class=\"comment\">#f(a, b =2)合法</span></span><br><span class=\"line\"><span class=\"comment\">#f(a = 2, b)非法</span></span><br><span class=\"line\"><span class=\"comment\">#关键字参数: 调用函数时，选择性的传入部分参数</span></span><br><span class=\"line\">def func(a, b = 4, c = 8):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">'a is'</span>, a, <span class=\"string\">'and b is'</span>, b, <span class=\"string\">'and c is'</span>, c)</span><br><span class=\"line\">func(13, 17)</span><br><span class=\"line\">func(125, c = 24)</span><br><span class=\"line\">func(c = 40, a = 80)</span><br><span class=\"line\"><span class=\"comment\">#VarArgs参数</span></span><br><span class=\"line\">def print_paras(fpara, *nums, **words):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"fpara: \"</span> + str(fpara))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"nums: \"</span> + str(nums))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"words: \"</span> + str(words))  </span><br><span class=\"line\">print_paras(<span class=\"string\">\"hello\"</span>, 1, 3, 5, 7, word = <span class=\"string\">\"python\"</span>, anohter_word = <span class=\"string\">\"java\"</span>)</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>函数：程序中可重复使用的程序段<br>给一段程程序起一个名字，用这个名字来执行一段程序，反复使用 （调用函数）<br>用关键字 ‘def’ 来定义，identifier(参数)<br>identifier<br>参数list<br>return statement<br>局部变量 vs 全局变量<br></p>","more":"<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#-*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\">#没有参数和返回的函数</span></span><br><span class=\"line\"><span class=\"comment\"># def say_hi():</span></span><br><span class=\"line\"><span class=\"comment\">#     print(\" hi!\")</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># say_hi()</span></span><br><span class=\"line\"><span class=\"comment\"># say_hi()</span></span><br><span class=\"line\"><span class=\"comment\">#    </span></span><br><span class=\"line\"><span class=\"comment\">#    </span></span><br><span class=\"line\"><span class=\"comment\">#有参数，无返回值</span></span><br><span class=\"line\"><span class=\"comment\"># def print_sum_two(a, b):</span></span><br><span class=\"line\"><span class=\"comment\">#     c = a + b</span></span><br><span class=\"line\"><span class=\"comment\">#     print(c)</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># print_sum_two(3, 6)</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># def hello_some(str):</span></span><br><span class=\"line\"><span class=\"comment\">#     print(\"hello \" + str + \"!\")</span></span><br><span class=\"line\"><span class=\"comment\">#         </span></span><br><span class=\"line\"><span class=\"comment\"># hello_some(\"China\")</span></span><br><span class=\"line\"><span class=\"comment\"># hello_some(\"Python\")</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">#有参数，有返回值</span></span><br><span class=\"line\"><span class=\"comment\"># def repeat_str(str, times):</span></span><br><span class=\"line\"><span class=\"comment\">#     repeated_strs = str * times</span></span><br><span class=\"line\"><span class=\"comment\">#     return repeated_strs</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># repeated_strings = repeat_str(\"Happy Birthday!\", 4)</span></span><br><span class=\"line\"><span class=\"comment\"># print(repeated_strings)</span></span><br><span class=\"line\">   </span><br><span class=\"line\"><span class=\"comment\">#全局变量与局部 变量</span></span><br><span class=\"line\"><span class=\"comment\"># x = 60</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># def foo(x):</span></span><br><span class=\"line\"><span class=\"comment\">#     print(\"x is: \" + str(x))</span></span><br><span class=\"line\"><span class=\"comment\">#     x = 3</span></span><br><span class=\"line\"><span class=\"comment\">#     print(\"change local x to \" + str(x))</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># foo(x)</span></span><br><span class=\"line\"><span class=\"comment\"># print('x is still', str(x))</span></span><br><span class=\"line\">x = 60</span><br><span class=\"line\">def foo():</span><br><span class=\"line\">    global x</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"x is: \"</span> + str(x))</span><br><span class=\"line\">    x = 3</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"change local x to \"</span> + str(x))</span><br><span class=\"line\">foo()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'value of x is'</span> , str(x))</span><br></pre></td></tr></table></figure><p></p>\n<p>默认参数<br>关键字参数<br>VarArgs参数<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#-*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"comment\"># 默认参数</span></span><br><span class=\"line\">def repeat_str(s, <span class=\"built_in\">times</span> = 1):</span><br><span class=\"line\">    repeated_strs = s * <span class=\"built_in\">times</span></span><br><span class=\"line\">    <span class=\"built_in\">return</span> repeated_strs</span><br><span class=\"line\">repeated_strings = repeat_str(<span class=\"string\">\"Happy Birthday!\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(repeated_strings)</span><br><span class=\"line\">repeated_strings_2 = repeat_str(<span class=\"string\">\"Happy Birthday!\"</span> , 4)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(repeated_strings_2)</span><br><span class=\"line\"><span class=\"comment\">#不能在有默认参数后面跟随没有默认参数</span></span><br><span class=\"line\"><span class=\"comment\">#f(a, b =2)合法</span></span><br><span class=\"line\"><span class=\"comment\">#f(a = 2, b)非法</span></span><br><span class=\"line\"><span class=\"comment\">#关键字参数: 调用函数时，选择性的传入部分参数</span></span><br><span class=\"line\">def func(a, b = 4, c = 8):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">'a is'</span>, a, <span class=\"string\">'and b is'</span>, b, <span class=\"string\">'and c is'</span>, c)</span><br><span class=\"line\">func(13, 17)</span><br><span class=\"line\">func(125, c = 24)</span><br><span class=\"line\">func(c = 40, a = 80)</span><br><span class=\"line\"><span class=\"comment\">#VarArgs参数</span></span><br><span class=\"line\">def print_paras(fpara, *nums, **words):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"fpara: \"</span> + str(fpara))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"nums: \"</span> + str(nums))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">\"words: \"</span> + str(words))  </span><br><span class=\"line\">print_paras(<span class=\"string\">\"hello\"</span>, 1, 3, 5, 7, word = <span class=\"string\">\"python\"</span>, anohter_word = <span class=\"string\">\"java\"</span>)</span><br></pre></td></tr></table></figure></p>"},{"title":"机器学习笔记（一）","date":"2017-06-23T06:33:37.000Z","comments":1,"reward":true,"_content":"1. 基本概念：训练集，测试集，特征值，监督学习，非监督学习，半监督学习，分类，回归 \n2. 概念学习：人类学习概念：鸟，车，计算机\n定义：概念学习是指从有关某个布尔函数的输入输出训练样例中推断出该布尔函数\n3. 例子：学习 “享受运动\"  这一概念：\n小明进行水上运动，是否享受运动取决于很多因素\n样例 天气 温度 湿度 风力 水温 预报 享受运动 \n1    晴   暖   普通 强   暖   一样   是 \n2    晴   暖   大   强   暖   一样   是 \n3    雨   冷   大   强   暖   变化   否 \n4    晴   暖   大   强   冷   变化   是 \n<!-- more -->\n天气：晴，阴， 雨 \n温度：暖，冷\n湿度：普通，大\n风力：强，弱\n水温：暖，冷\n预报：一样，变化\n享受运动：是，否\n概念定义在实例(instance)集合之上，这个集合表示为X。（X：所有可能的日子，每个日子的值由 天气，温度，湿度，风力，水温，预报6个属性表示。\n待学习的概念或目标函数成为目标概念（target concept), 记做c。\nc(x) = 1, 当享受运动时， c(x) = 0 当不享受运动时，c(x)也可叫做y\nx: 每一个实例\nX: 样例, 所有实例的集合\n学习目标：f: X -> Y\n4. 训练集(training set/data)/训练样例（training examples): 用来进行训练，也就是产生模型或者算法的数据集\n测试集(testing set/data)/测试样例 (testing examples)：用来专门进行测试已经学习好的模型或者算法的数据集\n特征向量(features/feature vector)：属性的集合，通常用一个向量来表示，附属于一个实例\n标记(label): c(x), 实例类别的标记\n正例(positive example)\n反例(negative example)\n5. 例子：研究美国硅谷房价\n影响房价的两个重要因素：面积(平方米），学区（评分1-10）\n样例 面积（平方米） 学区 （1-10） 房价 （1000$) \n1        100         8             1000 \n2        120         9             1300 \n3        60          6             800 \n4        80          9             1100 \n5        95          5             850 \n6.  分类 (classification): 目标标记为类别型数据(category) \n回归(regression): 目标标记为连续性数值 (continuous numeric value)\n7. 例子：研究肿瘤良性，恶性于尺寸，颜色的关系\n特征值：肿瘤尺寸，颜色\n标记：良性/恶性\n有监督学习(supervised learning)： 训练集有类别标记(class label)\n无监督学习(unsupervised learning)： 无类别标记(class label)\n半监督学习（semi-supervised learning)：有类别标记的训练集 + 无标记的训练集\n8. 机器学习步骤框架\n8.1 把数据拆分为训练集和测试集\n8.2 用训练集和训练集的特征向量来训练算法\n8.2 用学习来的算法运用在测试集上来评估算法 （可能要设计到调整参数（parameter tuning), 用验证集（validation set）\n100 天： 训练集\n10天：测试集 （不知道是否 ” 享受运动“， 知道6个属性，来预测每一天是否享受运动）","source":"_posts/2017-6-23-two.md","raw":"---\ntitle: 机器学习笔记（一）\ndate: 2017-06-23 14:33:37\ncomments: true\nreward: true\ntags: \n - 机器学习\n---\n1. 基本概念：训练集，测试集，特征值，监督学习，非监督学习，半监督学习，分类，回归 \n2. 概念学习：人类学习概念：鸟，车，计算机\n定义：概念学习是指从有关某个布尔函数的输入输出训练样例中推断出该布尔函数\n3. 例子：学习 “享受运动\"  这一概念：\n小明进行水上运动，是否享受运动取决于很多因素\n样例 天气 温度 湿度 风力 水温 预报 享受运动 \n1    晴   暖   普通 强   暖   一样   是 \n2    晴   暖   大   强   暖   一样   是 \n3    雨   冷   大   强   暖   变化   否 \n4    晴   暖   大   强   冷   变化   是 \n<!-- more -->\n天气：晴，阴， 雨 \n温度：暖，冷\n湿度：普通，大\n风力：强，弱\n水温：暖，冷\n预报：一样，变化\n享受运动：是，否\n概念定义在实例(instance)集合之上，这个集合表示为X。（X：所有可能的日子，每个日子的值由 天气，温度，湿度，风力，水温，预报6个属性表示。\n待学习的概念或目标函数成为目标概念（target concept), 记做c。\nc(x) = 1, 当享受运动时， c(x) = 0 当不享受运动时，c(x)也可叫做y\nx: 每一个实例\nX: 样例, 所有实例的集合\n学习目标：f: X -> Y\n4. 训练集(training set/data)/训练样例（training examples): 用来进行训练，也就是产生模型或者算法的数据集\n测试集(testing set/data)/测试样例 (testing examples)：用来专门进行测试已经学习好的模型或者算法的数据集\n特征向量(features/feature vector)：属性的集合，通常用一个向量来表示，附属于一个实例\n标记(label): c(x), 实例类别的标记\n正例(positive example)\n反例(negative example)\n5. 例子：研究美国硅谷房价\n影响房价的两个重要因素：面积(平方米），学区（评分1-10）\n样例 面积（平方米） 学区 （1-10） 房价 （1000$) \n1        100         8             1000 \n2        120         9             1300 \n3        60          6             800 \n4        80          9             1100 \n5        95          5             850 \n6.  分类 (classification): 目标标记为类别型数据(category) \n回归(regression): 目标标记为连续性数值 (continuous numeric value)\n7. 例子：研究肿瘤良性，恶性于尺寸，颜色的关系\n特征值：肿瘤尺寸，颜色\n标记：良性/恶性\n有监督学习(supervised learning)： 训练集有类别标记(class label)\n无监督学习(unsupervised learning)： 无类别标记(class label)\n半监督学习（semi-supervised learning)：有类别标记的训练集 + 无标记的训练集\n8. 机器学习步骤框架\n8.1 把数据拆分为训练集和测试集\n8.2 用训练集和训练集的特征向量来训练算法\n8.2 用学习来的算法运用在测试集上来评估算法 （可能要设计到调整参数（parameter tuning), 用验证集（validation set）\n100 天： 训练集\n10天：测试集 （不知道是否 ” 享受运动“， 知道6个属性，来预测每一天是否享受运动）","slug":"2017-6-23-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m000jycvjcze80lkd","content":"<ol>\n<li>基本概念：训练集，测试集，特征值，监督学习，非监督学习，半监督学习，分类，回归 </li>\n<li>概念学习：人类学习概念：鸟，车，计算机<br>定义：概念学习是指从有关某个布尔函数的输入输出训练样例中推断出该布尔函数</li>\n<li>例子：学习 “享受运动”  这一概念：<br>小明进行水上运动，是否享受运动取决于很多因素<br>样例 天气 温度 湿度 风力 水温 预报 享受运动<br>1    晴   暖   普通 强   暖   一样   是<br>2    晴   暖   大   强   暖   一样   是<br>3    雨   冷   大   强   暖   变化   否<br>4    晴   暖   大   强   冷   变化   是 <a id=\"more\"></a>\n天气：晴，阴， 雨<br>温度：暖，冷<br>湿度：普通，大<br>风力：强，弱<br>水温：暖，冷<br>预报：一样，变化<br>享受运动：是，否<br>概念定义在实例(instance)集合之上，这个集合表示为X。（X：所有可能的日子，每个日子的值由 天气，温度，湿度，风力，水温，预报6个属性表示。<br>待学习的概念或目标函数成为目标概念（target concept), 记做c。<br>c(x) = 1, 当享受运动时， c(x) = 0 当不享受运动时，c(x)也可叫做y<br>x: 每一个实例<br>X: 样例, 所有实例的集合<br>学习目标：f: X -&gt; Y</li>\n<li>训练集(training set/data)/训练样例（training examples): 用来进行训练，也就是产生模型或者算法的数据集<br>测试集(testing set/data)/测试样例 (testing examples)：用来专门进行测试已经学习好的模型或者算法的数据集<br>特征向量(features/feature vector)：属性的集合，通常用一个向量来表示，附属于一个实例<br>标记(label): c(x), 实例类别的标记<br>正例(positive example)<br>反例(negative example)</li>\n<li>例子：研究美国硅谷房价<br>影响房价的两个重要因素：面积(平方米），学区（评分1-10）<br>样例 面积（平方米） 学区 （1-10） 房价 （1000$)<br>1        100         8             1000<br>2        120         9             1300<br>3        60          6             800<br>4        80          9             1100<br>5        95          5             850 </li>\n<li>分类 (classification): 目标标记为类别型数据(category)<br>回归(regression): 目标标记为连续性数值 (continuous numeric value)</li>\n<li>例子：研究肿瘤良性，恶性于尺寸，颜色的关系<br>特征值：肿瘤尺寸，颜色<br>标记：良性/恶性<br>有监督学习(supervised learning)： 训练集有类别标记(class label)<br>无监督学习(unsupervised learning)： 无类别标记(class label)<br>半监督学习（semi-supervised learning)：有类别标记的训练集 + 无标记的训练集</li>\n<li>机器学习步骤框架<br>8.1 把数据拆分为训练集和测试集<br>8.2 用训练集和训练集的特征向量来训练算法<br>8.2 用学习来的算法运用在测试集上来评估算法 （可能要设计到调整参数（parameter tuning), 用验证集（validation set）<br>100 天： 训练集<br>10天：测试集 （不知道是否 ” 享受运动“， 知道6个属性，来预测每一天是否享受运动）</li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>基本概念：训练集，测试集，特征值，监督学习，非监督学习，半监督学习，分类，回归 </li>\n<li>概念学习：人类学习概念：鸟，车，计算机<br>定义：概念学习是指从有关某个布尔函数的输入输出训练样例中推断出该布尔函数</li>\n<li>例子：学习 “享受运动”  这一概念：<br>小明进行水上运动，是否享受运动取决于很多因素<br>样例 天气 温度 湿度 风力 水温 预报 享受运动<br>1    晴   暖   普通 强   暖   一样   是<br>2    晴   暖   大   强   暖   一样   是<br>3    雨   冷   大   强   暖   变化   否<br>4    晴   暖   大   强   冷   变化   是</li></ol>","more":"天气：晴，阴， 雨<br>温度：暖，冷<br>湿度：普通，大<br>风力：强，弱<br>水温：暖，冷<br>预报：一样，变化<br>享受运动：是，否<br>概念定义在实例(instance)集合之上，这个集合表示为X。（X：所有可能的日子，每个日子的值由 天气，温度，湿度，风力，水温，预报6个属性表示。<br>待学习的概念或目标函数成为目标概念（target concept), 记做c。<br>c(x) = 1, 当享受运动时， c(x) = 0 当不享受运动时，c(x)也可叫做y<br>x: 每一个实例<br>X: 样例, 所有实例的集合<br>学习目标：f: X -&gt; Y\n<li>训练集(training set/data)/训练样例（training examples): 用来进行训练，也就是产生模型或者算法的数据集<br>测试集(testing set/data)/测试样例 (testing examples)：用来专门进行测试已经学习好的模型或者算法的数据集<br>特征向量(features/feature vector)：属性的集合，通常用一个向量来表示，附属于一个实例<br>标记(label): c(x), 实例类别的标记<br>正例(positive example)<br>反例(negative example)</li>\n<li>例子：研究美国硅谷房价<br>影响房价的两个重要因素：面积(平方米），学区（评分1-10）<br>样例 面积（平方米） 学区 （1-10） 房价 （1000$)<br>1        100         8             1000<br>2        120         9             1300<br>3        60          6             800<br>4        80          9             1100<br>5        95          5             850 </li>\n<li>分类 (classification): 目标标记为类别型数据(category)<br>回归(regression): 目标标记为连续性数值 (continuous numeric value)</li>\n<li>例子：研究肿瘤良性，恶性于尺寸，颜色的关系<br>特征值：肿瘤尺寸，颜色<br>标记：良性/恶性<br>有监督学习(supervised learning)： 训练集有类别标记(class label)<br>无监督学习(unsupervised learning)： 无类别标记(class label)<br>半监督学习（semi-supervised learning)：有类别标记的训练集 + 无标记的训练集</li>\n<li>机器学习步骤框架<br>8.1 把数据拆分为训练集和测试集<br>8.2 用训练集和训练集的特征向量来训练算法<br>8.2 用学习来的算法运用在测试集上来评估算法 （可能要设计到调整参数（parameter tuning), 用验证集（validation set）<br>100 天： 训练集<br>10天：测试集 （不知道是否 ” 享受运动“， 知道6个属性，来预测每一天是否享受运动）</li>\n"},{"title":"破解百度云限速","date":"2017-06-26T13:24:29.000Z","comments":1,"reward":true,"_content":"致敬制作PCS命令行来处理百度云限速的大神：github帐号@GangZhuo\n完美的解决了坑爹Baidu限速和拉黑的限制，记录操作流程和简单命令 \n总的来说与Linux操作命令相同 在之前加上PCS即可。\nWindows：\n1、命令行版本：下载这个https://github.com/GangZhuo/BaiduPCS/releases/download/0.2.5/pcs-win32-0.2.5-db684dc.zip\n然后复制到System32里面\n2、检查是否安装成功：终端（windows命令行版本则打开cmd输入pcs，GUI版本双击打开）输入pcs，查看是否像我的一样，如果是，则安装成功。\n3、这个时候先设置一下线程数量，这里给一个参考的设置线程数：\n＜10m：5线程\n＜50m：10线程\n＜100m：25线程\n＜500m：40线程\n＜1G：70-80线程\n＞2G：100线程（最多也是只能设置100线程）\n<!-- more -->\n设置线程命令：pcs set --max_thread=你要设置的线程数\n例如我现在要设置100线程，则输入pcs set --max_thread=100\n下载文件：用pcs cd切换到你百度云中要下载的文件目录（例如说“我的应用数据”就是/apps）\n然后使用pcs download <文件名> <你要保存到的目录加文件名>\n例如说我要下载“Parrot-full-3.3_amd64.iso”，保存到/home/redapple/Downloads\n就输入pcs download Parrot-full-3.3_amd64.iso /home/redapple/Downloads/Parrot-full-3.3_amd64.iso\n注意：如果你要下载的文件带有空格（如1 2 3 ），就要打上引号，就想这样\npcs download \"1 2 3\" \"/home/redapple/Downloads/1 2 3\"\n上传文件命令是\npcs upload <你要上传的文件目录> <你要上传到云端的目录>","source":"_posts/2017-6-26-two.md","raw":"---\ntitle: 破解百度云限速\ndate: 2017-06-26 21:24:29\ncomments: true\nreward: true\ntags: \n - BaiduYun\n---\n致敬制作PCS命令行来处理百度云限速的大神：github帐号@GangZhuo\n完美的解决了坑爹Baidu限速和拉黑的限制，记录操作流程和简单命令 \n总的来说与Linux操作命令相同 在之前加上PCS即可。\nWindows：\n1、命令行版本：下载这个https://github.com/GangZhuo/BaiduPCS/releases/download/0.2.5/pcs-win32-0.2.5-db684dc.zip\n然后复制到System32里面\n2、检查是否安装成功：终端（windows命令行版本则打开cmd输入pcs，GUI版本双击打开）输入pcs，查看是否像我的一样，如果是，则安装成功。\n3、这个时候先设置一下线程数量，这里给一个参考的设置线程数：\n＜10m：5线程\n＜50m：10线程\n＜100m：25线程\n＜500m：40线程\n＜1G：70-80线程\n＞2G：100线程（最多也是只能设置100线程）\n<!-- more -->\n设置线程命令：pcs set --max_thread=你要设置的线程数\n例如我现在要设置100线程，则输入pcs set --max_thread=100\n下载文件：用pcs cd切换到你百度云中要下载的文件目录（例如说“我的应用数据”就是/apps）\n然后使用pcs download <文件名> <你要保存到的目录加文件名>\n例如说我要下载“Parrot-full-3.3_amd64.iso”，保存到/home/redapple/Downloads\n就输入pcs download Parrot-full-3.3_amd64.iso /home/redapple/Downloads/Parrot-full-3.3_amd64.iso\n注意：如果你要下载的文件带有空格（如1 2 3 ），就要打上引号，就想这样\npcs download \"1 2 3\" \"/home/redapple/Downloads/1 2 3\"\n上传文件命令是\npcs upload <你要上传的文件目录> <你要上传到云端的目录>","slug":"2017-6-26-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m000mycvj2ml62a4g","content":"<p>致敬制作PCS命令行来处理百度云限速的大神：github帐号@GangZhuo<br>完美的解决了坑爹Baidu限速和拉黑的限制，记录操作流程和简单命令<br>总的来说与Linux操作命令相同 在之前加上PCS即可。<br>Windows：<br>1、命令行版本：下载这个<a href=\"https://github.com/GangZhuo/BaiduPCS/releases/download/0.2.5/pcs-win32-0.2.5-db684dc.zip\" target=\"_blank\" rel=\"noopener\">https://github.com/GangZhuo/BaiduPCS/releases/download/0.2.5/pcs-win32-0.2.5-db684dc.zip</a><br>然后复制到System32里面<br>2、检查是否安装成功：终端（windows命令行版本则打开cmd输入pcs，GUI版本双击打开）输入pcs，查看是否像我的一样，如果是，则安装成功。<br>3、这个时候先设置一下线程数量，这里给一个参考的设置线程数：<br>＜10m：5线程<br>＜50m：10线程<br>＜100m：25线程<br>＜500m：40线程<br>＜1G：70-80线程<br>＞2G：100线程（最多也是只能设置100线程）<br><a id=\"more\"></a><br>设置线程命令：pcs set –max_thread=你要设置的线程数<br>例如我现在要设置100线程，则输入pcs set –max_thread=100<br>下载文件：用pcs cd切换到你百度云中要下载的文件目录（例如说“我的应用数据”就是/apps）<br>然后使用pcs download &lt;文件名&gt; &lt;你要保存到的目录加文件名&gt;<br>例如说我要下载“Parrot-full-3.3_amd64.iso”，保存到/home/redapple/Downloads<br>就输入pcs download Parrot-full-3.3_amd64.iso /home/redapple/Downloads/Parrot-full-3.3_amd64.iso<br>注意：如果你要下载的文件带有空格（如1 2 3 ），就要打上引号，就想这样<br>pcs download “1 2 3” “/home/redapple/Downloads/1 2 3”<br>上传文件命令是<br>pcs upload &lt;你要上传的文件目录&gt; &lt;你要上传到云端的目录&gt;</p>\n","site":{"data":{}},"excerpt":"<p>致敬制作PCS命令行来处理百度云限速的大神：github帐号@GangZhuo<br>完美的解决了坑爹Baidu限速和拉黑的限制，记录操作流程和简单命令<br>总的来说与Linux操作命令相同 在之前加上PCS即可。<br>Windows：<br>1、命令行版本：下载这个<a href=\"https://github.com/GangZhuo/BaiduPCS/releases/download/0.2.5/pcs-win32-0.2.5-db684dc.zip\" target=\"_blank\" rel=\"noopener\">https://github.com/GangZhuo/BaiduPCS/releases/download/0.2.5/pcs-win32-0.2.5-db684dc.zip</a><br>然后复制到System32里面<br>2、检查是否安装成功：终端（windows命令行版本则打开cmd输入pcs，GUI版本双击打开）输入pcs，查看是否像我的一样，如果是，则安装成功。<br>3、这个时候先设置一下线程数量，这里给一个参考的设置线程数：<br>＜10m：5线程<br>＜50m：10线程<br>＜100m：25线程<br>＜500m：40线程<br>＜1G：70-80线程<br>＞2G：100线程（最多也是只能设置100线程）<br></p>","more":"<br>设置线程命令：pcs set –max_thread=你要设置的线程数<br>例如我现在要设置100线程，则输入pcs set –max_thread=100<br>下载文件：用pcs cd切换到你百度云中要下载的文件目录（例如说“我的应用数据”就是/apps）<br>然后使用pcs download &lt;文件名&gt; &lt;你要保存到的目录加文件名&gt;<br>例如说我要下载“Parrot-full-3.3_amd64.iso”，保存到/home/redapple/Downloads<br>就输入pcs download Parrot-full-3.3_amd64.iso /home/redapple/Downloads/Parrot-full-3.3_amd64.iso<br>注意：如果你要下载的文件带有空格（如1 2 3 ），就要打上引号，就想这样<br>pcs download “1 2 3” “/home/redapple/Downloads/1 2 3”<br>上传文件命令是<br>pcs upload &lt;你要上传的文件目录&gt; &lt;你要上传到云端的目录&gt;<p></p>"},{"title":"机器学习笔记（二）决策树算法原理","date":"2017-06-27T01:59:43.000Z","comments":1,"reward":true,"_content":"0. 机器学习中分类和预测算法的评估：\n准确率\n速度\n强壮行\n可规模性\n可解释性\n1. 什么是决策树/判定树（decision tree)?\n     判定树是一个类似于流程图的树结构：其中，每个内部结点表示在一个属性上的测试，每个分支代表一个属性输出，而每个树叶结点代表类或类分布。树的最顶层是根结点。\n![](2017-6-27-one/1.png)\n<!-- more -->\n2. 机器学习中分类方法中的一个重要算法\n3. 构造决策树的基本算法\n![](2017-6-27-one/2.png)\n![](2017-6-27-one/3.png)\n3.1 熵（entropy）概念：\n信息和抽象，如何度量？\n1948年，香农提出了 ”信息熵(entropy)“的概念\n一条信息的信息量大小和它的不确定性有直接的关系，要搞清楚一件非常非常不确定的事情，或者是我们一无所知的事情，需要了解大量信息==>信息量的度量就等于不确定性的多少\n例子：猜世界杯冠军，假如一无所知，猜多少次？\n每个队夺冠的几率不是相等的\n比特(bit)来衡量信息的多少\n![](2017-6-27-one/4.png)\n变量的不确定性越大，熵也就越大\n3.1 决策树归纳算法 （ID3）\n1970-1980， J.Ross. Quinlan, ID3算法\n选择属性判断结点\n信息获取量(Information Gain)：Gain(A) = Info(D) - Infor_A(D)\n通过A来作为节点分类获取了多少信息\n![](2017-6-27-one/5.png)\n![](2017-6-27-one/6.png)\n类似，Gain(income) = 0.029, Gain(student) = 0.151, Gain(credit_rating)=0.048\n所以，选择age作为第一个根节点\n![](2017-6-27-one/7.png)\n重复。。。\n算法：\n树以代表训练样本的单个结点开始（步骤1）。\n如果样本都在同一个类，则该结点成为树叶，并用该类标号（步骤2 和3）。\n否则，算法使用称为信息增益的基于熵的度量作为启发信息，选择能够最好地将样本分类的属性（步骤6）。该属性成为该结点的“测试”或“判定”属性（步骤7）。\n在算法的该版本中，所有的属性都是分类的，即离散值。连续属性必须离散化。对测试属性的每个已知的值，创建一个分枝，并据此划分样本（步骤8-10）。\n算法使用同样的过程，递归地形成每个划分上的样本判定树。一旦一个属性出现在一个结点上，就不必该结点的任何后代上考虑它（步骤13）。\n递归划分步骤仅当下列条件之一成立停止：\n(a) 给定结点的所有样本属于同一类（步骤2 和3）。\n(b) 没有剩余属性可以用来进一步划分样本（步骤4）。在此情况下，使用多数表决（步骤5）。\n这涉及将给定的结点转换成树叶，并用样本中的多数所在的类标记它。替换地，可以存放结\n点样本的类分布。\n(c) 分枝\ntest_attribute = a i 没有样本（步骤11）。在这种情况下，以 samples 中的多数类\n创建一个树叶（步骤12）\n               \n3.1 其他算法：\nC4.5:  Quinlan\nClassification and Regression Trees (CART): (L. Breiman, J. Friedman, R. Olshen, C. Stone)\n共同点：都是贪心算法，自上而下(Top-down approach)\n区别：属性选择度量方法不同： C4.5 （gain ratio), CART(gini index), ID3 (Information Gain)\n3.2 如何处理连续性变量的属性？ \n4. 树剪枝叶 （避免overfitting)\n     4.1 先剪枝\n     4.2 后剪枝\n5. 决策树的优点：\n     直观，便于理解，小规模数据集有效     \n6. 决策树的缺点：\n     处理连续变量不好\n     类别较多时，错误增加的比较快\n     可规模性一般\n     ","source":"_posts/2017-6-27-one.md","raw":"---\ntitle: 机器学习笔记（二）决策树算法原理\ndate: 2017-06-27 09:59:43\ncomments: true\nreward: true\ntags: \n - 机器学习\n---\n0. 机器学习中分类和预测算法的评估：\n准确率\n速度\n强壮行\n可规模性\n可解释性\n1. 什么是决策树/判定树（decision tree)?\n     判定树是一个类似于流程图的树结构：其中，每个内部结点表示在一个属性上的测试，每个分支代表一个属性输出，而每个树叶结点代表类或类分布。树的最顶层是根结点。\n![](2017-6-27-one/1.png)\n<!-- more -->\n2. 机器学习中分类方法中的一个重要算法\n3. 构造决策树的基本算法\n![](2017-6-27-one/2.png)\n![](2017-6-27-one/3.png)\n3.1 熵（entropy）概念：\n信息和抽象，如何度量？\n1948年，香农提出了 ”信息熵(entropy)“的概念\n一条信息的信息量大小和它的不确定性有直接的关系，要搞清楚一件非常非常不确定的事情，或者是我们一无所知的事情，需要了解大量信息==>信息量的度量就等于不确定性的多少\n例子：猜世界杯冠军，假如一无所知，猜多少次？\n每个队夺冠的几率不是相等的\n比特(bit)来衡量信息的多少\n![](2017-6-27-one/4.png)\n变量的不确定性越大，熵也就越大\n3.1 决策树归纳算法 （ID3）\n1970-1980， J.Ross. Quinlan, ID3算法\n选择属性判断结点\n信息获取量(Information Gain)：Gain(A) = Info(D) - Infor_A(D)\n通过A来作为节点分类获取了多少信息\n![](2017-6-27-one/5.png)\n![](2017-6-27-one/6.png)\n类似，Gain(income) = 0.029, Gain(student) = 0.151, Gain(credit_rating)=0.048\n所以，选择age作为第一个根节点\n![](2017-6-27-one/7.png)\n重复。。。\n算法：\n树以代表训练样本的单个结点开始（步骤1）。\n如果样本都在同一个类，则该结点成为树叶，并用该类标号（步骤2 和3）。\n否则，算法使用称为信息增益的基于熵的度量作为启发信息，选择能够最好地将样本分类的属性（步骤6）。该属性成为该结点的“测试”或“判定”属性（步骤7）。\n在算法的该版本中，所有的属性都是分类的，即离散值。连续属性必须离散化。对测试属性的每个已知的值，创建一个分枝，并据此划分样本（步骤8-10）。\n算法使用同样的过程，递归地形成每个划分上的样本判定树。一旦一个属性出现在一个结点上，就不必该结点的任何后代上考虑它（步骤13）。\n递归划分步骤仅当下列条件之一成立停止：\n(a) 给定结点的所有样本属于同一类（步骤2 和3）。\n(b) 没有剩余属性可以用来进一步划分样本（步骤4）。在此情况下，使用多数表决（步骤5）。\n这涉及将给定的结点转换成树叶，并用样本中的多数所在的类标记它。替换地，可以存放结\n点样本的类分布。\n(c) 分枝\ntest_attribute = a i 没有样本（步骤11）。在这种情况下，以 samples 中的多数类\n创建一个树叶（步骤12）\n               \n3.1 其他算法：\nC4.5:  Quinlan\nClassification and Regression Trees (CART): (L. Breiman, J. Friedman, R. Olshen, C. Stone)\n共同点：都是贪心算法，自上而下(Top-down approach)\n区别：属性选择度量方法不同： C4.5 （gain ratio), CART(gini index), ID3 (Information Gain)\n3.2 如何处理连续性变量的属性？ \n4. 树剪枝叶 （避免overfitting)\n     4.1 先剪枝\n     4.2 后剪枝\n5. 决策树的优点：\n     直观，便于理解，小规模数据集有效     \n6. 决策树的缺点：\n     处理连续变量不好\n     类别较多时，错误增加的比较快\n     可规模性一般\n     ","slug":"2017-6-27-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m000oycvj6m87by53","content":"<ol>\n<li>机器学习中分类和预测算法的评估：<br>准确率<br>速度<br>强壮行<br>可规模性<br>可解释性</li>\n<li>什么是决策树/判定树（decision tree)?<br>  判定树是一个类似于流程图的树结构：其中，每个内部结点表示在一个属性上的测试，每个分支代表一个属性输出，而每个树叶结点代表类或类分布。树的最顶层是根结点。<br><img src=\"/2017/06/27/2017-6-27-one/1.png\" alt=\"\"><a id=\"more\"></a></li>\n<li>机器学习中分类方法中的一个重要算法</li>\n<li>构造决策树的基本算法<br><img src=\"/2017/06/27/2017-6-27-one/2.png\" alt=\"\"><br><img src=\"/2017/06/27/2017-6-27-one/3.png\" alt=\"\"><br>3.1 熵（entropy）概念：<br>信息和抽象，如何度量？<br>1948年，香农提出了 ”信息熵(entropy)“的概念<br>一条信息的信息量大小和它的不确定性有直接的关系，要搞清楚一件非常非常不确定的事情，或者是我们一无所知的事情，需要了解大量信息==&gt;信息量的度量就等于不确定性的多少<br>例子：猜世界杯冠军，假如一无所知，猜多少次？<br>每个队夺冠的几率不是相等的<br>比特(bit)来衡量信息的多少<br><img src=\"/2017/06/27/2017-6-27-one/4.png\" alt=\"\"><br>变量的不确定性越大，熵也就越大<br>3.1 决策树归纳算法 （ID3）<br>1970-1980， J.Ross. Quinlan, ID3算法<br>选择属性判断结点<br>信息获取量(Information Gain)：Gain(A) = Info(D) - Infor_A(D)<br>通过A来作为节点分类获取了多少信息<br><img src=\"/2017/06/27/2017-6-27-one/5.png\" alt=\"\"><br><img src=\"/2017/06/27/2017-6-27-one/6.png\" alt=\"\"><br>类似，Gain(income) = 0.029, Gain(student) = 0.151, Gain(credit_rating)=0.048<br>所以，选择age作为第一个根节点<br><img src=\"/2017/06/27/2017-6-27-one/7.png\" alt=\"\"><br>重复。。。<br>算法：<br>树以代表训练样本的单个结点开始（步骤1）。<br>如果样本都在同一个类，则该结点成为树叶，并用该类标号（步骤2 和3）。<br>否则，算法使用称为信息增益的基于熵的度量作为启发信息，选择能够最好地将样本分类的属性（步骤6）。该属性成为该结点的“测试”或“判定”属性（步骤7）。<br>在算法的该版本中，所有的属性都是分类的，即离散值。连续属性必须离散化。对测试属性的每个已知的值，创建一个分枝，并据此划分样本（步骤8-10）。<br>算法使用同样的过程，递归地形成每个划分上的样本判定树。一旦一个属性出现在一个结点上，就不必该结点的任何后代上考虑它（步骤13）。<br>递归划分步骤仅当下列条件之一成立停止：<br>(a) 给定结点的所有样本属于同一类（步骤2 和3）。<br>(b) 没有剩余属性可以用来进一步划分样本（步骤4）。在此情况下，使用多数表决（步骤5）。<br>这涉及将给定的结点转换成树叶，并用样本中的多数所在的类标记它。替换地，可以存放结<br>点样本的类分布。<br>(c) 分枝<br>test_attribute = a i 没有样本（步骤11）。在这种情况下，以 samples 中的多数类<br>创建一个树叶（步骤12）</li>\n</ol>\n<p>3.1 其他算法：<br>C4.5:  Quinlan<br>Classification and Regression Trees (CART): (L. Breiman, J. Friedman, R. Olshen, C. Stone)<br>共同点：都是贪心算法，自上而下(Top-down approach)<br>区别：属性选择度量方法不同： C4.5 （gain ratio), CART(gini index), ID3 (Information Gain)<br>3.2 如何处理连续性变量的属性？ </p>\n<ol>\n<li>树剪枝叶 （避免overfitting)<br>  4.1 先剪枝<br>  4.2 后剪枝</li>\n<li>决策树的优点：<br>  直观，便于理解，小规模数据集有效     </li>\n<li>决策树的缺点：<br>  处理连续变量不好<br>  类别较多时，错误增加的比较快<br>  可规模性一般</li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>机器学习中分类和预测算法的评估：<br>准确率<br>速度<br>强壮行<br>可规模性<br>可解释性</li>\n<li>什么是决策树/判定树（decision tree)?<br>  判定树是一个类似于流程图的树结构：其中，每个内部结点表示在一个属性上的测试，每个分支代表一个属性输出，而每个树叶结点代表类或类分布。树的最顶层是根结点。<br><img src=\"/2017/06/27/2017-6-27-one/1.png\" alt=\"\"></li></ol>","more":"\n<li>机器学习中分类方法中的一个重要算法</li>\n<li>构造决策树的基本算法<br><img src=\"/2017/06/27/2017-6-27-one/2.png\" alt=\"\"><br><img src=\"/2017/06/27/2017-6-27-one/3.png\" alt=\"\"><br>3.1 熵（entropy）概念：<br>信息和抽象，如何度量？<br>1948年，香农提出了 ”信息熵(entropy)“的概念<br>一条信息的信息量大小和它的不确定性有直接的关系，要搞清楚一件非常非常不确定的事情，或者是我们一无所知的事情，需要了解大量信息==&gt;信息量的度量就等于不确定性的多少<br>例子：猜世界杯冠军，假如一无所知，猜多少次？<br>每个队夺冠的几率不是相等的<br>比特(bit)来衡量信息的多少<br><img src=\"/2017/06/27/2017-6-27-one/4.png\" alt=\"\"><br>变量的不确定性越大，熵也就越大<br>3.1 决策树归纳算法 （ID3）<br>1970-1980， J.Ross. Quinlan, ID3算法<br>选择属性判断结点<br>信息获取量(Information Gain)：Gain(A) = Info(D) - Infor_A(D)<br>通过A来作为节点分类获取了多少信息<br><img src=\"/2017/06/27/2017-6-27-one/5.png\" alt=\"\"><br><img src=\"/2017/06/27/2017-6-27-one/6.png\" alt=\"\"><br>类似，Gain(income) = 0.029, Gain(student) = 0.151, Gain(credit_rating)=0.048<br>所以，选择age作为第一个根节点<br><img src=\"/2017/06/27/2017-6-27-one/7.png\" alt=\"\"><br>重复。。。<br>算法：<br>树以代表训练样本的单个结点开始（步骤1）。<br>如果样本都在同一个类，则该结点成为树叶，并用该类标号（步骤2 和3）。<br>否则，算法使用称为信息增益的基于熵的度量作为启发信息，选择能够最好地将样本分类的属性（步骤6）。该属性成为该结点的“测试”或“判定”属性（步骤7）。<br>在算法的该版本中，所有的属性都是分类的，即离散值。连续属性必须离散化。对测试属性的每个已知的值，创建一个分枝，并据此划分样本（步骤8-10）。<br>算法使用同样的过程，递归地形成每个划分上的样本判定树。一旦一个属性出现在一个结点上，就不必该结点的任何后代上考虑它（步骤13）。<br>递归划分步骤仅当下列条件之一成立停止：<br>(a) 给定结点的所有样本属于同一类（步骤2 和3）。<br>(b) 没有剩余属性可以用来进一步划分样本（步骤4）。在此情况下，使用多数表决（步骤5）。<br>这涉及将给定的结点转换成树叶，并用样本中的多数所在的类标记它。替换地，可以存放结<br>点样本的类分布。<br>(c) 分枝<br>test_attribute = a i 没有样本（步骤11）。在这种情况下，以 samples 中的多数类<br>创建一个树叶（步骤12）</li>\n\n<p>3.1 其他算法：<br>C4.5:  Quinlan<br>Classification and Regression Trees (CART): (L. Breiman, J. Friedman, R. Olshen, C. Stone)<br>共同点：都是贪心算法，自上而下(Top-down approach)<br>区别：属性选择度量方法不同： C4.5 （gain ratio), CART(gini index), ID3 (Information Gain)<br>3.2 如何处理连续性变量的属性？ </p>\n<ol>\n<li>树剪枝叶 （避免overfitting)<br>  4.1 先剪枝<br>  4.2 后剪枝</li>\n<li>决策树的优点：<br>  直观，便于理解，小规模数据集有效     </li>\n<li>决策树的缺点：<br>  处理连续变量不好<br>  类别较多时，错误增加的比较快<br>  可规模性一般</li>\n</ol>"},{"title":"Python学习笔记（六）","date":"2017-06-27T08:24:39.000Z","comments":1,"reward":true,"_content":"1.输入格式： input()\n2.输出格式：print(),str(), format\n``` bash\nstr_1 = input(\"Enter a string: \")\nstr_2 = input(\"Enter another string: \")\nprint(\"str_1 is: \" + str_1 + \". str_2 is :\" + str_2)\nprint(\"str_1 is {} + str_2 is {}\".format(str_1, str_2))\n```\n3. 写出文件\n4. 读入文件\n<!-- more -->\n``` bash\nsome_sentences = '''\\\nI love learning python\nbecause python is fun\nand also easy to use\n'''\n#Open for 'w'irting\nf = open('sentences.txt', 'w')\n#Write text to File\nf.write(some_sentences)\nf.close()\n#If not specifying mode, 'r'ead mode is default\nf = open('sentences.txt')\nwhile True:\n    line = f.readline()\n    #Zero length means End Of File\n    if len(line) == 0:\n        break\n    print(line)\n# close the File\nf.close()\n```\n5.Python有两种错误类型：\n5.1. 语法错误(Syntax Errors)\n5.2. 异常（Exceptions)\n首先，try语句下的（try和except之间的代码）被执行\n如果没有出现异常，except语句将被忽略\n如果try语句之间出现了异常，try之下异常之后的代码被忽略，直接跳跃到except语句\n如果异常出现，但并不属于except中定义的异常类型，程序将执行外围一层的try语句，如果异常没有被处理，将产生unhandled exception的错误\n处理异常（Handling Exceptions)\nException doc: https://docs.python.org/3.4/library/exceptions.html\n``` bash\n#Example of Syntax errors\n# while True print(\"Hello World!\")\n#Examples of exceptions\n# print(8/0)\n# print(hello * 4)\n# num = 6\n# print(\"Hello World \" + num )\n#Handling exceptions\n# while True:\n#     try:\n#         x = int(input(\"Please enter a number\"))\n#         break\n#     except ValueError:\n#         print(\"Not valid input, try again...\")\n```","source":"_posts/2017-6-27-three.md","raw":"---\ntitle: Python学习笔记（六）\ndate: 2017-06-27 16:24:39\ncomments: true\nreward: true\ntags: \n - python\n---\n1.输入格式： input()\n2.输出格式：print(),str(), format\n``` bash\nstr_1 = input(\"Enter a string: \")\nstr_2 = input(\"Enter another string: \")\nprint(\"str_1 is: \" + str_1 + \". str_2 is :\" + str_2)\nprint(\"str_1 is {} + str_2 is {}\".format(str_1, str_2))\n```\n3. 写出文件\n4. 读入文件\n<!-- more -->\n``` bash\nsome_sentences = '''\\\nI love learning python\nbecause python is fun\nand also easy to use\n'''\n#Open for 'w'irting\nf = open('sentences.txt', 'w')\n#Write text to File\nf.write(some_sentences)\nf.close()\n#If not specifying mode, 'r'ead mode is default\nf = open('sentences.txt')\nwhile True:\n    line = f.readline()\n    #Zero length means End Of File\n    if len(line) == 0:\n        break\n    print(line)\n# close the File\nf.close()\n```\n5.Python有两种错误类型：\n5.1. 语法错误(Syntax Errors)\n5.2. 异常（Exceptions)\n首先，try语句下的（try和except之间的代码）被执行\n如果没有出现异常，except语句将被忽略\n如果try语句之间出现了异常，try之下异常之后的代码被忽略，直接跳跃到except语句\n如果异常出现，但并不属于except中定义的异常类型，程序将执行外围一层的try语句，如果异常没有被处理，将产生unhandled exception的错误\n处理异常（Handling Exceptions)\nException doc: https://docs.python.org/3.4/library/exceptions.html\n``` bash\n#Example of Syntax errors\n# while True print(\"Hello World!\")\n#Examples of exceptions\n# print(8/0)\n# print(hello * 4)\n# num = 6\n# print(\"Hello World \" + num )\n#Handling exceptions\n# while True:\n#     try:\n#         x = int(input(\"Please enter a number\"))\n#         break\n#     except ValueError:\n#         print(\"Not valid input, try again...\")\n```","slug":"2017-6-27-three","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m000qycvjsfxg281l","content":"<p>1.输入格式： input()<br>2.输出格式：print(),str(), format<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">str_1 = input(<span class=\"string\">\"Enter a string: \"</span>)</span><br><span class=\"line\">str_2 = input(<span class=\"string\">\"Enter another string: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"str_1 is: \"</span> + str_1 + <span class=\"string\">\". str_2 is :\"</span> + str_2)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"str_1 is &#123;&#125; + str_2 is &#123;&#125;\"</span>.format(str_1, str_2))</span><br></pre></td></tr></table></figure></p>\n<ol>\n<li>写出文件</li>\n<li>读入文件<a id=\"more\"></a>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">some_sentences = <span class=\"string\">''</span><span class=\"string\">'\\</span></span><br><span class=\"line\"><span class=\"string\">I love learning python</span></span><br><span class=\"line\"><span class=\"string\">because python is fun</span></span><br><span class=\"line\"><span class=\"string\">and also easy to use</span></span><br><span class=\"line\"><span class=\"string\">'</span><span class=\"string\">''</span></span><br><span class=\"line\"><span class=\"comment\">#Open for 'w'irting</span></span><br><span class=\"line\">f = open(<span class=\"string\">'sentences.txt'</span>, <span class=\"string\">'w'</span>)</span><br><span class=\"line\"><span class=\"comment\">#Write text to File</span></span><br><span class=\"line\">f.write(some_sentences)</span><br><span class=\"line\">f.close()</span><br><span class=\"line\"><span class=\"comment\">#If not specifying mode, 'r'ead mode is default</span></span><br><span class=\"line\">f = open(<span class=\"string\">'sentences.txt'</span>)</span><br><span class=\"line\"><span class=\"keyword\">while</span> True:</span><br><span class=\"line\">    line = f.readline()</span><br><span class=\"line\">    <span class=\"comment\">#Zero length means End Of File</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> len(line) == 0:</span><br><span class=\"line\">        <span class=\"built_in\">break</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(line)</span><br><span class=\"line\"><span class=\"comment\"># close the File</span></span><br><span class=\"line\">f.close()</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>5.Python有两种错误类型：<br>5.1. 语法错误(Syntax Errors)<br>5.2. 异常（Exceptions)<br>首先，try语句下的（try和except之间的代码）被执行<br>如果没有出现异常，except语句将被忽略<br>如果try语句之间出现了异常，try之下异常之后的代码被忽略，直接跳跃到except语句<br>如果异常出现，但并不属于except中定义的异常类型，程序将执行外围一层的try语句，如果异常没有被处理，将产生unhandled exception的错误<br>处理异常（Handling Exceptions)<br>Exception doc: <a href=\"https://docs.python.org/3.4/library/exceptions.html\" target=\"_blank\" rel=\"noopener\">https://docs.python.org/3.4/library/exceptions.html</a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Example of Syntax errors</span></span><br><span class=\"line\"><span class=\"comment\"># while True print(\"Hello World!\")</span></span><br><span class=\"line\"><span class=\"comment\">#Examples of exceptions</span></span><br><span class=\"line\"><span class=\"comment\"># print(8/0)</span></span><br><span class=\"line\"><span class=\"comment\"># print(hello * 4)</span></span><br><span class=\"line\"><span class=\"comment\"># num = 6</span></span><br><span class=\"line\"><span class=\"comment\"># print(\"Hello World \" + num )</span></span><br><span class=\"line\"><span class=\"comment\">#Handling exceptions</span></span><br><span class=\"line\"><span class=\"comment\"># while True:</span></span><br><span class=\"line\"><span class=\"comment\">#     try:</span></span><br><span class=\"line\"><span class=\"comment\">#         x = int(input(\"Please enter a number\"))</span></span><br><span class=\"line\"><span class=\"comment\">#         break</span></span><br><span class=\"line\"><span class=\"comment\">#     except ValueError:</span></span><br><span class=\"line\"><span class=\"comment\">#         print(\"Not valid input, try again...\")</span></span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>1.输入格式： input()<br>2.输出格式：print(),str(), format<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">str_1 = input(<span class=\"string\">\"Enter a string: \"</span>)</span><br><span class=\"line\">str_2 = input(<span class=\"string\">\"Enter another string: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"str_1 is: \"</span> + str_1 + <span class=\"string\">\". str_2 is :\"</span> + str_2)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"str_1 is &#123;&#125; + str_2 is &#123;&#125;\"</span>.format(str_1, str_2))</span><br></pre></td></tr></table></figure></p>\n<ol>\n<li>写出文件</li>\n<li>读入文件</li></ol>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">some_sentences = <span class=\"string\">''</span><span class=\"string\">'\\</span></span><br><span class=\"line\"><span class=\"string\">I love learning python</span></span><br><span class=\"line\"><span class=\"string\">because python is fun</span></span><br><span class=\"line\"><span class=\"string\">and also easy to use</span></span><br><span class=\"line\"><span class=\"string\">'</span><span class=\"string\">''</span></span><br><span class=\"line\"><span class=\"comment\">#Open for 'w'irting</span></span><br><span class=\"line\">f = open(<span class=\"string\">'sentences.txt'</span>, <span class=\"string\">'w'</span>)</span><br><span class=\"line\"><span class=\"comment\">#Write text to File</span></span><br><span class=\"line\">f.write(some_sentences)</span><br><span class=\"line\">f.close()</span><br><span class=\"line\"><span class=\"comment\">#If not specifying mode, 'r'ead mode is default</span></span><br><span class=\"line\">f = open(<span class=\"string\">'sentences.txt'</span>)</span><br><span class=\"line\"><span class=\"keyword\">while</span> True:</span><br><span class=\"line\">    line = f.readline()</span><br><span class=\"line\">    <span class=\"comment\">#Zero length means End Of File</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> len(line) == 0:</span><br><span class=\"line\">        <span class=\"built_in\">break</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(line)</span><br><span class=\"line\"><span class=\"comment\"># close the File</span></span><br><span class=\"line\">f.close()</span><br></pre></td></tr></table></figure>\n\n\n<p>5.Python有两种错误类型：<br>5.1. 语法错误(Syntax Errors)<br>5.2. 异常（Exceptions)<br>首先，try语句下的（try和except之间的代码）被执行<br>如果没有出现异常，except语句将被忽略<br>如果try语句之间出现了异常，try之下异常之后的代码被忽略，直接跳跃到except语句<br>如果异常出现，但并不属于except中定义的异常类型，程序将执行外围一层的try语句，如果异常没有被处理，将产生unhandled exception的错误<br>处理异常（Handling Exceptions)<br>Exception doc: <a href=\"https://docs.python.org/3.4/library/exceptions.html\" target=\"_blank\" rel=\"noopener\">https://docs.python.org/3.4/library/exceptions.html</a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Example of Syntax errors</span></span><br><span class=\"line\"><span class=\"comment\"># while True print(\"Hello World!\")</span></span><br><span class=\"line\"><span class=\"comment\">#Examples of exceptions</span></span><br><span class=\"line\"><span class=\"comment\"># print(8/0)</span></span><br><span class=\"line\"><span class=\"comment\"># print(hello * 4)</span></span><br><span class=\"line\"><span class=\"comment\"># num = 6</span></span><br><span class=\"line\"><span class=\"comment\"># print(\"Hello World \" + num )</span></span><br><span class=\"line\"><span class=\"comment\">#Handling exceptions</span></span><br><span class=\"line\"><span class=\"comment\"># while True:</span></span><br><span class=\"line\"><span class=\"comment\">#     try:</span></span><br><span class=\"line\"><span class=\"comment\">#         x = int(input(\"Please enter a number\"))</span></span><br><span class=\"line\"><span class=\"comment\">#         break</span></span><br><span class=\"line\"><span class=\"comment\">#     except ValueError:</span></span><br><span class=\"line\"><span class=\"comment\">#         print(\"Not valid input, try again...\")</span></span><br></pre></td></tr></table></figure></p>"},{"title":"Python学习笔记（七）END","date":"2017-06-27T08:33:38.000Z","comments":1,"reward":true,"_content":"1. 面向对象编程\nPython支持面向对象编程\n类(class)：现实世界中一些事物的封装 （如：学生）\n类：属性 （如：名字，成绩）\n类对象\n实例对象\n引用：通过引用对类的属性和方法进行操作\n实例化：创建一个类的具体实例对象 （如：学生张三）\n<!-- more -->\n``` bash\n#Python OO example\nclass Student:\n    def __init__(self, name, grade):\n        self.name = name\n        self.grade = grade\n        \n    def introduce(self):\n        print(\"hi! I'm \" + self.name)\n        print(\"my grade is: \" + str(self.grade))\n        \n    def improve(self, amount):\n        self.grade = self.grade + amount\njim = Student(\"jim\", 86)\njim.introduce()\njim.improve(10)\njim.introduce()\n```\n2. 装饰器(decorator)\n``` bash\n# def add_candles(cake_func):\n#     def insert_candles():\n#         return cake_func() + \" candles\"\n#     return insert_candles\n#  \n# def make_cake():\n#     return \"cake\"\n#  \n# gift_func = add_candles(make_cake)\n#  \n# print(make_cake())\n# print(gift_func())\n# def add_candles(cake_func):\n#     def insert_candles():\n#         return cake_func() + \" candles\"\n#     return insert_candles\n#   \n# def make_cake():\n#     return \"cake\"\n#   \n# make_cake = add_candles(make_cake)\n#   \n# print(make_cake())\n# # print(gift_func)\n# def add_candles(cake_func):\n#     def insert_candles():\n#         return cake_func() + \" and candles\"\n#     return insert_candles\n# \n# @add_candles\n# def make_cake():\n#     return \"cake\"\n#  \n# # make_cake = add_candles(make_cake)\n#  \n# print(make_cake())\n# # print(gift_func)\n```\n\n3. GUI： Graphical User Interface\n4. tkinter: GUI library for Python\n5. GUI Example\n``` bash\n# -*- coding: utf-8 -*-\nfrom tkinter import *\nimport tkinter.simpledialog as dl\nimport tkinter.messagebox as mb\n#tkinter GUI Input Output Example\n#设置GUI\nroot = Tk()\nw = Label(root, text = \"Label Title\")\nw.pack()\n \n#欢迎消息\nmb.showinfo(\"Welcome\", \"Welcome Message\")\nguess = dl.askinteger(\"Number\", \"Enter a number\")\n \noutput = 'This is output message'\nmb.showinfo(\"Output: \", output)\n```\n6.猜数字游戏代码\n``` bash\n# #设置GUI\n# root = Tk()\n# w = Label(root, text = \"Guess Number Game\")\n# w.pack()\n#  \n# #欢迎消息\n# mb.showinfo(\"Welcome\", \"Welcome to Guess Number Game\")\n#  \n#  \n# #处理信息\n# number = 59\n#  \n# while True:\n# #让用户输入信息\n#     guess = dl.askinteger(\"Number\", \"What's your guess?\")\n#        \n#     if guess == number:\n#         # New block starts here\n#         output = 'Bingo! you guessed it right, but you do not win any prizes!'\n#         mb.showinfo(\"Hint: \", output)\n#         break\n#         # New block ends here\n#     elif guess < number:\n#         output = 'No, the number is a  higer than that'\n#         mb.showinfo(\"Hint: \", output)\n#     else:\n#         output = 'No, the number is a  lower than that'\n#         mb.showinfo(\"Hint: \", output)\n#     \n# print('Done')\n```\n7.网页编程介绍\n7.1. 下载并安装python 2.7 32 bit\n7.2. 下载并安装easy_install windows installer (python 2.7 32bit)\n7.3. 安装 lpthw.web\n   windows 命令行：  C:\\Python27\\Scripts\\easy_install lpthw.web\n7.4. 创建目录 C:\\Users\\plg519\\Maizi\\TeachingPython\\gotoweb\\bin\n7.5. 目录下创建 app.py:\n``` bash\nimport web\nurls = (\n  '/', 'index'\n)\napp = web.application(urls, globals())\nclass index:\n    def GET(self):\n        greeting = \"Hello World\"\n        return greeting\nif __name__ == \"__main__\":\n    app.run()\n```\n7.6. Windows cmd 运行：\ncd  C:\\Users\\plg519\\Maizi\\TeachingPython\\gotoweb\\bin\nC:\\python27\\python27 app.py\n7.7. 打开浏览器：localhost：8080","source":"_posts/2017-6-27-four.md","raw":"---\ntitle: Python学习笔记（七）END\ndate: 2017-06-27 16:33:38\ncomments: true\nreward: true\ntags: \n - python\n---\n1. 面向对象编程\nPython支持面向对象编程\n类(class)：现实世界中一些事物的封装 （如：学生）\n类：属性 （如：名字，成绩）\n类对象\n实例对象\n引用：通过引用对类的属性和方法进行操作\n实例化：创建一个类的具体实例对象 （如：学生张三）\n<!-- more -->\n``` bash\n#Python OO example\nclass Student:\n    def __init__(self, name, grade):\n        self.name = name\n        self.grade = grade\n        \n    def introduce(self):\n        print(\"hi! I'm \" + self.name)\n        print(\"my grade is: \" + str(self.grade))\n        \n    def improve(self, amount):\n        self.grade = self.grade + amount\njim = Student(\"jim\", 86)\njim.introduce()\njim.improve(10)\njim.introduce()\n```\n2. 装饰器(decorator)\n``` bash\n# def add_candles(cake_func):\n#     def insert_candles():\n#         return cake_func() + \" candles\"\n#     return insert_candles\n#  \n# def make_cake():\n#     return \"cake\"\n#  \n# gift_func = add_candles(make_cake)\n#  \n# print(make_cake())\n# print(gift_func())\n# def add_candles(cake_func):\n#     def insert_candles():\n#         return cake_func() + \" candles\"\n#     return insert_candles\n#   \n# def make_cake():\n#     return \"cake\"\n#   \n# make_cake = add_candles(make_cake)\n#   \n# print(make_cake())\n# # print(gift_func)\n# def add_candles(cake_func):\n#     def insert_candles():\n#         return cake_func() + \" and candles\"\n#     return insert_candles\n# \n# @add_candles\n# def make_cake():\n#     return \"cake\"\n#  \n# # make_cake = add_candles(make_cake)\n#  \n# print(make_cake())\n# # print(gift_func)\n```\n\n3. GUI： Graphical User Interface\n4. tkinter: GUI library for Python\n5. GUI Example\n``` bash\n# -*- coding: utf-8 -*-\nfrom tkinter import *\nimport tkinter.simpledialog as dl\nimport tkinter.messagebox as mb\n#tkinter GUI Input Output Example\n#设置GUI\nroot = Tk()\nw = Label(root, text = \"Label Title\")\nw.pack()\n \n#欢迎消息\nmb.showinfo(\"Welcome\", \"Welcome Message\")\nguess = dl.askinteger(\"Number\", \"Enter a number\")\n \noutput = 'This is output message'\nmb.showinfo(\"Output: \", output)\n```\n6.猜数字游戏代码\n``` bash\n# #设置GUI\n# root = Tk()\n# w = Label(root, text = \"Guess Number Game\")\n# w.pack()\n#  \n# #欢迎消息\n# mb.showinfo(\"Welcome\", \"Welcome to Guess Number Game\")\n#  \n#  \n# #处理信息\n# number = 59\n#  \n# while True:\n# #让用户输入信息\n#     guess = dl.askinteger(\"Number\", \"What's your guess?\")\n#        \n#     if guess == number:\n#         # New block starts here\n#         output = 'Bingo! you guessed it right, but you do not win any prizes!'\n#         mb.showinfo(\"Hint: \", output)\n#         break\n#         # New block ends here\n#     elif guess < number:\n#         output = 'No, the number is a  higer than that'\n#         mb.showinfo(\"Hint: \", output)\n#     else:\n#         output = 'No, the number is a  lower than that'\n#         mb.showinfo(\"Hint: \", output)\n#     \n# print('Done')\n```\n7.网页编程介绍\n7.1. 下载并安装python 2.7 32 bit\n7.2. 下载并安装easy_install windows installer (python 2.7 32bit)\n7.3. 安装 lpthw.web\n   windows 命令行：  C:\\Python27\\Scripts\\easy_install lpthw.web\n7.4. 创建目录 C:\\Users\\plg519\\Maizi\\TeachingPython\\gotoweb\\bin\n7.5. 目录下创建 app.py:\n``` bash\nimport web\nurls = (\n  '/', 'index'\n)\napp = web.application(urls, globals())\nclass index:\n    def GET(self):\n        greeting = \"Hello World\"\n        return greeting\nif __name__ == \"__main__\":\n    app.run()\n```\n7.6. Windows cmd 运行：\ncd  C:\\Users\\plg519\\Maizi\\TeachingPython\\gotoweb\\bin\nC:\\python27\\python27 app.py\n7.7. 打开浏览器：localhost：8080","slug":"2017-6-27-four","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m000tycvjvlf6ma4j","content":"<ol>\n<li><p>面向对象编程<br>Python支持面向对象编程<br>类(class)：现实世界中一些事物的封装 （如：学生）<br>类：属性 （如：名字，成绩）<br>类对象<br>实例对象<br>引用：通过引用对类的属性和方法进行操作<br>实例化：创建一个类的具体实例对象 （如：学生张三）</p>\n<a id=\"more\"></a>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Python OO example</span></span><br><span class=\"line\">class Student:</span><br><span class=\"line\">    def __init__(self, name, grade):</span><br><span class=\"line\">        self.name = name</span><br><span class=\"line\">        self.grade = grade</span><br><span class=\"line\">        </span><br><span class=\"line\">    def introduce(self):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">\"hi! I'm \"</span> + self.name)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">\"my grade is: \"</span> + str(self.grade))</span><br><span class=\"line\">        </span><br><span class=\"line\">    def improve(self, amount):</span><br><span class=\"line\">        self.grade = self.grade + amount</span><br><span class=\"line\">jim = Student(<span class=\"string\">\"jim\"</span>, 86)</span><br><span class=\"line\">jim.introduce()</span><br><span class=\"line\">jim.improve(10)</span><br><span class=\"line\">jim.introduce()</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>装饰器(decorator)</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># def add_candles(cake_func):</span></span><br><span class=\"line\"><span class=\"comment\">#     def insert_candles():</span></span><br><span class=\"line\"><span class=\"comment\">#         return cake_func() + \" candles\"</span></span><br><span class=\"line\"><span class=\"comment\">#     return insert_candles</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># def make_cake():</span></span><br><span class=\"line\"><span class=\"comment\">#     return \"cake\"</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># gift_func = add_candles(make_cake)</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># print(make_cake())</span></span><br><span class=\"line\"><span class=\"comment\"># print(gift_func())</span></span><br><span class=\"line\"><span class=\"comment\"># def add_candles(cake_func):</span></span><br><span class=\"line\"><span class=\"comment\">#     def insert_candles():</span></span><br><span class=\"line\"><span class=\"comment\">#         return cake_func() + \" candles\"</span></span><br><span class=\"line\"><span class=\"comment\">#     return insert_candles</span></span><br><span class=\"line\"><span class=\"comment\">#   </span></span><br><span class=\"line\"><span class=\"comment\"># def make_cake():</span></span><br><span class=\"line\"><span class=\"comment\">#     return \"cake\"</span></span><br><span class=\"line\"><span class=\"comment\">#   </span></span><br><span class=\"line\"><span class=\"comment\"># make_cake = add_candles(make_cake)</span></span><br><span class=\"line\"><span class=\"comment\">#   </span></span><br><span class=\"line\"><span class=\"comment\"># print(make_cake())</span></span><br><span class=\"line\"><span class=\"comment\"># # print(gift_func)</span></span><br><span class=\"line\"><span class=\"comment\"># def add_candles(cake_func):</span></span><br><span class=\"line\"><span class=\"comment\">#     def insert_candles():</span></span><br><span class=\"line\"><span class=\"comment\">#         return cake_func() + \" and candles\"</span></span><br><span class=\"line\"><span class=\"comment\">#     return insert_candles</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># @add_candles</span></span><br><span class=\"line\"><span class=\"comment\"># def make_cake():</span></span><br><span class=\"line\"><span class=\"comment\">#     return \"cake\"</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># # make_cake = add_candles(make_cake)</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># print(make_cake())</span></span><br><span class=\"line\"><span class=\"comment\"># # print(gift_func)</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>GUI： Graphical User Interface</p>\n</li>\n<li>tkinter: GUI library for Python</li>\n<li>GUI Example<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\">from tkinter import *</span><br><span class=\"line\">import tkinter.simpledialog as dl</span><br><span class=\"line\">import tkinter.messagebox as mb</span><br><span class=\"line\"><span class=\"comment\">#tkinter GUI Input Output Example</span></span><br><span class=\"line\"><span class=\"comment\">#设置GUI</span></span><br><span class=\"line\">root = Tk()</span><br><span class=\"line\">w = Label(root, text = <span class=\"string\">\"Label Title\"</span>)</span><br><span class=\"line\">w.pack()</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">#欢迎消息</span></span><br><span class=\"line\">mb.showinfo(<span class=\"string\">\"Welcome\"</span>, <span class=\"string\">\"Welcome Message\"</span>)</span><br><span class=\"line\">guess = dl.askinteger(<span class=\"string\">\"Number\"</span>, <span class=\"string\">\"Enter a number\"</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\">output = <span class=\"string\">'This is output message'</span></span><br><span class=\"line\">mb.showinfo(<span class=\"string\">\"Output: \"</span>, output)</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>6.猜数字游戏代码<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># #设置GUI</span></span><br><span class=\"line\"><span class=\"comment\"># root = Tk()</span></span><br><span class=\"line\"><span class=\"comment\"># w = Label(root, text = \"Guess Number Game\")</span></span><br><span class=\"line\"><span class=\"comment\"># w.pack()</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># #欢迎消息</span></span><br><span class=\"line\"><span class=\"comment\"># mb.showinfo(\"Welcome\", \"Welcome to Guess Number Game\")</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># #处理信息</span></span><br><span class=\"line\"><span class=\"comment\"># number = 59</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># while True:</span></span><br><span class=\"line\"><span class=\"comment\"># #让用户输入信息</span></span><br><span class=\"line\"><span class=\"comment\">#     guess = dl.askinteger(\"Number\", \"What's your guess?\")</span></span><br><span class=\"line\"><span class=\"comment\">#        </span></span><br><span class=\"line\"><span class=\"comment\">#     if guess == number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # New block starts here</span></span><br><span class=\"line\"><span class=\"comment\">#         output = 'Bingo! you guessed it right, but you do not win any prizes!'</span></span><br><span class=\"line\"><span class=\"comment\">#         mb.showinfo(\"Hint: \", output)</span></span><br><span class=\"line\"><span class=\"comment\">#         break</span></span><br><span class=\"line\"><span class=\"comment\">#         # New block ends here</span></span><br><span class=\"line\"><span class=\"comment\">#     elif guess &lt; number:</span></span><br><span class=\"line\"><span class=\"comment\">#         output = 'No, the number is a  higer than that'</span></span><br><span class=\"line\"><span class=\"comment\">#         mb.showinfo(\"Hint: \", output)</span></span><br><span class=\"line\"><span class=\"comment\">#     else:</span></span><br><span class=\"line\"><span class=\"comment\">#         output = 'No, the number is a  lower than that'</span></span><br><span class=\"line\"><span class=\"comment\">#         mb.showinfo(\"Hint: \", output)</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># print('Done')</span></span><br></pre></td></tr></table></figure></p>\n<p>7.网页编程介绍<br>7.1. 下载并安装python 2.7 32 bit<br>7.2. 下载并安装easy_install windows installer (python 2.7 32bit)<br>7.3. 安装 lpthw.web<br>   windows 命令行：  C:\\Python27\\Scripts\\easy_install lpthw.web<br>7.4. 创建目录 C:\\Users\\plg519\\Maizi\\TeachingPython\\gotoweb\\bin<br>7.5. 目录下创建 app.py:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import web</span><br><span class=\"line\">urls = (</span><br><span class=\"line\">  <span class=\"string\">'/'</span>, <span class=\"string\">'index'</span></span><br><span class=\"line\">)</span><br><span class=\"line\">app = web.application(urls, globals())</span><br><span class=\"line\">class index:</span><br><span class=\"line\">    def GET(self):</span><br><span class=\"line\">        greeting = <span class=\"string\">\"Hello World\"</span></span><br><span class=\"line\">        <span class=\"built_in\">return</span> greeting</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    app.run()</span><br></pre></td></tr></table></figure></p>\n<p>7.6. Windows cmd 运行：<br>cd  C:\\Users\\plg519\\Maizi\\TeachingPython\\gotoweb\\bin<br>C:\\python27\\python27 app.py<br>7.7. 打开浏览器：localhost：8080</p>\n","site":{"data":{}},"excerpt":"<ol>\n<li><p>面向对象编程<br>Python支持面向对象编程<br>类(class)：现实世界中一些事物的封装 （如：学生）<br>类：属性 （如：名字，成绩）<br>类对象<br>实例对象<br>引用：通过引用对类的属性和方法进行操作<br>实例化：创建一个类的具体实例对象 （如：学生张三）</p></li></ol>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Python OO example</span></span><br><span class=\"line\">class Student:</span><br><span class=\"line\">    def __init__(self, name, grade):</span><br><span class=\"line\">        self.name = name</span><br><span class=\"line\">        self.grade = grade</span><br><span class=\"line\">        </span><br><span class=\"line\">    def introduce(self):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">\"hi! I'm \"</span> + self.name)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">\"my grade is: \"</span> + str(self.grade))</span><br><span class=\"line\">        </span><br><span class=\"line\">    def improve(self, amount):</span><br><span class=\"line\">        self.grade = self.grade + amount</span><br><span class=\"line\">jim = Student(<span class=\"string\">\"jim\"</span>, 86)</span><br><span class=\"line\">jim.introduce()</span><br><span class=\"line\">jim.improve(10)</span><br><span class=\"line\">jim.introduce()</span><br></pre></td></tr></table></figure>\n\n<li><p>装饰器(decorator)</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># def add_candles(cake_func):</span></span><br><span class=\"line\"><span class=\"comment\">#     def insert_candles():</span></span><br><span class=\"line\"><span class=\"comment\">#         return cake_func() + \" candles\"</span></span><br><span class=\"line\"><span class=\"comment\">#     return insert_candles</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># def make_cake():</span></span><br><span class=\"line\"><span class=\"comment\">#     return \"cake\"</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># gift_func = add_candles(make_cake)</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># print(make_cake())</span></span><br><span class=\"line\"><span class=\"comment\"># print(gift_func())</span></span><br><span class=\"line\"><span class=\"comment\"># def add_candles(cake_func):</span></span><br><span class=\"line\"><span class=\"comment\">#     def insert_candles():</span></span><br><span class=\"line\"><span class=\"comment\">#         return cake_func() + \" candles\"</span></span><br><span class=\"line\"><span class=\"comment\">#     return insert_candles</span></span><br><span class=\"line\"><span class=\"comment\">#   </span></span><br><span class=\"line\"><span class=\"comment\"># def make_cake():</span></span><br><span class=\"line\"><span class=\"comment\">#     return \"cake\"</span></span><br><span class=\"line\"><span class=\"comment\">#   </span></span><br><span class=\"line\"><span class=\"comment\"># make_cake = add_candles(make_cake)</span></span><br><span class=\"line\"><span class=\"comment\">#   </span></span><br><span class=\"line\"><span class=\"comment\"># print(make_cake())</span></span><br><span class=\"line\"><span class=\"comment\"># # print(gift_func)</span></span><br><span class=\"line\"><span class=\"comment\"># def add_candles(cake_func):</span></span><br><span class=\"line\"><span class=\"comment\">#     def insert_candles():</span></span><br><span class=\"line\"><span class=\"comment\">#         return cake_func() + \" and candles\"</span></span><br><span class=\"line\"><span class=\"comment\">#     return insert_candles</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># @add_candles</span></span><br><span class=\"line\"><span class=\"comment\"># def make_cake():</span></span><br><span class=\"line\"><span class=\"comment\">#     return \"cake\"</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># # make_cake = add_candles(make_cake)</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># print(make_cake())</span></span><br><span class=\"line\"><span class=\"comment\"># # print(gift_func)</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>GUI： Graphical User Interface</p>\n</li>\n<li>tkinter: GUI library for Python</li>\n<li>GUI Example<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\">from tkinter import *</span><br><span class=\"line\">import tkinter.simpledialog as dl</span><br><span class=\"line\">import tkinter.messagebox as mb</span><br><span class=\"line\"><span class=\"comment\">#tkinter GUI Input Output Example</span></span><br><span class=\"line\"><span class=\"comment\">#设置GUI</span></span><br><span class=\"line\">root = Tk()</span><br><span class=\"line\">w = Label(root, text = <span class=\"string\">\"Label Title\"</span>)</span><br><span class=\"line\">w.pack()</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">#欢迎消息</span></span><br><span class=\"line\">mb.showinfo(<span class=\"string\">\"Welcome\"</span>, <span class=\"string\">\"Welcome Message\"</span>)</span><br><span class=\"line\">guess = dl.askinteger(<span class=\"string\">\"Number\"</span>, <span class=\"string\">\"Enter a number\"</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\">output = <span class=\"string\">'This is output message'</span></span><br><span class=\"line\">mb.showinfo(<span class=\"string\">\"Output: \"</span>, output)</span><br></pre></td></tr></table></figure>\n</li>\n\n<p>6.猜数字游戏代码<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># #设置GUI</span></span><br><span class=\"line\"><span class=\"comment\"># root = Tk()</span></span><br><span class=\"line\"><span class=\"comment\"># w = Label(root, text = \"Guess Number Game\")</span></span><br><span class=\"line\"><span class=\"comment\"># w.pack()</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># #欢迎消息</span></span><br><span class=\"line\"><span class=\"comment\"># mb.showinfo(\"Welcome\", \"Welcome to Guess Number Game\")</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># #处理信息</span></span><br><span class=\"line\"><span class=\"comment\"># number = 59</span></span><br><span class=\"line\"><span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># while True:</span></span><br><span class=\"line\"><span class=\"comment\"># #让用户输入信息</span></span><br><span class=\"line\"><span class=\"comment\">#     guess = dl.askinteger(\"Number\", \"What's your guess?\")</span></span><br><span class=\"line\"><span class=\"comment\">#        </span></span><br><span class=\"line\"><span class=\"comment\">#     if guess == number:</span></span><br><span class=\"line\"><span class=\"comment\">#         # New block starts here</span></span><br><span class=\"line\"><span class=\"comment\">#         output = 'Bingo! you guessed it right, but you do not win any prizes!'</span></span><br><span class=\"line\"><span class=\"comment\">#         mb.showinfo(\"Hint: \", output)</span></span><br><span class=\"line\"><span class=\"comment\">#         break</span></span><br><span class=\"line\"><span class=\"comment\">#         # New block ends here</span></span><br><span class=\"line\"><span class=\"comment\">#     elif guess &lt; number:</span></span><br><span class=\"line\"><span class=\"comment\">#         output = 'No, the number is a  higer than that'</span></span><br><span class=\"line\"><span class=\"comment\">#         mb.showinfo(\"Hint: \", output)</span></span><br><span class=\"line\"><span class=\"comment\">#     else:</span></span><br><span class=\"line\"><span class=\"comment\">#         output = 'No, the number is a  lower than that'</span></span><br><span class=\"line\"><span class=\"comment\">#         mb.showinfo(\"Hint: \", output)</span></span><br><span class=\"line\"><span class=\"comment\">#     </span></span><br><span class=\"line\"><span class=\"comment\"># print('Done')</span></span><br></pre></td></tr></table></figure></p>\n<p>7.网页编程介绍<br>7.1. 下载并安装python 2.7 32 bit<br>7.2. 下载并安装easy_install windows installer (python 2.7 32bit)<br>7.3. 安装 lpthw.web<br>   windows 命令行：  C:\\Python27\\Scripts\\easy_install lpthw.web<br>7.4. 创建目录 C:\\Users\\plg519\\Maizi\\TeachingPython\\gotoweb\\bin<br>7.5. 目录下创建 app.py:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import web</span><br><span class=\"line\">urls = (</span><br><span class=\"line\">  <span class=\"string\">'/'</span>, <span class=\"string\">'index'</span></span><br><span class=\"line\">)</span><br><span class=\"line\">app = web.application(urls, globals())</span><br><span class=\"line\">class index:</span><br><span class=\"line\">    def GET(self):</span><br><span class=\"line\">        greeting = <span class=\"string\">\"Hello World\"</span></span><br><span class=\"line\">        <span class=\"built_in\">return</span> greeting</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    app.run()</span><br></pre></td></tr></table></figure></p>\n<p>7.6. Windows cmd 运行：<br>cd  C:\\Users\\plg519\\Maizi\\TeachingPython\\gotoweb\\bin<br>C:\\python27\\python27 app.py<br>7.7. 打开浏览器：localhost：8080</p>"},{"title":"机器学习笔记（三）决策树算法代码与应用","date":"2017-06-27T07:22:31.000Z","comments":1,"reward":true,"_content":"1. Python\n2.  Python机器学习的库：scikit-learn\n2.1： 特性：\n简单高效的数据挖掘和机器学习分析\n对所有用户开放，根据不同需求高度可重用性\n基于Numpy, SciPy和matplotlib\n开源，商用级别：获得 BSD许可\n2.2 覆盖问题领域：\n分类（classification), 回归（regression), 聚类（clustering), 降维(dimensionality reduction)\n模型选择(model selection), 预处理(preprocessing)\n3. 使用用scikit-learn\n安装scikit-learn: pip, easy_install, windows installer\n安装必要package：numpy， SciPy和matplotlib， 可使用Anaconda (包含numpy, scipy等科学计算常用package）\n安装注意问题：Python解释器版本（2.7 or 3.4？）, 32-bit or 64-bit系统\n4. 例子：  \n文档： http://scikit-learn.org/stable/modules/tree.html\nDecesionTree 代码\n<!-- more -->\n``` bash\nfrom sklearn.feature_extraction import DictVectorizer\nimport csv\nfrom sklearn import tree\nfrom sklearn import preprocessing\nfrom sklearn.externals.six import StringIO\n#Read in the csv file and put features into list of dict and list of class label\nallElectronicsData = open(r'C:\\Users\\Administrator\\workspace\\Machinelearning\\DecesionTree\\data.csv', 'rb')\nreader = csv.reader(allElectronicsData)\nheaders = reader.next()\nprint(headers)\nfeatureList = []\nlabelList = []\nfor row in reader:\n    labelList.append(row[len(row)-1])\n    rowDict = {} #Dictionary \n    for i in range(1, len(row)-1):\n        rowDict[headers[i]] = row[i]\n    featureList.append(rowDict)\nprint(labelList)\n#Vetorize features\nvec = DictVectorizer()\ndummyX = vec.fit_transform(featureList) .toarray()\nprint(\"dummyX: \" + str(dummyX))\nprint(vec.get_feature_names())\n#vectorize class labels\nlb = preprocessing.LabelBinarizer()\ndummyY = lb.fit_transform(labelList)\nprint(\"dummyY: \" + str(dummyY))\n#Using decision tree for classification\n#clf = tree.DecisionTreeClassifier()\nclf = tree.DecisionTreeClassifier(criterion='entropy')\nclf = clf.fit(dummyX, dummyY)\nprint(\"clf: \" + str(clf))\n# Visualize model\nwith open(\"DataAfterDecesionTree.dot\", 'w') as f:\n    f = tree.export_graphviz(clf, feature_names=vec.get_feature_names(), out_file=f)\n#Predict   \noneRowX = dummyX[0, :]\nprint(\"oneRowX: \" + str(oneRowX))\nnewRowX = oneRowX\nnewRowX[0] = 1\nnewRowX[2] = 0\nprint(\"newRowX: \" + str(newRowX))\npredictedY = clf.predict(newRowX)\nprint(\"predictedY: \" + str(predictedY))\n```\n安装 Graphviz： http://www.graphviz.org/\n可以将决策树图形化直接输出决策树图形\n配置环境变量\n转化dot文件至pdf可视化决策树：dot -Tpdf iris.dot -o outpu.pdf\n","source":"_posts/2017-6-27-two.md","raw":"---\ntitle: 机器学习笔记（三）决策树算法代码与应用\ndate: 2017-06-27 15:22:31\ncomments: true\nreward: true\ntags: \n - 机器学习\n---\n1. Python\n2.  Python机器学习的库：scikit-learn\n2.1： 特性：\n简单高效的数据挖掘和机器学习分析\n对所有用户开放，根据不同需求高度可重用性\n基于Numpy, SciPy和matplotlib\n开源，商用级别：获得 BSD许可\n2.2 覆盖问题领域：\n分类（classification), 回归（regression), 聚类（clustering), 降维(dimensionality reduction)\n模型选择(model selection), 预处理(preprocessing)\n3. 使用用scikit-learn\n安装scikit-learn: pip, easy_install, windows installer\n安装必要package：numpy， SciPy和matplotlib， 可使用Anaconda (包含numpy, scipy等科学计算常用package）\n安装注意问题：Python解释器版本（2.7 or 3.4？）, 32-bit or 64-bit系统\n4. 例子：  \n文档： http://scikit-learn.org/stable/modules/tree.html\nDecesionTree 代码\n<!-- more -->\n``` bash\nfrom sklearn.feature_extraction import DictVectorizer\nimport csv\nfrom sklearn import tree\nfrom sklearn import preprocessing\nfrom sklearn.externals.six import StringIO\n#Read in the csv file and put features into list of dict and list of class label\nallElectronicsData = open(r'C:\\Users\\Administrator\\workspace\\Machinelearning\\DecesionTree\\data.csv', 'rb')\nreader = csv.reader(allElectronicsData)\nheaders = reader.next()\nprint(headers)\nfeatureList = []\nlabelList = []\nfor row in reader:\n    labelList.append(row[len(row)-1])\n    rowDict = {} #Dictionary \n    for i in range(1, len(row)-1):\n        rowDict[headers[i]] = row[i]\n    featureList.append(rowDict)\nprint(labelList)\n#Vetorize features\nvec = DictVectorizer()\ndummyX = vec.fit_transform(featureList) .toarray()\nprint(\"dummyX: \" + str(dummyX))\nprint(vec.get_feature_names())\n#vectorize class labels\nlb = preprocessing.LabelBinarizer()\ndummyY = lb.fit_transform(labelList)\nprint(\"dummyY: \" + str(dummyY))\n#Using decision tree for classification\n#clf = tree.DecisionTreeClassifier()\nclf = tree.DecisionTreeClassifier(criterion='entropy')\nclf = clf.fit(dummyX, dummyY)\nprint(\"clf: \" + str(clf))\n# Visualize model\nwith open(\"DataAfterDecesionTree.dot\", 'w') as f:\n    f = tree.export_graphviz(clf, feature_names=vec.get_feature_names(), out_file=f)\n#Predict   \noneRowX = dummyX[0, :]\nprint(\"oneRowX: \" + str(oneRowX))\nnewRowX = oneRowX\nnewRowX[0] = 1\nnewRowX[2] = 0\nprint(\"newRowX: \" + str(newRowX))\npredictedY = clf.predict(newRowX)\nprint(\"predictedY: \" + str(predictedY))\n```\n安装 Graphviz： http://www.graphviz.org/\n可以将决策树图形化直接输出决策树图形\n配置环境变量\n转化dot文件至pdf可视化决策树：dot -Tpdf iris.dot -o outpu.pdf\n","slug":"2017-6-27-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m000vycvjdgusaeo4","content":"<ol>\n<li>Python</li>\n<li>Python机器学习的库：scikit-learn<br>2.1： 特性：<br>简单高效的数据挖掘和机器学习分析<br>对所有用户开放，根据不同需求高度可重用性<br>基于Numpy, SciPy和matplotlib<br>开源，商用级别：获得 BSD许可<br>2.2 覆盖问题领域：<br>分类（classification), 回归（regression), 聚类（clustering), 降维(dimensionality reduction)<br>模型选择(model selection), 预处理(preprocessing)</li>\n<li>使用用scikit-learn<br>安装scikit-learn: pip, easy_install, windows installer<br>安装必要package：numpy， SciPy和matplotlib， 可使用Anaconda (包含numpy, scipy等科学计算常用package）<br>安装注意问题：Python解释器版本（2.7 or 3.4？）, 32-bit or 64-bit系统</li>\n<li>例子：<br>文档： <a href=\"http://scikit-learn.org/stable/modules/tree.html\" target=\"_blank\" rel=\"noopener\">http://scikit-learn.org/stable/modules/tree.html</a><br>DecesionTree 代码<a id=\"more\"></a>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from sklearn.feature_extraction import DictVectorizer</span><br><span class=\"line\">import csv</span><br><span class=\"line\">from sklearn import tree</span><br><span class=\"line\">from sklearn import preprocessing</span><br><span class=\"line\">from sklearn.externals.six import StringIO</span><br><span class=\"line\"><span class=\"comment\">#Read in the csv file and put features into list of dict and list of class label</span></span><br><span class=\"line\">allElectronicsData = open(r<span class=\"string\">'C:\\Users\\Administrator\\workspace\\Machinelearning\\DecesionTree\\data.csv'</span>, <span class=\"string\">'rb'</span>)</span><br><span class=\"line\">reader = csv.reader(allElectronicsData)</span><br><span class=\"line\">headers = reader.next()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(headers)</span><br><span class=\"line\">featureList = []</span><br><span class=\"line\">labelList = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> reader:</span><br><span class=\"line\">    labelList.append(row[len(row)-1])</span><br><span class=\"line\">    rowDict = &#123;&#125; <span class=\"comment\">#Dictionary </span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1, len(row)-1):</span><br><span class=\"line\">        rowDict[headers[i]] = row[i]</span><br><span class=\"line\">    featureList.append(rowDict)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(labelList)</span><br><span class=\"line\"><span class=\"comment\">#Vetorize features</span></span><br><span class=\"line\">vec = DictVectorizer()</span><br><span class=\"line\">dummyX = vec.fit_transform(featureList) .toarray()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"dummyX: \"</span> + str(dummyX))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(vec.get_feature_names())</span><br><span class=\"line\"><span class=\"comment\">#vectorize class labels</span></span><br><span class=\"line\">lb = preprocessing.LabelBinarizer()</span><br><span class=\"line\">dummyY = lb.fit_transform(labelList)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"dummyY: \"</span> + str(dummyY))</span><br><span class=\"line\"><span class=\"comment\">#Using decision tree for classification</span></span><br><span class=\"line\"><span class=\"comment\">#clf = tree.DecisionTreeClassifier()</span></span><br><span class=\"line\">clf = tree.DecisionTreeClassifier(criterion=<span class=\"string\">'entropy'</span>)</span><br><span class=\"line\">clf = clf.fit(dummyX, dummyY)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"clf: \"</span> + str(clf))</span><br><span class=\"line\"><span class=\"comment\"># Visualize model</span></span><br><span class=\"line\">with open(<span class=\"string\">\"DataAfterDecesionTree.dot\"</span>, <span class=\"string\">'w'</span>) as f:</span><br><span class=\"line\">    f = tree.export_graphviz(clf, feature_names=vec.get_feature_names(), out_file=f)</span><br><span class=\"line\"><span class=\"comment\">#Predict   </span></span><br><span class=\"line\">oneRowX = dummyX[0, :]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"oneRowX: \"</span> + str(oneRowX))</span><br><span class=\"line\">newRowX = oneRowX</span><br><span class=\"line\">newRowX[0] = 1</span><br><span class=\"line\">newRowX[2] = 0</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"newRowX: \"</span> + str(newRowX))</span><br><span class=\"line\">predictedY = clf.predict(newRowX)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"predictedY: \"</span> + str(predictedY))</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>安装 Graphviz： <a href=\"http://www.graphviz.org/\" target=\"_blank\" rel=\"noopener\">http://www.graphviz.org/</a><br>可以将决策树图形化直接输出决策树图形<br>配置环境变量<br>转化dot文件至pdf可视化决策树：dot -Tpdf iris.dot -o outpu.pdf</p>\n","site":{"data":{}},"excerpt":"<ol>\n<li>Python</li>\n<li>Python机器学习的库：scikit-learn<br>2.1： 特性：<br>简单高效的数据挖掘和机器学习分析<br>对所有用户开放，根据不同需求高度可重用性<br>基于Numpy, SciPy和matplotlib<br>开源，商用级别：获得 BSD许可<br>2.2 覆盖问题领域：<br>分类（classification), 回归（regression), 聚类（clustering), 降维(dimensionality reduction)<br>模型选择(model selection), 预处理(preprocessing)</li>\n<li>使用用scikit-learn<br>安装scikit-learn: pip, easy_install, windows installer<br>安装必要package：numpy， SciPy和matplotlib， 可使用Anaconda (包含numpy, scipy等科学计算常用package）<br>安装注意问题：Python解释器版本（2.7 or 3.4？）, 32-bit or 64-bit系统</li>\n<li>例子：<br>文档： <a href=\"http://scikit-learn.org/stable/modules/tree.html\" target=\"_blank\" rel=\"noopener\">http://scikit-learn.org/stable/modules/tree.html</a><br>DecesionTree 代码</li></ol>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from sklearn.feature_extraction import DictVectorizer</span><br><span class=\"line\">import csv</span><br><span class=\"line\">from sklearn import tree</span><br><span class=\"line\">from sklearn import preprocessing</span><br><span class=\"line\">from sklearn.externals.six import StringIO</span><br><span class=\"line\"><span class=\"comment\">#Read in the csv file and put features into list of dict and list of class label</span></span><br><span class=\"line\">allElectronicsData = open(r<span class=\"string\">'C:\\Users\\Administrator\\workspace\\Machinelearning\\DecesionTree\\data.csv'</span>, <span class=\"string\">'rb'</span>)</span><br><span class=\"line\">reader = csv.reader(allElectronicsData)</span><br><span class=\"line\">headers = reader.next()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(headers)</span><br><span class=\"line\">featureList = []</span><br><span class=\"line\">labelList = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> reader:</span><br><span class=\"line\">    labelList.append(row[len(row)-1])</span><br><span class=\"line\">    rowDict = &#123;&#125; <span class=\"comment\">#Dictionary </span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1, len(row)-1):</span><br><span class=\"line\">        rowDict[headers[i]] = row[i]</span><br><span class=\"line\">    featureList.append(rowDict)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(labelList)</span><br><span class=\"line\"><span class=\"comment\">#Vetorize features</span></span><br><span class=\"line\">vec = DictVectorizer()</span><br><span class=\"line\">dummyX = vec.fit_transform(featureList) .toarray()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"dummyX: \"</span> + str(dummyX))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(vec.get_feature_names())</span><br><span class=\"line\"><span class=\"comment\">#vectorize class labels</span></span><br><span class=\"line\">lb = preprocessing.LabelBinarizer()</span><br><span class=\"line\">dummyY = lb.fit_transform(labelList)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"dummyY: \"</span> + str(dummyY))</span><br><span class=\"line\"><span class=\"comment\">#Using decision tree for classification</span></span><br><span class=\"line\"><span class=\"comment\">#clf = tree.DecisionTreeClassifier()</span></span><br><span class=\"line\">clf = tree.DecisionTreeClassifier(criterion=<span class=\"string\">'entropy'</span>)</span><br><span class=\"line\">clf = clf.fit(dummyX, dummyY)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"clf: \"</span> + str(clf))</span><br><span class=\"line\"><span class=\"comment\"># Visualize model</span></span><br><span class=\"line\">with open(<span class=\"string\">\"DataAfterDecesionTree.dot\"</span>, <span class=\"string\">'w'</span>) as f:</span><br><span class=\"line\">    f = tree.export_graphviz(clf, feature_names=vec.get_feature_names(), out_file=f)</span><br><span class=\"line\"><span class=\"comment\">#Predict   </span></span><br><span class=\"line\">oneRowX = dummyX[0, :]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"oneRowX: \"</span> + str(oneRowX))</span><br><span class=\"line\">newRowX = oneRowX</span><br><span class=\"line\">newRowX[0] = 1</span><br><span class=\"line\">newRowX[2] = 0</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"newRowX: \"</span> + str(newRowX))</span><br><span class=\"line\">predictedY = clf.predict(newRowX)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"predictedY: \"</span> + str(predictedY))</span><br></pre></td></tr></table></figure>\n\n\n<p>安装 Graphviz： <a href=\"http://www.graphviz.org/\" target=\"_blank\" rel=\"noopener\">http://www.graphviz.org/</a><br>可以将决策树图形化直接输出决策树图形<br>配置环境变量<br>转化dot文件至pdf可视化决策树：dot -Tpdf iris.dot -o outpu.pdf</p>"},{"title":"机器学习笔记（四）最临近分类算法原理（KNN）","date":"2017-06-28T13:31:09.000Z","comments":1,"reward":true,"_content":"1. 综述\n1.1Cover和Hart在1968年提出了最初的邻近算法\n1.2分类(classification)算法\n1.3输入基于实例的学习(instance-based learning), 懒惰学习(lazy learning)\n2. 例子：\n![](2017-6-28-one/1.png)\n<!-- more -->未知电影属于什么类型？\n![](2017-6-28-one/2.png)\n3. 算法详述\n3.1步骤：\n为了判断未知实例的类别，以所有已知类别的实例作为参照\n选择参数K\n计算未知实例与所有已知实例的距离\n选择最近K个已知实例\n根据少数服从多数的投票法则(majority-voting)，让未知实例归类为K个最邻近样本中最多数的类别\n3.2细节:\n关于K\n关于距离的衡量方法:\n3.2.1Euclidean Distance 定义\n![](2017-6-28-one/3.png)               \n其他距离衡量：余弦值（cos）, 相关度 （correlation）, 曼哈顿距离 （Manhattan distance）           \n3.3举例\n![](2017-6-28-one/4.png)  \n4. 算法优缺点：\n![](2017-6-28-one/5.png)\n4.1算法优点\n简单\n易于理解\n容易实现\n通过对K的选择可具备丢噪音数据的健壮性\n4.2算法缺点   需要大量空间储存所有已知实例\n算法复杂度高（需要比较所有已知实例与要分类的实例）\n当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，但这个新的未知实例实际并木接近目标样本\n5. 改进版本\n考虑距离，根据距离加上权重\n比如: 1/d (d: 距离）\n\n","source":"_posts/2017-6-28-one.md","raw":"---\ntitle: 机器学习笔记（四）最临近分类算法原理（KNN）\ndate: 2017-06-28 21:31:09\ncomments: true\nreward: true\ntags: \n - 机器学习\n---\n1. 综述\n1.1Cover和Hart在1968年提出了最初的邻近算法\n1.2分类(classification)算法\n1.3输入基于实例的学习(instance-based learning), 懒惰学习(lazy learning)\n2. 例子：\n![](2017-6-28-one/1.png)\n<!-- more -->未知电影属于什么类型？\n![](2017-6-28-one/2.png)\n3. 算法详述\n3.1步骤：\n为了判断未知实例的类别，以所有已知类别的实例作为参照\n选择参数K\n计算未知实例与所有已知实例的距离\n选择最近K个已知实例\n根据少数服从多数的投票法则(majority-voting)，让未知实例归类为K个最邻近样本中最多数的类别\n3.2细节:\n关于K\n关于距离的衡量方法:\n3.2.1Euclidean Distance 定义\n![](2017-6-28-one/3.png)               \n其他距离衡量：余弦值（cos）, 相关度 （correlation）, 曼哈顿距离 （Manhattan distance）           \n3.3举例\n![](2017-6-28-one/4.png)  \n4. 算法优缺点：\n![](2017-6-28-one/5.png)\n4.1算法优点\n简单\n易于理解\n容易实现\n通过对K的选择可具备丢噪音数据的健壮性\n4.2算法缺点   需要大量空间储存所有已知实例\n算法复杂度高（需要比较所有已知实例与要分类的实例）\n当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，但这个新的未知实例实际并木接近目标样本\n5. 改进版本\n考虑距离，根据距离加上权重\n比如: 1/d (d: 距离）\n\n","slug":"2017-6-28-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m000yycvjl165e327","content":"<ol>\n<li>综述<br>1.1Cover和Hart在1968年提出了最初的邻近算法<br>1.2分类(classification)算法<br>1.3输入基于实例的学习(instance-based learning), 懒惰学习(lazy learning)</li>\n<li>例子：<br><img src=\"/2017/06/28/2017-6-28-one/1.png\" alt=\"\"><br><a id=\"more\"></a>未知电影属于什么类型？<br><img src=\"/2017/06/28/2017-6-28-one/2.png\" alt=\"\"></li>\n<li>算法详述<br>3.1步骤：<br>为了判断未知实例的类别，以所有已知类别的实例作为参照<br>选择参数K<br>计算未知实例与所有已知实例的距离<br>选择最近K个已知实例<br>根据少数服从多数的投票法则(majority-voting)，让未知实例归类为K个最邻近样本中最多数的类别<br>3.2细节:<br>关于K<br>关于距离的衡量方法:<br>3.2.1Euclidean Distance 定义<br><img src=\"/2017/06/28/2017-6-28-one/3.png\" alt=\"\"><br>其他距离衡量：余弦值（cos）, 相关度 （correlation）, 曼哈顿距离 （Manhattan distance）<br>3.3举例<br><img src=\"/2017/06/28/2017-6-28-one/4.png\" alt=\"\">  </li>\n<li>算法优缺点：<br><img src=\"/2017/06/28/2017-6-28-one/5.png\" alt=\"\"><br>4.1算法优点<br>简单<br>易于理解<br>容易实现<br>通过对K的选择可具备丢噪音数据的健壮性<br>4.2算法缺点   需要大量空间储存所有已知实例<br>算法复杂度高（需要比较所有已知实例与要分类的实例）<br>当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，但这个新的未知实例实际并木接近目标样本</li>\n<li>改进版本<br>考虑距离，根据距离加上权重<br>比如: 1/d (d: 距离）</li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>综述<br>1.1Cover和Hart在1968年提出了最初的邻近算法<br>1.2分类(classification)算法<br>1.3输入基于实例的学习(instance-based learning), 懒惰学习(lazy learning)</li>\n<li>例子：<br><img src=\"/2017/06/28/2017-6-28-one/1.png\" alt=\"\"><br></li></ol>","more":"未知电影属于什么类型？<br><img src=\"/2017/06/28/2017-6-28-one/2.png\" alt=\"\">\n<li>算法详述<br>3.1步骤：<br>为了判断未知实例的类别，以所有已知类别的实例作为参照<br>选择参数K<br>计算未知实例与所有已知实例的距离<br>选择最近K个已知实例<br>根据少数服从多数的投票法则(majority-voting)，让未知实例归类为K个最邻近样本中最多数的类别<br>3.2细节:<br>关于K<br>关于距离的衡量方法:<br>3.2.1Euclidean Distance 定义<br><img src=\"/2017/06/28/2017-6-28-one/3.png\" alt=\"\"><br>其他距离衡量：余弦值（cos）, 相关度 （correlation）, 曼哈顿距离 （Manhattan distance）<br>3.3举例<br><img src=\"/2017/06/28/2017-6-28-one/4.png\" alt=\"\">  </li>\n<li>算法优缺点：<br><img src=\"/2017/06/28/2017-6-28-one/5.png\" alt=\"\"><br>4.1算法优点<br>简单<br>易于理解<br>容易实现<br>通过对K的选择可具备丢噪音数据的健壮性<br>4.2算法缺点   需要大量空间储存所有已知实例<br>算法复杂度高（需要比较所有已知实例与要分类的实例）<br>当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，但这个新的未知实例实际并木接近目标样本</li>\n<li>改进版本<br>考虑距离，根据距离加上权重<br>比如: 1/d (d: 距离）</li>\n"},{"title":"机器学习笔记（五）最临近分类算法应用（KNN）","date":"2017-06-28T13:31:19.000Z","comments":1,"reward":true,"_content":"1. 数据集介绍：\n虹膜\n![](2017-6-28-two/1.png)\n150个实例\n萼片长度，萼片宽度，花瓣长度，花瓣宽度\n(sepal length, sepal width, petal length and petal width）\n类别：\nIris setosa, Iris versicolor, Iris virginica.\n![](2017-6-28-two/2.png)\n<!-- more -->\n\n2. 利用Python的机器学习库sklearn: SkLearnExample.py\n``` bash\nfrom sklearn import neighbors\nfrom sklearn import datasets\nknn = neighbors.KNeighborsClassifier()\niris = datasets.load_iris()\nprint iris\nknn.fit(iris.data, iris.target)\npredictedLabel = knn.predict([[0.1, 0.2, 0.3, 0.4]])\nprint predictedLabel\n```\n3. 自编代码KNN 实现Implementation:\n``` bash\n# Example of kNN implemented from Scratch in Python\nimport csv\nimport random\nimport math\nimport operator\ndef loadDataset(filename, split, trainingSet=[] , testSet=[]):\n    with open(filename, 'rb') as csvfile:\n        lines = csv.reader(csvfile)\n        dataset = list(lines)\n        for x in range(len(dataset)-1):\n            for y in range(4):\n                dataset[x][y] = float(dataset[x][y])\n            if random.random() < split:\n                trainingSet.append(dataset[x])\n            else:\n                testSet.append(dataset[x])\ndef euclideanDistance(instance1, instance2, length):\n    distance = 0\n    for x in range(length):\n        distance += pow((instance1[x] - instance2[x]), 2)\n    return math.sqrt(distance)\ndef getNeighbors(trainingSet, testInstance, k):\n    distances = []\n    length = len(testInstance)-1\n    for x in range(len(trainingSet)):\n        dist = euclideanDistance(testInstance, trainingSet[x], length)\n        distances.append((trainingSet[x], dist))\n    distances.sort(key=operator.itemgetter(1))\n    neighbors = []\n    for x in range(k):\n        neighbors.append(distances[x][0])\n    return neighbors\ndef getResponse(neighbors):\n    classVotes = {}\n    for x in range(len(neighbors)):\n        response = neighbors[x][-1]\n        if response in classVotes:\n            classVotes[response] += 1\n        else:\n            classVotes[response] = 1\n    sortedVotes = sorted(classVotes.iteritems(), key=operator.itemgetter(1), reverse=True)\n    return sortedVotes[0][0]\ndef getAccuracy(testSet, predictions):\n    correct = 0\n    for x in range(len(testSet)):\n        if testSet[x][-1] == predictions[x]:\n            correct += 1\n    return (correct/float(len(testSet))) * 100.0\n    \ndef main():\n    # prepare data\n    trainingSet=[]\n    testSet=[]\n    split = 0.67\n    loadDataset(r'D:\\MaiziEdu\\DeepLearningBasics_MachineLearning\\Datasets\\iris.data.txt', split, trainingSet, testSet)\n    print 'Train set: ' + repr(len(trainingSet))\n    print 'Test set: ' + repr(len(testSet))\n    # generate predictions\n    predictions=[]\n    k = 3\n    for x in range(len(testSet)):\n        neighbors = getNeighbors(trainingSet, testSet[x], k)\n        result = getResponse(neighbors)\n        predictions.append(result)\n        print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n    accuracy = getAccuracy(testSet, predictions)\n    print('Accuracy: ' + repr(accuracy) + '%')\n```","source":"_posts/2017-6-28-two.md","raw":"---\ntitle: 机器学习笔记（五）最临近分类算法应用（KNN）\ndate: 2017-06-28 21:31:19\ncomments: true\nreward: true\ntags: \n - 机器学习\n---\n1. 数据集介绍：\n虹膜\n![](2017-6-28-two/1.png)\n150个实例\n萼片长度，萼片宽度，花瓣长度，花瓣宽度\n(sepal length, sepal width, petal length and petal width）\n类别：\nIris setosa, Iris versicolor, Iris virginica.\n![](2017-6-28-two/2.png)\n<!-- more -->\n\n2. 利用Python的机器学习库sklearn: SkLearnExample.py\n``` bash\nfrom sklearn import neighbors\nfrom sklearn import datasets\nknn = neighbors.KNeighborsClassifier()\niris = datasets.load_iris()\nprint iris\nknn.fit(iris.data, iris.target)\npredictedLabel = knn.predict([[0.1, 0.2, 0.3, 0.4]])\nprint predictedLabel\n```\n3. 自编代码KNN 实现Implementation:\n``` bash\n# Example of kNN implemented from Scratch in Python\nimport csv\nimport random\nimport math\nimport operator\ndef loadDataset(filename, split, trainingSet=[] , testSet=[]):\n    with open(filename, 'rb') as csvfile:\n        lines = csv.reader(csvfile)\n        dataset = list(lines)\n        for x in range(len(dataset)-1):\n            for y in range(4):\n                dataset[x][y] = float(dataset[x][y])\n            if random.random() < split:\n                trainingSet.append(dataset[x])\n            else:\n                testSet.append(dataset[x])\ndef euclideanDistance(instance1, instance2, length):\n    distance = 0\n    for x in range(length):\n        distance += pow((instance1[x] - instance2[x]), 2)\n    return math.sqrt(distance)\ndef getNeighbors(trainingSet, testInstance, k):\n    distances = []\n    length = len(testInstance)-1\n    for x in range(len(trainingSet)):\n        dist = euclideanDistance(testInstance, trainingSet[x], length)\n        distances.append((trainingSet[x], dist))\n    distances.sort(key=operator.itemgetter(1))\n    neighbors = []\n    for x in range(k):\n        neighbors.append(distances[x][0])\n    return neighbors\ndef getResponse(neighbors):\n    classVotes = {}\n    for x in range(len(neighbors)):\n        response = neighbors[x][-1]\n        if response in classVotes:\n            classVotes[response] += 1\n        else:\n            classVotes[response] = 1\n    sortedVotes = sorted(classVotes.iteritems(), key=operator.itemgetter(1), reverse=True)\n    return sortedVotes[0][0]\ndef getAccuracy(testSet, predictions):\n    correct = 0\n    for x in range(len(testSet)):\n        if testSet[x][-1] == predictions[x]:\n            correct += 1\n    return (correct/float(len(testSet))) * 100.0\n    \ndef main():\n    # prepare data\n    trainingSet=[]\n    testSet=[]\n    split = 0.67\n    loadDataset(r'D:\\MaiziEdu\\DeepLearningBasics_MachineLearning\\Datasets\\iris.data.txt', split, trainingSet, testSet)\n    print 'Train set: ' + repr(len(trainingSet))\n    print 'Test set: ' + repr(len(testSet))\n    # generate predictions\n    predictions=[]\n    k = 3\n    for x in range(len(testSet)):\n        neighbors = getNeighbors(trainingSet, testSet[x], k)\n        result = getResponse(neighbors)\n        predictions.append(result)\n        print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n    accuracy = getAccuracy(testSet, predictions)\n    print('Accuracy: ' + repr(accuracy) + '%')\n```","slug":"2017-6-28-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m0010ycvjnu8tgdu7","content":"<ol>\n<li><p>数据集介绍：<br>虹膜<br><img src=\"/2017/06/28/2017-6-28-two/1.png\" alt=\"\"><br>150个实例<br>萼片长度，萼片宽度，花瓣长度，花瓣宽度<br>(sepal length, sepal width, petal length and petal width）<br>类别：<br>Iris setosa, Iris versicolor, Iris virginica.<br><img src=\"/2017/06/28/2017-6-28-two/2.png\" alt=\"\"></p>\n<a id=\"more\"></a>\n</li>\n<li><p>利用Python的机器学习库sklearn: SkLearnExample.py</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from sklearn import neighbors</span><br><span class=\"line\">from sklearn import datasets</span><br><span class=\"line\">knn = neighbors.KNeighborsClassifier()</span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\"><span class=\"built_in\">print</span> iris</span><br><span class=\"line\">knn.fit(iris.data, iris.target)</span><br><span class=\"line\">predictedLabel = knn.predict([[0.1, 0.2, 0.3, 0.4]])</span><br><span class=\"line\"><span class=\"built_in\">print</span> predictedLabel</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>自编代码KNN 实现Implementation:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Example of kNN implemented from Scratch in Python</span></span><br><span class=\"line\">import csv</span><br><span class=\"line\">import random</span><br><span class=\"line\">import math</span><br><span class=\"line\">import operator</span><br><span class=\"line\">def loadDataset(filename, split, trainingSet=[] , testSet=[]):</span><br><span class=\"line\">    with open(filename, <span class=\"string\">'rb'</span>) as csvfile:</span><br><span class=\"line\">        lines = csv.reader(csvfile)</span><br><span class=\"line\">        dataset = list(lines)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(dataset)-1):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> range(4):</span><br><span class=\"line\">                dataset[x][y] = <span class=\"built_in\">float</span>(dataset[x][y])</span><br><span class=\"line\">            <span class=\"keyword\">if</span> random.random() &lt; split:</span><br><span class=\"line\">                trainingSet.append(dataset[x])</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                testSet.append(dataset[x])</span><br><span class=\"line\">def euclideanDistance(instance1, instance2, length):</span><br><span class=\"line\">    distance = 0</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(length):</span><br><span class=\"line\">        distance += pow((instance1[x] - instance2[x]), 2)</span><br><span class=\"line\">    <span class=\"built_in\">return</span> math.sqrt(distance)</span><br><span class=\"line\">def getNeighbors(trainingSet, testInstance, k):</span><br><span class=\"line\">    distances = []</span><br><span class=\"line\">    length = len(testInstance)-1</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(trainingSet)):</span><br><span class=\"line\">        dist = euclideanDistance(testInstance, trainingSet[x], length)</span><br><span class=\"line\">        distances.append((trainingSet[x], dist))</span><br><span class=\"line\">    distances.sort(key=operator.itemgetter(1))</span><br><span class=\"line\">    neighbors = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(k):</span><br><span class=\"line\">        neighbors.append(distances[x][0])</span><br><span class=\"line\">    <span class=\"built_in\">return</span> neighbors</span><br><span class=\"line\">def getResponse(neighbors):</span><br><span class=\"line\">    classVotes = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(neighbors)):</span><br><span class=\"line\">        response = neighbors[x][-1]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> response <span class=\"keyword\">in</span> classVotes:</span><br><span class=\"line\">            classVotes[response] += 1</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            classVotes[response] = 1</span><br><span class=\"line\">    sortedVotes = sorted(classVotes.iteritems(), key=operator.itemgetter(1), reverse=True)</span><br><span class=\"line\">    <span class=\"built_in\">return</span> sortedVotes[0][0]</span><br><span class=\"line\">def getAccuracy(testSet, predictions):</span><br><span class=\"line\">    correct = 0</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(testSet)):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> testSet[x][-1] == predictions[x]:</span><br><span class=\"line\">            correct += 1</span><br><span class=\"line\">    <span class=\"built_in\">return</span> (correct/<span class=\"built_in\">float</span>(len(testSet))) * 100.0</span><br><span class=\"line\">    </span><br><span class=\"line\">def main():</span><br><span class=\"line\">    <span class=\"comment\"># prepare data</span></span><br><span class=\"line\">    trainingSet=[]</span><br><span class=\"line\">    testSet=[]</span><br><span class=\"line\">    split = 0.67</span><br><span class=\"line\">    loadDataset(r<span class=\"string\">'D:\\MaiziEdu\\DeepLearningBasics_MachineLearning\\Datasets\\iris.data.txt'</span>, split, trainingSet, testSet)</span><br><span class=\"line\">    <span class=\"built_in\">print</span> <span class=\"string\">'Train set: '</span> + repr(len(trainingSet))</span><br><span class=\"line\">    <span class=\"built_in\">print</span> <span class=\"string\">'Test set: '</span> + repr(len(testSet))</span><br><span class=\"line\">    <span class=\"comment\"># generate predictions</span></span><br><span class=\"line\">    predictions=[]</span><br><span class=\"line\">    k = 3</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(testSet)):</span><br><span class=\"line\">        neighbors = getNeighbors(trainingSet, testSet[x], k)</span><br><span class=\"line\">        result = getResponse(neighbors)</span><br><span class=\"line\">        predictions.append(result)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'&gt; predicted='</span> + repr(result) + <span class=\"string\">', actual='</span> + repr(testSet[x][-1]))</span><br><span class=\"line\">    accuracy = getAccuracy(testSet, predictions)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">'Accuracy: '</span> + repr(accuracy) + <span class=\"string\">'%'</span>)</span><br></pre></td></tr></table></figure></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li><p>数据集介绍：<br>虹膜<br><img src=\"/2017/06/28/2017-6-28-two/1.png\" alt=\"\"><br>150个实例<br>萼片长度，萼片宽度，花瓣长度，花瓣宽度<br>(sepal length, sepal width, petal length and petal width）<br>类别：<br>Iris setosa, Iris versicolor, Iris virginica.<br><img src=\"/2017/06/28/2017-6-28-two/2.png\" alt=\"\"></p></li></ol>","more":"\n<li><p>利用Python的机器学习库sklearn: SkLearnExample.py</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from sklearn import neighbors</span><br><span class=\"line\">from sklearn import datasets</span><br><span class=\"line\">knn = neighbors.KNeighborsClassifier()</span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\"><span class=\"built_in\">print</span> iris</span><br><span class=\"line\">knn.fit(iris.data, iris.target)</span><br><span class=\"line\">predictedLabel = knn.predict([[0.1, 0.2, 0.3, 0.4]])</span><br><span class=\"line\"><span class=\"built_in\">print</span> predictedLabel</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>自编代码KNN 实现Implementation:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Example of kNN implemented from Scratch in Python</span></span><br><span class=\"line\">import csv</span><br><span class=\"line\">import random</span><br><span class=\"line\">import math</span><br><span class=\"line\">import operator</span><br><span class=\"line\">def loadDataset(filename, split, trainingSet=[] , testSet=[]):</span><br><span class=\"line\">    with open(filename, <span class=\"string\">'rb'</span>) as csvfile:</span><br><span class=\"line\">        lines = csv.reader(csvfile)</span><br><span class=\"line\">        dataset = list(lines)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(dataset)-1):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> range(4):</span><br><span class=\"line\">                dataset[x][y] = <span class=\"built_in\">float</span>(dataset[x][y])</span><br><span class=\"line\">            <span class=\"keyword\">if</span> random.random() &lt; split:</span><br><span class=\"line\">                trainingSet.append(dataset[x])</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                testSet.append(dataset[x])</span><br><span class=\"line\">def euclideanDistance(instance1, instance2, length):</span><br><span class=\"line\">    distance = 0</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(length):</span><br><span class=\"line\">        distance += pow((instance1[x] - instance2[x]), 2)</span><br><span class=\"line\">    <span class=\"built_in\">return</span> math.sqrt(distance)</span><br><span class=\"line\">def getNeighbors(trainingSet, testInstance, k):</span><br><span class=\"line\">    distances = []</span><br><span class=\"line\">    length = len(testInstance)-1</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(trainingSet)):</span><br><span class=\"line\">        dist = euclideanDistance(testInstance, trainingSet[x], length)</span><br><span class=\"line\">        distances.append((trainingSet[x], dist))</span><br><span class=\"line\">    distances.sort(key=operator.itemgetter(1))</span><br><span class=\"line\">    neighbors = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(k):</span><br><span class=\"line\">        neighbors.append(distances[x][0])</span><br><span class=\"line\">    <span class=\"built_in\">return</span> neighbors</span><br><span class=\"line\">def getResponse(neighbors):</span><br><span class=\"line\">    classVotes = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(neighbors)):</span><br><span class=\"line\">        response = neighbors[x][-1]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> response <span class=\"keyword\">in</span> classVotes:</span><br><span class=\"line\">            classVotes[response] += 1</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            classVotes[response] = 1</span><br><span class=\"line\">    sortedVotes = sorted(classVotes.iteritems(), key=operator.itemgetter(1), reverse=True)</span><br><span class=\"line\">    <span class=\"built_in\">return</span> sortedVotes[0][0]</span><br><span class=\"line\">def getAccuracy(testSet, predictions):</span><br><span class=\"line\">    correct = 0</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(testSet)):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> testSet[x][-1] == predictions[x]:</span><br><span class=\"line\">            correct += 1</span><br><span class=\"line\">    <span class=\"built_in\">return</span> (correct/<span class=\"built_in\">float</span>(len(testSet))) * 100.0</span><br><span class=\"line\">    </span><br><span class=\"line\">def main():</span><br><span class=\"line\">    <span class=\"comment\"># prepare data</span></span><br><span class=\"line\">    trainingSet=[]</span><br><span class=\"line\">    testSet=[]</span><br><span class=\"line\">    split = 0.67</span><br><span class=\"line\">    loadDataset(r<span class=\"string\">'D:\\MaiziEdu\\DeepLearningBasics_MachineLearning\\Datasets\\iris.data.txt'</span>, split, trainingSet, testSet)</span><br><span class=\"line\">    <span class=\"built_in\">print</span> <span class=\"string\">'Train set: '</span> + repr(len(trainingSet))</span><br><span class=\"line\">    <span class=\"built_in\">print</span> <span class=\"string\">'Test set: '</span> + repr(len(testSet))</span><br><span class=\"line\">    <span class=\"comment\"># generate predictions</span></span><br><span class=\"line\">    predictions=[]</span><br><span class=\"line\">    k = 3</span><br><span class=\"line\">    <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(len(testSet)):</span><br><span class=\"line\">        neighbors = getNeighbors(trainingSet, testSet[x], k)</span><br><span class=\"line\">        result = getResponse(neighbors)</span><br><span class=\"line\">        predictions.append(result)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'&gt; predicted='</span> + repr(result) + <span class=\"string\">', actual='</span> + repr(testSet[x][-1]))</span><br><span class=\"line\">    accuracy = getAccuracy(testSet, predictions)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">'Accuracy: '</span> + repr(accuracy) + <span class=\"string\">'%'</span>)</span><br></pre></td></tr></table></figure></li>\n"},{"title":"机器学习笔记（八）支持向量机（SVM）原理下","date":"2017-06-30T13:21:16.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. SVM算法特性：\n![](2017-6-30-three/1.png)\n1.1训练好的模型的算法复杂度是由支持向量的个数决定的，而不是由数据的维度决定的。所以SVM不太容易产生overfitting\n1.2SVM训练出来的模型完全依赖于支持向量(Support Vectors), 即使训练集里面所有非支持向量的点都被去除，重复训练过程，结果仍然会得到完全一样的模型。\n1.3一个SVM如果训练得出的支持向量个数比较小，SVM训练出的模型比较容易被泛化。\n<!-- more -->\n2. 线性不可分的情况 （linearly inseparable case)\n![](2017-6-30-three/2.png)\n2.1数据集在空间中对应的向量不可被一个超平面区分开\n2.2两个步骤来解决：\n2.2.1利用一个非线性的映射把原数据集中的向量点转化到一个更高维度的空间中\n2.2.2在这个高维度的空间中找一个线性的超平面来根据线性可分的情况处理\n![](2017-6-30-three/3.jpg)\n![](2017-6-30-three/4.png)\n2.2.3视觉化演示 https://www.youtube.com/watch?v=3liCbRZPrZA\n2.3如何利用非线性映射把原始数据转化到高维中？\n2.3.1 例子：\n3维输入向量：$X=${$x_1,x_2,x_3$)\n转化到6维空间 Z 中去：\n$\\phi_1(X)=x1,\\phi_2(X)=x2,\\phi_3(X)=x3,\\phi_4(X)=x1^2,\\phi_5(X)=x1x2,\\phi_6(X)=x1x3$ \n新的决策超平面： $d(Z)=WZ+b$ 其中W和Z是向量，这个超平面是线性的\n解出W和b之后，并且带入回原方程：\nd(Z)=w1x1+w2x2+w3x3+$w4x1^2$+w5x1x2+w3x1x3+b\n    =w1z1+w2z2+w3z3+w4z4+w5z5+w6z6+b\n2.3.2思考问题：\n2.3.2.1如何选择合理的非线性转化把数据转到高纬度中？\n2.3.2.2如何解决计算内积时算法复杂度非常高的问题？\n2.3.3使用核方法（kernel trick)\n3. 核方法（kernel trick)\n3.1动机\n在线性SVM中转化为最优化问题时求解的公式计算都是以内积(dot product)的形式出现的$\\phi(X_i)\\phi(X_j)$，其中$\\phi(x)$是把训练集中的向量点转化到高维的非线性映射函数，因为内积的算法复杂度非常大，\n所以我们利用核函数来取代计算非线性映射函数的内积\n3.1以下核函数和非线性映射函数的内积等同\n$K(X_i,X_j)=\\phi(X_i)\\phi(X_j)$\n3.2  常用的核函数(kernel functions)\nh度多项式核函数(polynomial kernel of degree h)：  $K(X_i,X_j)=(X_iX_j+1)^n$          \n高斯径向基核函数(Gaussian radial basis function kernel):  $K(X_i,X_j)=e^{-||X_i-X_j||^2/2\\sigma^2}$\nS型核函数(Sigmoid function kernel):   $K(X_i,X_j)=tanh(\\alpha X_iX_j-\\delta)$                            \n如何选择使用哪个kernel？\n根据先验知识，比如图像分类，通常使用RBF，文字不使用RBF\n尝试不同的kernel，根据结果准确度而定\n3.3  核函数举例:\n假设定义两个向量： x = (x1, x2, x3); y = (y1, y2, y3)\n定义方程：f(x) = (x1x1, x1x2, x1x3, x2x1, x2x2, x2x3, x3x1, x3x2, x3x3)\nK(x, y ) = (xy)^2\n假设x = (1, 2, 3); y = (4, 5, 6). \nf(x) = (1, 2, 3, 2, 4, 6, 3, 6, 9)\nf(y) = (16, 20, 24, 20, 25, 36, 24, 30, 36)\n<f(x), f(y)> = 16 + 40 + 72 + 40 + 100+ 180 + 72 + 180 + 324 = 1024\nK(x, y) = (4  + 10 + 18 ) ^2 = 32^2 = 1024\n同样的结果，使用kernel方法计算容易很多\n4. SVM扩展可解决多个类别分类问题\n对于每个类，有一个当前类和其他类的二类分类器（one-vs-rest)","source":"_posts/2017-6-30-three.md","raw":"---\ntitle: 机器学习笔记（八）支持向量机（SVM）原理下\ndate: 2017-06-30 21:21:16\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. SVM算法特性：\n![](2017-6-30-three/1.png)\n1.1训练好的模型的算法复杂度是由支持向量的个数决定的，而不是由数据的维度决定的。所以SVM不太容易产生overfitting\n1.2SVM训练出来的模型完全依赖于支持向量(Support Vectors), 即使训练集里面所有非支持向量的点都被去除，重复训练过程，结果仍然会得到完全一样的模型。\n1.3一个SVM如果训练得出的支持向量个数比较小，SVM训练出的模型比较容易被泛化。\n<!-- more -->\n2. 线性不可分的情况 （linearly inseparable case)\n![](2017-6-30-three/2.png)\n2.1数据集在空间中对应的向量不可被一个超平面区分开\n2.2两个步骤来解决：\n2.2.1利用一个非线性的映射把原数据集中的向量点转化到一个更高维度的空间中\n2.2.2在这个高维度的空间中找一个线性的超平面来根据线性可分的情况处理\n![](2017-6-30-three/3.jpg)\n![](2017-6-30-three/4.png)\n2.2.3视觉化演示 https://www.youtube.com/watch?v=3liCbRZPrZA\n2.3如何利用非线性映射把原始数据转化到高维中？\n2.3.1 例子：\n3维输入向量：$X=${$x_1,x_2,x_3$)\n转化到6维空间 Z 中去：\n$\\phi_1(X)=x1,\\phi_2(X)=x2,\\phi_3(X)=x3,\\phi_4(X)=x1^2,\\phi_5(X)=x1x2,\\phi_6(X)=x1x3$ \n新的决策超平面： $d(Z)=WZ+b$ 其中W和Z是向量，这个超平面是线性的\n解出W和b之后，并且带入回原方程：\nd(Z)=w1x1+w2x2+w3x3+$w4x1^2$+w5x1x2+w3x1x3+b\n    =w1z1+w2z2+w3z3+w4z4+w5z5+w6z6+b\n2.3.2思考问题：\n2.3.2.1如何选择合理的非线性转化把数据转到高纬度中？\n2.3.2.2如何解决计算内积时算法复杂度非常高的问题？\n2.3.3使用核方法（kernel trick)\n3. 核方法（kernel trick)\n3.1动机\n在线性SVM中转化为最优化问题时求解的公式计算都是以内积(dot product)的形式出现的$\\phi(X_i)\\phi(X_j)$，其中$\\phi(x)$是把训练集中的向量点转化到高维的非线性映射函数，因为内积的算法复杂度非常大，\n所以我们利用核函数来取代计算非线性映射函数的内积\n3.1以下核函数和非线性映射函数的内积等同\n$K(X_i,X_j)=\\phi(X_i)\\phi(X_j)$\n3.2  常用的核函数(kernel functions)\nh度多项式核函数(polynomial kernel of degree h)：  $K(X_i,X_j)=(X_iX_j+1)^n$          \n高斯径向基核函数(Gaussian radial basis function kernel):  $K(X_i,X_j)=e^{-||X_i-X_j||^2/2\\sigma^2}$\nS型核函数(Sigmoid function kernel):   $K(X_i,X_j)=tanh(\\alpha X_iX_j-\\delta)$                            \n如何选择使用哪个kernel？\n根据先验知识，比如图像分类，通常使用RBF，文字不使用RBF\n尝试不同的kernel，根据结果准确度而定\n3.3  核函数举例:\n假设定义两个向量： x = (x1, x2, x3); y = (y1, y2, y3)\n定义方程：f(x) = (x1x1, x1x2, x1x3, x2x1, x2x2, x2x3, x3x1, x3x2, x3x3)\nK(x, y ) = (xy)^2\n假设x = (1, 2, 3); y = (4, 5, 6). \nf(x) = (1, 2, 3, 2, 4, 6, 3, 6, 9)\nf(y) = (16, 20, 24, 20, 25, 36, 24, 30, 36)\n<f(x), f(y)> = 16 + 40 + 72 + 40 + 100+ 180 + 72 + 180 + 324 = 1024\nK(x, y) = (4  + 10 + 18 ) ^2 = 32^2 = 1024\n同样的结果，使用kernel方法计算容易很多\n4. SVM扩展可解决多个类别分类问题\n对于每个类，有一个当前类和其他类的二类分类器（one-vs-rest)","slug":"2017-6-30-three","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m0013ycvj9l5g9rf4","content":"<ol>\n<li>SVM算法特性：<br><img src=\"/2017/06/30/2017-6-30-three/1.png\" alt=\"\"><br>1.1训练好的模型的算法复杂度是由支持向量的个数决定的，而不是由数据的维度决定的。所以SVM不太容易产生overfitting<br>1.2SVM训练出来的模型完全依赖于支持向量(Support Vectors), 即使训练集里面所有非支持向量的点都被去除，重复训练过程，结果仍然会得到完全一样的模型。<br>1.3一个SVM如果训练得出的支持向量个数比较小，SVM训练出的模型比较容易被泛化。<a id=\"more\"></a></li>\n<li>线性不可分的情况 （linearly inseparable case)<br><img src=\"/2017/06/30/2017-6-30-three/2.png\" alt=\"\"><br>2.1数据集在空间中对应的向量不可被一个超平面区分开<br>2.2两个步骤来解决：<br>2.2.1利用一个非线性的映射把原数据集中的向量点转化到一个更高维度的空间中<br>2.2.2在这个高维度的空间中找一个线性的超平面来根据线性可分的情况处理<br><img src=\"/2017/06/30/2017-6-30-three/3.jpg\" alt=\"\"><br><img src=\"/2017/06/30/2017-6-30-three/4.png\" alt=\"\"><br>2.2.3视觉化演示 <a href=\"https://www.youtube.com/watch?v=3liCbRZPrZA\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=3liCbRZPrZA</a><br>2.3如何利用非线性映射把原始数据转化到高维中？<br>2.3.1 例子：<br>3维输入向量：$X=${$x_1,x_2,x_3$)<br>转化到6维空间 Z 中去：<br>$\\phi_1(X)=x1,\\phi_2(X)=x2,\\phi_3(X)=x3,\\phi_4(X)=x1^2,\\phi_5(X)=x1x2,\\phi_6(X)=x1x3$<br>新的决策超平面： $d(Z)=WZ+b$ 其中W和Z是向量，这个超平面是线性的<br>解出W和b之后，并且带入回原方程：<br>d(Z)=w1x1+w2x2+w3x3+$w4x1^2$+w5x1x2+w3x1x3+b<br> =w1z1+w2z2+w3z3+w4z4+w5z5+w6z6+b<br>2.3.2思考问题：<br>2.3.2.1如何选择合理的非线性转化把数据转到高纬度中？<br>2.3.2.2如何解决计算内积时算法复杂度非常高的问题？<br>2.3.3使用核方法（kernel trick)</li>\n<li>核方法（kernel trick)<br>3.1动机<br>在线性SVM中转化为最优化问题时求解的公式计算都是以内积(dot product)的形式出现的$\\phi(X_i)\\phi(X_j)$，其中$\\phi(x)$是把训练集中的向量点转化到高维的非线性映射函数，因为内积的算法复杂度非常大，<br>所以我们利用核函数来取代计算非线性映射函数的内积<br>3.1以下核函数和非线性映射函数的内积等同<br>$K(X_i,X_j)=\\phi(X_i)\\phi(X_j)$<br>3.2  常用的核函数(kernel functions)<br>h度多项式核函数(polynomial kernel of degree h)：  $K(X_i,X_j)=(X_iX_j+1)^n$<br>高斯径向基核函数(Gaussian radial basis function kernel):  $K(X_i,X_j)=e^{-||X_i-X_j||^2/2\\sigma^2}$<br>S型核函数(Sigmoid function kernel):   $K(X_i,X_j)=tanh(\\alpha X_iX_j-\\delta)$<br>如何选择使用哪个kernel？<br>根据先验知识，比如图像分类，通常使用RBF，文字不使用RBF<br>尝试不同的kernel，根据结果准确度而定<br>3.3  核函数举例:<br>假设定义两个向量： x = (x1, x2, x3); y = (y1, y2, y3)<br>定义方程：f(x) = (x1x1, x1x2, x1x3, x2x1, x2x2, x2x3, x3x1, x3x2, x3x3)<br>K(x, y ) = (xy)^2<br>假设x = (1, 2, 3); y = (4, 5, 6).<br>f(x) = (1, 2, 3, 2, 4, 6, 3, 6, 9)<br>f(y) = (16, 20, 24, 20, 25, 36, 24, 30, 36)<br><f(x), f(y)=\"\"> = 16 + 40 + 72 + 40 + 100+ 180 + 72 + 180 + 324 = 1024<br>K(x, y) = (4  + 10 + 18 ) ^2 = 32^2 = 1024<br>同样的结果，使用kernel方法计算容易很多</f(x),></li>\n<li>SVM扩展可解决多个类别分类问题<br>对于每个类，有一个当前类和其他类的二类分类器（one-vs-rest)</li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>SVM算法特性：<br><img src=\"/2017/06/30/2017-6-30-three/1.png\" alt=\"\"><br>1.1训练好的模型的算法复杂度是由支持向量的个数决定的，而不是由数据的维度决定的。所以SVM不太容易产生overfitting<br>1.2SVM训练出来的模型完全依赖于支持向量(Support Vectors), 即使训练集里面所有非支持向量的点都被去除，重复训练过程，结果仍然会得到完全一样的模型。<br>1.3一个SVM如果训练得出的支持向量个数比较小，SVM训练出的模型比较容易被泛化。</li></ol>","more":"\n<li>线性不可分的情况 （linearly inseparable case)<br><img src=\"/2017/06/30/2017-6-30-three/2.png\" alt=\"\"><br>2.1数据集在空间中对应的向量不可被一个超平面区分开<br>2.2两个步骤来解决：<br>2.2.1利用一个非线性的映射把原数据集中的向量点转化到一个更高维度的空间中<br>2.2.2在这个高维度的空间中找一个线性的超平面来根据线性可分的情况处理<br><img src=\"/2017/06/30/2017-6-30-three/3.jpg\" alt=\"\"><br><img src=\"/2017/06/30/2017-6-30-three/4.png\" alt=\"\"><br>2.2.3视觉化演示 <a href=\"https://www.youtube.com/watch?v=3liCbRZPrZA\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=3liCbRZPrZA</a><br>2.3如何利用非线性映射把原始数据转化到高维中？<br>2.3.1 例子：<br>3维输入向量：$X=${$x_1,x_2,x_3$)<br>转化到6维空间 Z 中去：<br>$\\phi_1(X)=x1,\\phi_2(X)=x2,\\phi_3(X)=x3,\\phi_4(X)=x1^2,\\phi_5(X)=x1x2,\\phi_6(X)=x1x3$<br>新的决策超平面： $d(Z)=WZ+b$ 其中W和Z是向量，这个超平面是线性的<br>解出W和b之后，并且带入回原方程：<br>d(Z)=w1x1+w2x2+w3x3+$w4x1^2$+w5x1x2+w3x1x3+b<br> =w1z1+w2z2+w3z3+w4z4+w5z5+w6z6+b<br>2.3.2思考问题：<br>2.3.2.1如何选择合理的非线性转化把数据转到高纬度中？<br>2.3.2.2如何解决计算内积时算法复杂度非常高的问题？<br>2.3.3使用核方法（kernel trick)</li>\n<li>核方法（kernel trick)<br>3.1动机<br>在线性SVM中转化为最优化问题时求解的公式计算都是以内积(dot product)的形式出现的$\\phi(X_i)\\phi(X_j)$，其中$\\phi(x)$是把训练集中的向量点转化到高维的非线性映射函数，因为内积的算法复杂度非常大，<br>所以我们利用核函数来取代计算非线性映射函数的内积<br>3.1以下核函数和非线性映射函数的内积等同<br>$K(X_i,X_j)=\\phi(X_i)\\phi(X_j)$<br>3.2  常用的核函数(kernel functions)<br>h度多项式核函数(polynomial kernel of degree h)：  $K(X_i,X_j)=(X_iX_j+1)^n$<br>高斯径向基核函数(Gaussian radial basis function kernel):  $K(X_i,X_j)=e^{-||X_i-X_j||^2/2\\sigma^2}$<br>S型核函数(Sigmoid function kernel):   $K(X_i,X_j)=tanh(\\alpha X_iX_j-\\delta)$<br>如何选择使用哪个kernel？<br>根据先验知识，比如图像分类，通常使用RBF，文字不使用RBF<br>尝试不同的kernel，根据结果准确度而定<br>3.3  核函数举例:<br>假设定义两个向量： x = (x1, x2, x3); y = (y1, y2, y3)<br>定义方程：f(x) = (x1x1, x1x2, x1x3, x2x1, x2x2, x2x3, x3x1, x3x2, x3x3)<br>K(x, y ) = (xy)^2<br>假设x = (1, 2, 3); y = (4, 5, 6).<br>f(x) = (1, 2, 3, 2, 4, 6, 3, 6, 9)<br>f(y) = (16, 20, 24, 20, 25, 36, 24, 30, 36)<br><f(x), f(y)=\"\"> = 16 + 40 + 72 + 40 + 100+ 180 + 72 + 180 + 324 = 1024<br>K(x, y) = (4  + 10 + 18 ) ^2 = 32^2 = 1024<br>同样的结果，使用kernel方法计算容易很多</f(x),></li>\n<li>SVM扩展可解决多个类别分类问题<br>对于每个类，有一个当前类和其他类的二类分类器（one-vs-rest)</li>\n"},{"title":"机器学习笔记（六）支持向量机（SVM）原理上","date":"2017-06-30T02:39:50.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 背景：\n1.1 最早是由 Vladimir N. Vapnik 和 Alexey Ya. Chervonenkis 在1963年提出\n1.2 目前的版本(soft margin)是由Corinna Cortes 和 Vapnik在1993年提出，并在1995年发表\n1.3 深度学习（2012）出现之前，SVM被认为机器学习中近十几年来最成功，表现最好的算法\n2. 机器学习的一般框架：\n训练集 => 提取特征向量 => 结合一定的算法（分类器：比如决策树，KNN）=>得到结果\n3. 介绍：\n3.1例子：\n![](2017-6-30-one/1.png)\n两类？哪条线最好？\n<!-- more -->\n3.2SVM寻找区分两类的超平面（hyper plane), 使边际(margin)最大\n![](2017-6-30-one/2.png)\n总共可以有多少个可能的超平面？无数条\n如何选取使边际(margin)最大的超平面 (Max Margin Hyperplane)？\n超平面到一侧最近点的距离等于到另一侧最近点的距离，两侧的两个超平面平行\n3.3线性可区分(linear separable) 和 线性不可区分 （linear inseparable) \n![](2017-6-30-one/3.jpg)![](2017-6-30-one/4.jpg)\n![](2017-6-30-one/5.png)\n上图皆为线性不可区分\n4. 定义与公式建立\n超平面可以定义为：$W\\dot X+b=0$\nW: weight vectot,$W$={$w_1,w_2,\\cdots,w_n$} , n 是特征值的个数\nX: 训练实例\nb: bias\n4.1假设2维特征向量：X = (x1, X2)\n把 b 想象为额外的 wight\n超平面方程变为： $w_0+w_1x_1+w_2x_2=0$\n所有超平面右上方的点满足：$w_0+w_1x_1+w_2x_2>0$\n所有超平面左下方的点满足： $w_0+w_1x_1+w_2x_2<0$\n调整weight，使超平面定义边际的两边：\n$H1:w_0+w_1x_1+w_2x_2\\ge  1 \\text{for} y_i=+1$\n$H2:w_0+w_1x_1+w_2x_2\\le  -1 \\text{for} y_i=-1$\n综合以上两式，\n得到：$y_i(w_0+w_1x_1+w_2x_2)\\ge 1,\\forall i$（1）\n所有坐落在边际的两边的的超平面上的被称作”支持向量(support vectors)\"\n分界的超平面和H1或H2上任意一点的距离为 $\\frac{1}{||w||}$ (i.e.: 其中||W||是向量的范数(norm))\n所以，最大边际距离为：$\\frac{2}{||w||}$  \n5. 求解\n5.1SVM如何找出最大边际的超平面呢(MMH)？\n利用一些数学推倒，以上公式 （1）可变为有限制的凸优化问题(convex quadratic optimization)\n利用 Karush-Kuhn-Tucker (KKT)条件和拉格朗日公式，可以推出MMH可以被表示为以下“决定边界 (decision boundary)”  \n$d(X^T)=\\sum{y_i\\alpha_iX_iX^T}+b_0$        \n其中，\n$y_i$ 是支持向量点\n$X_i$（support vector)的类别标记（class label)\n$X^T$是要测试的实例\n$\\alpha _i$ 和 $b_0$ 都是单一数值型参数，由以上提到的最有算法得出\n$l$ 是支持向量点的个数\n5.2对于任何测试（要归类的）实例，带入以上公式，得出的符号是正还是负决定\n6. 例子：\n![](2017-6-30-one/6.png)\n![](2017-6-30-one/7.png)\n\n\n\n\n","source":"_posts/2017-6-30-one.md","raw":"---\ntitle: 机器学习笔记（六）支持向量机（SVM）原理上\ndate: 2017-06-30 10:39:50\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 背景：\n1.1 最早是由 Vladimir N. Vapnik 和 Alexey Ya. Chervonenkis 在1963年提出\n1.2 目前的版本(soft margin)是由Corinna Cortes 和 Vapnik在1993年提出，并在1995年发表\n1.3 深度学习（2012）出现之前，SVM被认为机器学习中近十几年来最成功，表现最好的算法\n2. 机器学习的一般框架：\n训练集 => 提取特征向量 => 结合一定的算法（分类器：比如决策树，KNN）=>得到结果\n3. 介绍：\n3.1例子：\n![](2017-6-30-one/1.png)\n两类？哪条线最好？\n<!-- more -->\n3.2SVM寻找区分两类的超平面（hyper plane), 使边际(margin)最大\n![](2017-6-30-one/2.png)\n总共可以有多少个可能的超平面？无数条\n如何选取使边际(margin)最大的超平面 (Max Margin Hyperplane)？\n超平面到一侧最近点的距离等于到另一侧最近点的距离，两侧的两个超平面平行\n3.3线性可区分(linear separable) 和 线性不可区分 （linear inseparable) \n![](2017-6-30-one/3.jpg)![](2017-6-30-one/4.jpg)\n![](2017-6-30-one/5.png)\n上图皆为线性不可区分\n4. 定义与公式建立\n超平面可以定义为：$W\\dot X+b=0$\nW: weight vectot,$W$={$w_1,w_2,\\cdots,w_n$} , n 是特征值的个数\nX: 训练实例\nb: bias\n4.1假设2维特征向量：X = (x1, X2)\n把 b 想象为额外的 wight\n超平面方程变为： $w_0+w_1x_1+w_2x_2=0$\n所有超平面右上方的点满足：$w_0+w_1x_1+w_2x_2>0$\n所有超平面左下方的点满足： $w_0+w_1x_1+w_2x_2<0$\n调整weight，使超平面定义边际的两边：\n$H1:w_0+w_1x_1+w_2x_2\\ge  1 \\text{for} y_i=+1$\n$H2:w_0+w_1x_1+w_2x_2\\le  -1 \\text{for} y_i=-1$\n综合以上两式，\n得到：$y_i(w_0+w_1x_1+w_2x_2)\\ge 1,\\forall i$（1）\n所有坐落在边际的两边的的超平面上的被称作”支持向量(support vectors)\"\n分界的超平面和H1或H2上任意一点的距离为 $\\frac{1}{||w||}$ (i.e.: 其中||W||是向量的范数(norm))\n所以，最大边际距离为：$\\frac{2}{||w||}$  \n5. 求解\n5.1SVM如何找出最大边际的超平面呢(MMH)？\n利用一些数学推倒，以上公式 （1）可变为有限制的凸优化问题(convex quadratic optimization)\n利用 Karush-Kuhn-Tucker (KKT)条件和拉格朗日公式，可以推出MMH可以被表示为以下“决定边界 (decision boundary)”  \n$d(X^T)=\\sum{y_i\\alpha_iX_iX^T}+b_0$        \n其中，\n$y_i$ 是支持向量点\n$X_i$（support vector)的类别标记（class label)\n$X^T$是要测试的实例\n$\\alpha _i$ 和 $b_0$ 都是单一数值型参数，由以上提到的最有算法得出\n$l$ 是支持向量点的个数\n5.2对于任何测试（要归类的）实例，带入以上公式，得出的符号是正还是负决定\n6. 例子：\n![](2017-6-30-one/6.png)\n![](2017-6-30-one/7.png)\n\n\n\n\n","slug":"2017-6-30-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va2m0015ycvjp6ntcwql","content":"<ol>\n<li>背景：<br>1.1 最早是由 Vladimir N. Vapnik 和 Alexey Ya. Chervonenkis 在1963年提出<br>1.2 目前的版本(soft margin)是由Corinna Cortes 和 Vapnik在1993年提出，并在1995年发表<br>1.3 深度学习（2012）出现之前，SVM被认为机器学习中近十几年来最成功，表现最好的算法</li>\n<li>机器学习的一般框架：<br>训练集 =&gt; 提取特征向量 =&gt; 结合一定的算法（分类器：比如决策树，KNN）=&gt;得到结果</li>\n<li>介绍：<br>3.1例子：<br><img src=\"/2017/06/30/2017-6-30-one/1.png\" alt=\"\"><br>两类？哪条线最好？<a id=\"more\"></a>\n3.2SVM寻找区分两类的超平面（hyper plane), 使边际(margin)最大<br><img src=\"/2017/06/30/2017-6-30-one/2.png\" alt=\"\"><br>总共可以有多少个可能的超平面？无数条<br>如何选取使边际(margin)最大的超平面 (Max Margin Hyperplane)？<br>超平面到一侧最近点的距离等于到另一侧最近点的距离，两侧的两个超平面平行<br>3.3线性可区分(linear separable) 和 线性不可区分 （linear inseparable)<br><img src=\"/2017/06/30/2017-6-30-one/3.jpg\" alt=\"\"><img src=\"/2017/06/30/2017-6-30-one/4.jpg\" alt=\"\"><br><img src=\"/2017/06/30/2017-6-30-one/5.png\" alt=\"\"><br>上图皆为线性不可区分</li>\n<li>定义与公式建立<br>超平面可以定义为：$W\\dot X+b=0$<br>W: weight vectot,$W$={$w_1,w_2,\\cdots,w_n$} , n 是特征值的个数<br>X: 训练实例<br>b: bias<br>4.1假设2维特征向量：X = (x1, X2)<br>把 b 想象为额外的 wight<br>超平面方程变为： $w_0+w_1x_1+w_2x_2=0$<br>所有超平面右上方的点满足：$w_0+w_1x_1+w_2x_2&gt;0$<br>所有超平面左下方的点满足： $w_0+w_1x_1+w_2x_2&lt;0$<br>调整weight，使超平面定义边际的两边：<br>$H1:w_0+w_1x_1+w_2x_2\\ge  1 \\text{for} y_i=+1$<br>$H2:w_0+w_1x_1+w_2x_2\\le  -1 \\text{for} y_i=-1$<br>综合以上两式，<br>得到：$y_i(w_0+w_1x_1+w_2x_2)\\ge 1,\\forall i$（1）<br>所有坐落在边际的两边的的超平面上的被称作”支持向量(support vectors)”<br>分界的超平面和H1或H2上任意一点的距离为 $\\frac{1}{||w||}$ (i.e.: 其中||W||是向量的范数(norm))<br>所以，最大边际距离为：$\\frac{2}{||w||}$  </li>\n<li>求解<br>5.1SVM如何找出最大边际的超平面呢(MMH)？<br>利用一些数学推倒，以上公式 （1）可变为有限制的凸优化问题(convex quadratic optimization)<br>利用 Karush-Kuhn-Tucker (KKT)条件和拉格朗日公式，可以推出MMH可以被表示为以下“决定边界 (decision boundary)”<br>$d(X^T)=\\sum{y_i\\alpha_iX_iX^T}+b_0$<br>其中，<br>$y_i$ 是支持向量点<br>$X_i$（support vector)的类别标记（class label)<br>$X^T$是要测试的实例<br>$\\alpha _i$ 和 $b_0$ 都是单一数值型参数，由以上提到的最有算法得出<br>$l$ 是支持向量点的个数<br>5.2对于任何测试（要归类的）实例，带入以上公式，得出的符号是正还是负决定</li>\n<li>例子：<br><img src=\"/2017/06/30/2017-6-30-one/6.png\" alt=\"\"><br><img src=\"/2017/06/30/2017-6-30-one/7.png\" alt=\"\"></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>背景：<br>1.1 最早是由 Vladimir N. Vapnik 和 Alexey Ya. Chervonenkis 在1963年提出<br>1.2 目前的版本(soft margin)是由Corinna Cortes 和 Vapnik在1993年提出，并在1995年发表<br>1.3 深度学习（2012）出现之前，SVM被认为机器学习中近十几年来最成功，表现最好的算法</li>\n<li>机器学习的一般框架：<br>训练集 =&gt; 提取特征向量 =&gt; 结合一定的算法（分类器：比如决策树，KNN）=&gt;得到结果</li>\n<li>介绍：<br>3.1例子：<br><img src=\"/2017/06/30/2017-6-30-one/1.png\" alt=\"\"><br>两类？哪条线最好？</li></ol>","more":"3.2SVM寻找区分两类的超平面（hyper plane), 使边际(margin)最大<br><img src=\"/2017/06/30/2017-6-30-one/2.png\" alt=\"\"><br>总共可以有多少个可能的超平面？无数条<br>如何选取使边际(margin)最大的超平面 (Max Margin Hyperplane)？<br>超平面到一侧最近点的距离等于到另一侧最近点的距离，两侧的两个超平面平行<br>3.3线性可区分(linear separable) 和 线性不可区分 （linear inseparable)<br><img src=\"/2017/06/30/2017-6-30-one/3.jpg\" alt=\"\"><img src=\"/2017/06/30/2017-6-30-one/4.jpg\" alt=\"\"><br><img src=\"/2017/06/30/2017-6-30-one/5.png\" alt=\"\"><br>上图皆为线性不可区分\n<li>定义与公式建立<br>超平面可以定义为：$W\\dot X+b=0$<br>W: weight vectot,$W$={$w_1,w_2,\\cdots,w_n$} , n 是特征值的个数<br>X: 训练实例<br>b: bias<br>4.1假设2维特征向量：X = (x1, X2)<br>把 b 想象为额外的 wight<br>超平面方程变为： $w_0+w_1x_1+w_2x_2=0$<br>所有超平面右上方的点满足：$w_0+w_1x_1+w_2x_2&gt;0$<br>所有超平面左下方的点满足： $w_0+w_1x_1+w_2x_2&lt;0$<br>调整weight，使超平面定义边际的两边：<br>$H1:w_0+w_1x_1+w_2x_2\\ge  1 \\text{for} y_i=+1$<br>$H2:w_0+w_1x_1+w_2x_2\\le  -1 \\text{for} y_i=-1$<br>综合以上两式，<br>得到：$y_i(w_0+w_1x_1+w_2x_2)\\ge 1,\\forall i$（1）<br>所有坐落在边际的两边的的超平面上的被称作”支持向量(support vectors)”<br>分界的超平面和H1或H2上任意一点的距离为 $\\frac{1}{||w||}$ (i.e.: 其中||W||是向量的范数(norm))<br>所以，最大边际距离为：$\\frac{2}{||w||}$  </li>\n<li>求解<br>5.1SVM如何找出最大边际的超平面呢(MMH)？<br>利用一些数学推倒，以上公式 （1）可变为有限制的凸优化问题(convex quadratic optimization)<br>利用 Karush-Kuhn-Tucker (KKT)条件和拉格朗日公式，可以推出MMH可以被表示为以下“决定边界 (decision boundary)”<br>$d(X^T)=\\sum{y_i\\alpha_iX_iX^T}+b_0$<br>其中，<br>$y_i$ 是支持向量点<br>$X_i$（support vector)的类别标记（class label)<br>$X^T$是要测试的实例<br>$\\alpha _i$ 和 $b_0$ 都是单一数值型参数，由以上提到的最有算法得出<br>$l$ 是支持向量点的个数<br>5.2对于任何测试（要归类的）实例，带入以上公式，得出的符号是正还是负决定</li>\n<li>例子：<br><img src=\"/2017/06/30/2017-6-30-one/6.png\" alt=\"\"><br><img src=\"/2017/06/30/2017-6-30-one/7.png\" alt=\"\"></li>\n"},{"title":"机器学习笔记（七）支持向量机（SVM）应用上","date":"2017-06-30T13:20:56.000Z","comments":1,"reward":true,"_content":"1 sklearn简单例子\n``` bash\nfrom sklearn import svm\nX = [[2, 0], [1, 1], [2,3]]\ny = [0, 0, 1]\nclf = svm.SVC(kernel = 'linear')\nclf.fit(X, y)  \nprint clf\n# get support vectors\nprint clf.support_vectors_\n# get indices of support vectors\nprint clf.support_ \n# get number of support vectors for each class\nprint clf.n_support_ \n```\n<!-- more -->\n2 sklearn画出决定界限\n``` bash\nprint(__doc__)\nimport numpy as np\nimport pylab as pl\nfrom sklearn import svm\n# we create 40 separable points\nnp.random.seed(0)\nX = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\nY = [0] * 20 + [1] * 20\n# fit the model\nclf = svm.SVC(kernel='linear')\nclf.fit(X, Y)\n# get the separating hyperplane\nw = clf.coef_[0]\na = -w[0] / w[1]\nxx = np.linspace(-5, 5)\nyy = a * xx - (clf.intercept_[0]) / w[1]\n# plot the parallels to the separating hyperplane that pass through the\n# support vectors\nb = clf.support_vectors_[0]\nyy_down = a * xx + (b[1] - a * b[0])\nb = clf.support_vectors_[-1]\nyy_up = a * xx + (b[1] - a * b[0])\nprint \"w: \", w\nprint \"a: \", a\n# print \" xx: \", xx\n# print \" yy: \", yy\nprint \"support_vectors_: \", clf.support_vectors_\nprint \"clf.coef_: \", clf.coef_\n# In scikit-learn coef_ attribute holds the vectors of the separating hyperplanes for linear models. It has shape (n_classes, n_features) if n_classes > 1 (multi-class one-vs-all) and (1, n_features) for binary classification.\n# \n# In this toy binary classification example, n_features == 2, hence w = coef_[0] is the vector orthogonal to the hyperplane (the hyperplane is fully defined by it + the intercept).\n# \n# To plot this hyperplane in the 2D case (any hyperplane of a 2D plane is a 1D line), we want to find a f as in y = f(x) = a.x + b. In this case a is the slope of the line and can be computed by a = -w[0] / w[1].\n# plot the line, the points, and the nearest vectors to the plane\npl.plot(xx, yy, 'k-')\npl.plot(xx, yy_down, 'k--')\npl.plot(xx, yy_up, 'k--')\npl.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n           s=80, facecolors='none')\npl.scatter(X[:, 0], X[:, 1], c=Y, cmap=pl.cm.Paired)\npl.axis('tight')\npl.show()\n```","source":"_posts/2017-6-30-two.md","raw":"---\ntitle: 机器学习笔记（七）支持向量机（SVM）应用上\ndate: 2017-06-30 21:20:56\ncomments: true\nreward: true\ntags: \n - 机器学习\n---\n1 sklearn简单例子\n``` bash\nfrom sklearn import svm\nX = [[2, 0], [1, 1], [2,3]]\ny = [0, 0, 1]\nclf = svm.SVC(kernel = 'linear')\nclf.fit(X, y)  \nprint clf\n# get support vectors\nprint clf.support_vectors_\n# get indices of support vectors\nprint clf.support_ \n# get number of support vectors for each class\nprint clf.n_support_ \n```\n<!-- more -->\n2 sklearn画出决定界限\n``` bash\nprint(__doc__)\nimport numpy as np\nimport pylab as pl\nfrom sklearn import svm\n# we create 40 separable points\nnp.random.seed(0)\nX = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\nY = [0] * 20 + [1] * 20\n# fit the model\nclf = svm.SVC(kernel='linear')\nclf.fit(X, Y)\n# get the separating hyperplane\nw = clf.coef_[0]\na = -w[0] / w[1]\nxx = np.linspace(-5, 5)\nyy = a * xx - (clf.intercept_[0]) / w[1]\n# plot the parallels to the separating hyperplane that pass through the\n# support vectors\nb = clf.support_vectors_[0]\nyy_down = a * xx + (b[1] - a * b[0])\nb = clf.support_vectors_[-1]\nyy_up = a * xx + (b[1] - a * b[0])\nprint \"w: \", w\nprint \"a: \", a\n# print \" xx: \", xx\n# print \" yy: \", yy\nprint \"support_vectors_: \", clf.support_vectors_\nprint \"clf.coef_: \", clf.coef_\n# In scikit-learn coef_ attribute holds the vectors of the separating hyperplanes for linear models. It has shape (n_classes, n_features) if n_classes > 1 (multi-class one-vs-all) and (1, n_features) for binary classification.\n# \n# In this toy binary classification example, n_features == 2, hence w = coef_[0] is the vector orthogonal to the hyperplane (the hyperplane is fully defined by it + the intercept).\n# \n# To plot this hyperplane in the 2D case (any hyperplane of a 2D plane is a 1D line), we want to find a f as in y = f(x) = a.x + b. In this case a is the slope of the line and can be computed by a = -w[0] / w[1].\n# plot the line, the points, and the nearest vectors to the plane\npl.plot(xx, yy, 'k-')\npl.plot(xx, yy_down, 'k--')\npl.plot(xx, yy_up, 'k--')\npl.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n           s=80, facecolors='none')\npl.scatter(X[:, 0], X[:, 1], c=Y, cmap=pl.cm.Paired)\npl.axis('tight')\npl.show()\n```","slug":"2017-6-30-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va310018ycvjzwi48ab3","content":"<p>1 sklearn简单例子<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from sklearn import svm</span><br><span class=\"line\">X = [[2, 0], [1, 1], [2,3]]</span><br><span class=\"line\">y = [0, 0, 1]</span><br><span class=\"line\">clf = svm.SVC(kernel = <span class=\"string\">'linear'</span>)</span><br><span class=\"line\">clf.fit(X, y)  </span><br><span class=\"line\"><span class=\"built_in\">print</span> clf</span><br><span class=\"line\"><span class=\"comment\"># get support vectors</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> clf.support_vectors_</span><br><span class=\"line\"><span class=\"comment\"># get indices of support vectors</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> clf.support_ </span><br><span class=\"line\"><span class=\"comment\"># get number of support vectors for each class</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> clf.n_support_</span><br></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<p>2 sklearn画出决定界限<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(__doc__)</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">import pylab as pl</span><br><span class=\"line\">from sklearn import svm</span><br><span class=\"line\"><span class=\"comment\"># we create 40 separable points</span></span><br><span class=\"line\">np.random.seed(0)</span><br><span class=\"line\">X = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]</span><br><span class=\"line\">Y = [0] * 20 + [1] * 20</span><br><span class=\"line\"><span class=\"comment\"># fit the model</span></span><br><span class=\"line\">clf = svm.SVC(kernel=<span class=\"string\">'linear'</span>)</span><br><span class=\"line\">clf.fit(X, Y)</span><br><span class=\"line\"><span class=\"comment\"># get the separating hyperplane</span></span><br><span class=\"line\">w = clf.coef_[0]</span><br><span class=\"line\">a = -w[0] / w[1]</span><br><span class=\"line\">xx = np.linspace(-5, 5)</span><br><span class=\"line\">yy = a * xx - (clf.intercept_[0]) / w[1]</span><br><span class=\"line\"><span class=\"comment\"># plot the parallels to the separating hyperplane that pass through the</span></span><br><span class=\"line\"><span class=\"comment\"># support vectors</span></span><br><span class=\"line\">b = clf.support_vectors_[0]</span><br><span class=\"line\">yy_down = a * xx + (b[1] - a * b[0])</span><br><span class=\"line\">b = clf.support_vectors_[-1]</span><br><span class=\"line\">yy_up = a * xx + (b[1] - a * b[0])</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"w: \"</span>, w</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"a: \"</span>, a</span><br><span class=\"line\"><span class=\"comment\"># print \" xx: \", xx</span></span><br><span class=\"line\"><span class=\"comment\"># print \" yy: \", yy</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"support_vectors_: \"</span>, clf.support_vectors_</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"clf.coef_: \"</span>, clf.coef_</span><br><span class=\"line\"><span class=\"comment\"># In scikit-learn coef_ attribute holds the vectors of the separating hyperplanes for linear models. It has shape (n_classes, n_features) if n_classes &gt; 1 (multi-class one-vs-all) and (1, n_features) for binary classification.</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># In this toy binary classification example, n_features == 2, hence w = coef_[0] is the vector orthogonal to the hyperplane (the hyperplane is fully defined by it + the intercept).</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># To plot this hyperplane in the 2D case (any hyperplane of a 2D plane is a 1D line), we want to find a f as in y = f(x) = a.x + b. In this case a is the slope of the line and can be computed by a = -w[0] / w[1].</span></span><br><span class=\"line\"><span class=\"comment\"># plot the line, the points, and the nearest vectors to the plane</span></span><br><span class=\"line\">pl.plot(xx, yy, <span class=\"string\">'k-'</span>)</span><br><span class=\"line\">pl.plot(xx, yy_down, <span class=\"string\">'k--'</span>)</span><br><span class=\"line\">pl.plot(xx, yy_up, <span class=\"string\">'k--'</span>)</span><br><span class=\"line\">pl.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],</span><br><span class=\"line\">           s=80, facecolors=<span class=\"string\">'none'</span>)</span><br><span class=\"line\">pl.scatter(X[:, 0], X[:, 1], c=Y, cmap=pl.cm.Paired)</span><br><span class=\"line\">pl.axis(<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">pl.show()</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>1 sklearn简单例子<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from sklearn import svm</span><br><span class=\"line\">X = [[2, 0], [1, 1], [2,3]]</span><br><span class=\"line\">y = [0, 0, 1]</span><br><span class=\"line\">clf = svm.SVC(kernel = <span class=\"string\">'linear'</span>)</span><br><span class=\"line\">clf.fit(X, y)  </span><br><span class=\"line\"><span class=\"built_in\">print</span> clf</span><br><span class=\"line\"><span class=\"comment\"># get support vectors</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> clf.support_vectors_</span><br><span class=\"line\"><span class=\"comment\"># get indices of support vectors</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> clf.support_ </span><br><span class=\"line\"><span class=\"comment\"># get number of support vectors for each class</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> clf.n_support_</span><br></pre></td></tr></table></figure></p>","more":"<p>2 sklearn画出决定界限<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(__doc__)</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">import pylab as pl</span><br><span class=\"line\">from sklearn import svm</span><br><span class=\"line\"><span class=\"comment\"># we create 40 separable points</span></span><br><span class=\"line\">np.random.seed(0)</span><br><span class=\"line\">X = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]</span><br><span class=\"line\">Y = [0] * 20 + [1] * 20</span><br><span class=\"line\"><span class=\"comment\"># fit the model</span></span><br><span class=\"line\">clf = svm.SVC(kernel=<span class=\"string\">'linear'</span>)</span><br><span class=\"line\">clf.fit(X, Y)</span><br><span class=\"line\"><span class=\"comment\"># get the separating hyperplane</span></span><br><span class=\"line\">w = clf.coef_[0]</span><br><span class=\"line\">a = -w[0] / w[1]</span><br><span class=\"line\">xx = np.linspace(-5, 5)</span><br><span class=\"line\">yy = a * xx - (clf.intercept_[0]) / w[1]</span><br><span class=\"line\"><span class=\"comment\"># plot the parallels to the separating hyperplane that pass through the</span></span><br><span class=\"line\"><span class=\"comment\"># support vectors</span></span><br><span class=\"line\">b = clf.support_vectors_[0]</span><br><span class=\"line\">yy_down = a * xx + (b[1] - a * b[0])</span><br><span class=\"line\">b = clf.support_vectors_[-1]</span><br><span class=\"line\">yy_up = a * xx + (b[1] - a * b[0])</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"w: \"</span>, w</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"a: \"</span>, a</span><br><span class=\"line\"><span class=\"comment\"># print \" xx: \", xx</span></span><br><span class=\"line\"><span class=\"comment\"># print \" yy: \", yy</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"support_vectors_: \"</span>, clf.support_vectors_</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"clf.coef_: \"</span>, clf.coef_</span><br><span class=\"line\"><span class=\"comment\"># In scikit-learn coef_ attribute holds the vectors of the separating hyperplanes for linear models. It has shape (n_classes, n_features) if n_classes &gt; 1 (multi-class one-vs-all) and (1, n_features) for binary classification.</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># In this toy binary classification example, n_features == 2, hence w = coef_[0] is the vector orthogonal to the hyperplane (the hyperplane is fully defined by it + the intercept).</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># To plot this hyperplane in the 2D case (any hyperplane of a 2D plane is a 1D line), we want to find a f as in y = f(x) = a.x + b. In this case a is the slope of the line and can be computed by a = -w[0] / w[1].</span></span><br><span class=\"line\"><span class=\"comment\"># plot the line, the points, and the nearest vectors to the plane</span></span><br><span class=\"line\">pl.plot(xx, yy, <span class=\"string\">'k-'</span>)</span><br><span class=\"line\">pl.plot(xx, yy_down, <span class=\"string\">'k--'</span>)</span><br><span class=\"line\">pl.plot(xx, yy_up, <span class=\"string\">'k--'</span>)</span><br><span class=\"line\">pl.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],</span><br><span class=\"line\">           s=80, facecolors=<span class=\"string\">'none'</span>)</span><br><span class=\"line\">pl.scatter(X[:, 0], X[:, 1], c=Y, cmap=pl.cm.Paired)</span><br><span class=\"line\">pl.axis(<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">pl.show()</span><br></pre></td></tr></table></figure></p>"},{"title":"机器学习笔记（九）利用SVM进行人脸识别","date":"2017-07-01T03:44:10.000Z","comments":1,"reward":true,"_content":"利用SVM进行人脸识别代码\n<!-- more -->\n``` bash\nfrom __future__ import print_function\nfrom time import time\nimport logging\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import RandomizedPCA\nfrom sklearn.svm import SVC\nprint(__doc__)\n# Display progress logs on stdout\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n###############################################################################\n# Download the data, if not already on disk and load it as numpy arrays\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n# introspect the images arrays to find the shapes (for plotting)\nn_samples, h, w = lfw_people.images.shape\n# for machine learning we use the 2 data directly (as relative pixel\n# positions info is ignored by this model)\nX = lfw_people.data\nn_features = X.shape[1]\n# the label to predict is the id of the person\ny = lfw_people.target\ntarget_names = lfw_people.target_names\nn_classes = target_names.shape[0]\nprint(\"Total dataset size:\")\nprint(\"n_samples: %d\" % n_samples)\nprint(\"n_features: %d\" % n_features)\nprint(\"n_classes: %d\" % n_classes)\n###############################################################################\n# Split into a training set and a test set using a stratified k fold\n# split into a training and testing set\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25)\n###############################################################################\n# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n# dataset): unsupervised feature extraction / dimensionality reduction\nn_components = 150\nprint(\"Extracting the top %d eigenfaces from %d faces\"\n      % (n_components, X_train.shape[0]))\nt0 = time()\npca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\nprint(\"done in %0.3fs\" % (time() - t0))\neigenfaces = pca.components_.reshape((n_components, h, w))\nprint(\"Projecting the input data on the eigenfaces orthonormal basis\")\nt0 = time()\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\nprint(\"done in %0.3fs\" % (time() - t0))\n###############################################################################\n# Train a SVM classification model\nprint(\"Fitting the classifier to the training set\")\nt0 = time()\nparam_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\nclf = GridSearchCV(SVC(kernel='rbf', class_weight='auto'), param_grid)\nclf = clf.fit(X_train_pca, y_train)\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(\"Best estimator found by grid search:\")\nprint(clf.best_estimator_)\n###############################################################################\n# Quantitative evaluation of the model quality on the test set\nprint(\"Predicting people's names on the test set\")\nt0 = time()\ny_pred = clf.predict(X_test_pca)\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(classification_report(y_test, y_pred, target_names=target_names))\nprint(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n###############################################################################\n# Qualitative evaluation of the predictions using matplotlib\ndef plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n        plt.title(titles[i], size=12)\n        plt.xticks(())\n        plt.yticks(())\n# plot the result of the prediction on a portion of the test set\ndef title(y_pred, y_test, target_names, i):\n    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\nprediction_titles = [title(y_pred, y_test, target_names, i)\n                     for i in range(y_pred.shape[0])]\nplot_gallery(X_test, prediction_titles, h, w)\n# plot the gallery of the most significative eigenfaces\neigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\nplot_gallery(eigenfaces, eigenface_titles, h, w)\nplt.show()\n```","source":"_posts/2017-7-1-one.md","raw":"---\ntitle: 机器学习笔记（九）利用SVM进行人脸识别\ndate: 2017-07-01 11:44:10\ncomments: true\nreward: true\ntags: \n - 机器学习\n---\n利用SVM进行人脸识别代码\n<!-- more -->\n``` bash\nfrom __future__ import print_function\nfrom time import time\nimport logging\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import RandomizedPCA\nfrom sklearn.svm import SVC\nprint(__doc__)\n# Display progress logs on stdout\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n###############################################################################\n# Download the data, if not already on disk and load it as numpy arrays\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n# introspect the images arrays to find the shapes (for plotting)\nn_samples, h, w = lfw_people.images.shape\n# for machine learning we use the 2 data directly (as relative pixel\n# positions info is ignored by this model)\nX = lfw_people.data\nn_features = X.shape[1]\n# the label to predict is the id of the person\ny = lfw_people.target\ntarget_names = lfw_people.target_names\nn_classes = target_names.shape[0]\nprint(\"Total dataset size:\")\nprint(\"n_samples: %d\" % n_samples)\nprint(\"n_features: %d\" % n_features)\nprint(\"n_classes: %d\" % n_classes)\n###############################################################################\n# Split into a training set and a test set using a stratified k fold\n# split into a training and testing set\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25)\n###############################################################################\n# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n# dataset): unsupervised feature extraction / dimensionality reduction\nn_components = 150\nprint(\"Extracting the top %d eigenfaces from %d faces\"\n      % (n_components, X_train.shape[0]))\nt0 = time()\npca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\nprint(\"done in %0.3fs\" % (time() - t0))\neigenfaces = pca.components_.reshape((n_components, h, w))\nprint(\"Projecting the input data on the eigenfaces orthonormal basis\")\nt0 = time()\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\nprint(\"done in %0.3fs\" % (time() - t0))\n###############################################################################\n# Train a SVM classification model\nprint(\"Fitting the classifier to the training set\")\nt0 = time()\nparam_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\nclf = GridSearchCV(SVC(kernel='rbf', class_weight='auto'), param_grid)\nclf = clf.fit(X_train_pca, y_train)\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(\"Best estimator found by grid search:\")\nprint(clf.best_estimator_)\n###############################################################################\n# Quantitative evaluation of the model quality on the test set\nprint(\"Predicting people's names on the test set\")\nt0 = time()\ny_pred = clf.predict(X_test_pca)\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(classification_report(y_test, y_pred, target_names=target_names))\nprint(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n###############################################################################\n# Qualitative evaluation of the predictions using matplotlib\ndef plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n        plt.title(titles[i], size=12)\n        plt.xticks(())\n        plt.yticks(())\n# plot the result of the prediction on a portion of the test set\ndef title(y_pred, y_test, target_names, i):\n    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\nprediction_titles = [title(y_pred, y_test, target_names, i)\n                     for i in range(y_pred.shape[0])]\nplot_gallery(X_test, prediction_titles, h, w)\n# plot the gallery of the most significative eigenfaces\neigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\nplot_gallery(eigenfaces, eigenface_titles, h, w)\nplt.show()\n```","slug":"2017-7-1-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001aycvjy84vevpj","content":"<p>利用SVM进行人脸识别代码<br><a id=\"more\"></a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from __future__ import print_function</span><br><span class=\"line\">from time import time</span><br><span class=\"line\">import logging</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from sklearn.cross_validation import train_test_split</span><br><span class=\"line\">from sklearn.datasets import fetch_lfw_people</span><br><span class=\"line\">from sklearn.grid_search import GridSearchCV</span><br><span class=\"line\">from sklearn.metrics import classification_report</span><br><span class=\"line\">from sklearn.metrics import confusion_matrix</span><br><span class=\"line\">from sklearn.decomposition import RandomizedPCA</span><br><span class=\"line\">from sklearn.svm import SVC</span><br><span class=\"line\"><span class=\"built_in\">print</span>(__doc__)</span><br><span class=\"line\"><span class=\"comment\"># Display progress logs on stdout</span></span><br><span class=\"line\">logging.basicConfig(level=logging.INFO, format=<span class=\"string\">'%(asctime)s %(message)s'</span>)</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Download the data, if not already on disk and load it as numpy arrays</span></span><br><span class=\"line\">lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)</span><br><span class=\"line\"><span class=\"comment\"># introspect the images arrays to find the shapes (for plotting)</span></span><br><span class=\"line\">n_samples, h, w = lfw_people.images.shape</span><br><span class=\"line\"><span class=\"comment\"># for machine learning we use the 2 data directly (as relative pixel</span></span><br><span class=\"line\"><span class=\"comment\"># positions info is ignored by this model)</span></span><br><span class=\"line\">X = lfw_people.data</span><br><span class=\"line\">n_features = X.shape[1]</span><br><span class=\"line\"><span class=\"comment\"># the label to predict is the id of the person</span></span><br><span class=\"line\">y = lfw_people.target</span><br><span class=\"line\">target_names = lfw_people.target_names</span><br><span class=\"line\">n_classes = target_names.shape[0]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Total dataset size:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"n_samples: %d\"</span> % n_samples)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"n_features: %d\"</span> % n_features)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"n_classes: %d\"</span> % n_classes)</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Split into a training set and a test set using a stratified k fold</span></span><br><span class=\"line\"><span class=\"comment\"># split into a training and testing set</span></span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class=\"line\">    X, y, test_size=0.25)</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled</span></span><br><span class=\"line\"><span class=\"comment\"># dataset): unsupervised feature extraction / dimensionality reduction</span></span><br><span class=\"line\">n_components = 150</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Extracting the top %d eigenfaces from %d faces\"</span></span><br><span class=\"line\">      % (n_components, X_train.shape[0]))</span><br><span class=\"line\">t0 = time()</span><br><span class=\"line\">pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"done in %0.3fs\"</span> % (time() - t0))</span><br><span class=\"line\">eigenfaces = pca.components_.reshape((n_components, h, w))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Projecting the input data on the eigenfaces orthonormal basis\"</span>)</span><br><span class=\"line\">t0 = time()</span><br><span class=\"line\">X_train_pca = pca.transform(X_train)</span><br><span class=\"line\">X_test_pca = pca.transform(X_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"done in %0.3fs\"</span> % (time() - t0))</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Train a SVM classification model</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Fitting the classifier to the training set\"</span>)</span><br><span class=\"line\">t0 = time()</span><br><span class=\"line\">param_grid = &#123;<span class=\"string\">'C'</span>: [1e3, 5e3, 1e4, 5e4, 1e5],</span><br><span class=\"line\">              <span class=\"string\">'gamma'</span>: [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], &#125;</span><br><span class=\"line\">clf = GridSearchCV(SVC(kernel=<span class=\"string\">'rbf'</span>, class_weight=<span class=\"string\">'auto'</span>), param_grid)</span><br><span class=\"line\">clf = clf.fit(X_train_pca, y_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"done in %0.3fs\"</span> % (time() - t0))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Best estimator found by grid search:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(clf.best_estimator_)</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Quantitative evaluation of the model quality on the test set</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Predicting people's names on the test set\"</span>)</span><br><span class=\"line\">t0 = time()</span><br><span class=\"line\">y_pred = clf.predict(X_test_pca)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"done in %0.3fs\"</span> % (time() - t0))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(y_test, y_pred, target_names=target_names))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(confusion_matrix(y_test, y_pred, labels=range(n_classes)))</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Qualitative evaluation of the predictions using matplotlib</span></span><br><span class=\"line\">def plot_gallery(images, titles, h, w, n_row=3, n_col=4):</span><br><span class=\"line\">    <span class=\"string\">\"\"</span><span class=\"string\">\"Helper function to plot a gallery of portraits\"</span><span class=\"string\">\"\"</span></span><br><span class=\"line\">    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))</span><br><span class=\"line\">    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n_row * n_col):</span><br><span class=\"line\">        plt.subplot(n_row, n_col, i + 1)</span><br><span class=\"line\">        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)</span><br><span class=\"line\">        plt.title(titles[i], size=12)</span><br><span class=\"line\">        plt.xticks(())</span><br><span class=\"line\">        plt.yticks(())</span><br><span class=\"line\"><span class=\"comment\"># plot the result of the prediction on a portion of the test set</span></span><br><span class=\"line\">def title(y_pred, y_test, target_names, i):</span><br><span class=\"line\">    pred_name = target_names[y_pred[i]].rsplit(<span class=\"string\">' '</span>, 1)[-1]</span><br><span class=\"line\">    true_name = target_names[y_test[i]].rsplit(<span class=\"string\">' '</span>, 1)[-1]</span><br><span class=\"line\">    <span class=\"built_in\">return</span> <span class=\"string\">'predicted: %s\\ntrue:      %s'</span> % (pred_name, true_name)</span><br><span class=\"line\">prediction_titles = [title(y_pred, y_test, target_names, i)</span><br><span class=\"line\">                     <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(y_pred.shape[0])]</span><br><span class=\"line\">plot_gallery(X_test, prediction_titles, h, w)</span><br><span class=\"line\"><span class=\"comment\"># plot the gallery of the most significative eigenfaces</span></span><br><span class=\"line\">eigenface_titles = [<span class=\"string\">\"eigenface %d\"</span> % i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(eigenfaces.shape[0])]</span><br><span class=\"line\">plot_gallery(eigenfaces, eigenface_titles, h, w)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>利用SVM进行人脸识别代码<br></p>","more":"<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from __future__ import print_function</span><br><span class=\"line\">from time import time</span><br><span class=\"line\">import logging</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from sklearn.cross_validation import train_test_split</span><br><span class=\"line\">from sklearn.datasets import fetch_lfw_people</span><br><span class=\"line\">from sklearn.grid_search import GridSearchCV</span><br><span class=\"line\">from sklearn.metrics import classification_report</span><br><span class=\"line\">from sklearn.metrics import confusion_matrix</span><br><span class=\"line\">from sklearn.decomposition import RandomizedPCA</span><br><span class=\"line\">from sklearn.svm import SVC</span><br><span class=\"line\"><span class=\"built_in\">print</span>(__doc__)</span><br><span class=\"line\"><span class=\"comment\"># Display progress logs on stdout</span></span><br><span class=\"line\">logging.basicConfig(level=logging.INFO, format=<span class=\"string\">'%(asctime)s %(message)s'</span>)</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Download the data, if not already on disk and load it as numpy arrays</span></span><br><span class=\"line\">lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)</span><br><span class=\"line\"><span class=\"comment\"># introspect the images arrays to find the shapes (for plotting)</span></span><br><span class=\"line\">n_samples, h, w = lfw_people.images.shape</span><br><span class=\"line\"><span class=\"comment\"># for machine learning we use the 2 data directly (as relative pixel</span></span><br><span class=\"line\"><span class=\"comment\"># positions info is ignored by this model)</span></span><br><span class=\"line\">X = lfw_people.data</span><br><span class=\"line\">n_features = X.shape[1]</span><br><span class=\"line\"><span class=\"comment\"># the label to predict is the id of the person</span></span><br><span class=\"line\">y = lfw_people.target</span><br><span class=\"line\">target_names = lfw_people.target_names</span><br><span class=\"line\">n_classes = target_names.shape[0]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Total dataset size:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"n_samples: %d\"</span> % n_samples)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"n_features: %d\"</span> % n_features)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"n_classes: %d\"</span> % n_classes)</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Split into a training set and a test set using a stratified k fold</span></span><br><span class=\"line\"><span class=\"comment\"># split into a training and testing set</span></span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class=\"line\">    X, y, test_size=0.25)</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled</span></span><br><span class=\"line\"><span class=\"comment\"># dataset): unsupervised feature extraction / dimensionality reduction</span></span><br><span class=\"line\">n_components = 150</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Extracting the top %d eigenfaces from %d faces\"</span></span><br><span class=\"line\">      % (n_components, X_train.shape[0]))</span><br><span class=\"line\">t0 = time()</span><br><span class=\"line\">pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"done in %0.3fs\"</span> % (time() - t0))</span><br><span class=\"line\">eigenfaces = pca.components_.reshape((n_components, h, w))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Projecting the input data on the eigenfaces orthonormal basis\"</span>)</span><br><span class=\"line\">t0 = time()</span><br><span class=\"line\">X_train_pca = pca.transform(X_train)</span><br><span class=\"line\">X_test_pca = pca.transform(X_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"done in %0.3fs\"</span> % (time() - t0))</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Train a SVM classification model</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Fitting the classifier to the training set\"</span>)</span><br><span class=\"line\">t0 = time()</span><br><span class=\"line\">param_grid = &#123;<span class=\"string\">'C'</span>: [1e3, 5e3, 1e4, 5e4, 1e5],</span><br><span class=\"line\">              <span class=\"string\">'gamma'</span>: [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], &#125;</span><br><span class=\"line\">clf = GridSearchCV(SVC(kernel=<span class=\"string\">'rbf'</span>, class_weight=<span class=\"string\">'auto'</span>), param_grid)</span><br><span class=\"line\">clf = clf.fit(X_train_pca, y_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"done in %0.3fs\"</span> % (time() - t0))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Best estimator found by grid search:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(clf.best_estimator_)</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Quantitative evaluation of the model quality on the test set</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Predicting people's names on the test set\"</span>)</span><br><span class=\"line\">t0 = time()</span><br><span class=\"line\">y_pred = clf.predict(X_test_pca)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"done in %0.3fs\"</span> % (time() - t0))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(y_test, y_pred, target_names=target_names))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(confusion_matrix(y_test, y_pred, labels=range(n_classes)))</span><br><span class=\"line\"><span class=\"comment\">###############################################################################</span></span><br><span class=\"line\"><span class=\"comment\"># Qualitative evaluation of the predictions using matplotlib</span></span><br><span class=\"line\">def plot_gallery(images, titles, h, w, n_row=3, n_col=4):</span><br><span class=\"line\">    <span class=\"string\">\"\"</span><span class=\"string\">\"Helper function to plot a gallery of portraits\"</span><span class=\"string\">\"\"</span></span><br><span class=\"line\">    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))</span><br><span class=\"line\">    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n_row * n_col):</span><br><span class=\"line\">        plt.subplot(n_row, n_col, i + 1)</span><br><span class=\"line\">        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)</span><br><span class=\"line\">        plt.title(titles[i], size=12)</span><br><span class=\"line\">        plt.xticks(())</span><br><span class=\"line\">        plt.yticks(())</span><br><span class=\"line\"><span class=\"comment\"># plot the result of the prediction on a portion of the test set</span></span><br><span class=\"line\">def title(y_pred, y_test, target_names, i):</span><br><span class=\"line\">    pred_name = target_names[y_pred[i]].rsplit(<span class=\"string\">' '</span>, 1)[-1]</span><br><span class=\"line\">    true_name = target_names[y_test[i]].rsplit(<span class=\"string\">' '</span>, 1)[-1]</span><br><span class=\"line\">    <span class=\"built_in\">return</span> <span class=\"string\">'predicted: %s\\ntrue:      %s'</span> % (pred_name, true_name)</span><br><span class=\"line\">prediction_titles = [title(y_pred, y_test, target_names, i)</span><br><span class=\"line\">                     <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(y_pred.shape[0])]</span><br><span class=\"line\">plot_gallery(X_test, prediction_titles, h, w)</span><br><span class=\"line\"><span class=\"comment\"># plot the gallery of the most significative eigenfaces</span></span><br><span class=\"line\">eigenface_titles = [<span class=\"string\">\"eigenface %d\"</span> % i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(eigenfaces.shape[0])]</span><br><span class=\"line\">plot_gallery(eigenfaces, eigenface_titles, h, w)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure><p></p>"},{"title":"机器学习笔记（十）神经网络原理","date":"2017-07-03T09:02:17.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 背景:\n1.1以人脑中的神经网络为启发，历史上出现过很多不同版本\n1.2最著名的算法是1980年的 backpropagation \n2. 多层向前神经网络(Multilayer Feed-Forward Neural Network)\n2.1Backpropagation被使用在多层向前神经网络上\n2.2多层向前神经网络由以下部分组成：\n<!-- more -->\n输入层(input layer), 隐藏层 (hidden layers), 输入层 (output layers)\n![](2017-7-3-one/1.png)\n2.3每层由单元(units)组成\n2.4输入层(input layer)是由训练集的实例特征向量传入\n2.5经过连接结点的权重(weight)传入下一层，一层的输出是下一层的输入\n2.6隐藏层的个数可以是任意的，输入层有一层，输出层有一层\n2.7每个单元(unit)也可以被称作神经结点，根据生物学来源定义\n2.8以上成为2层的神经网络（输入层不算）\n2.8一层中加权的求和，然后根据非线性方程转化输出\n2.9作为多层向前神经网络，理论上，如果有足够多的隐藏层(hidden layers) 和足够大的训练集, 可以模拟出任何方程\n3. 设计神经网络结构\n3.1使用神经网络训练数据之前，必须确定神经网络的层数，以及每层单元的个数\n3.2特征向量在被传入输入层时通常被先标准化(normalize）到0和1之间 （为了加速学习过程）\n3.3离散型变量可以被编码成每一个输入单元对应一个特征值可能赋的值\n比如：特征值A可能取三个值（a0, a1, a2), 可以使用3个输入单元来代表A。\n如果A=a0, 那么代表a0的单元值就取1, 其他取0；\n如果A=a1, 那么代表a1de单元值就取1，其他取0，以此类推\n3.4神经网络即可以用来做分类(classification）问题，也可以解决回归(regression)问题\n3.4.1对于分类问题，如果是2类，可以用一个输出单元表示（0和1分别代表2类）\n如果多余2类，每一个类别用一个输出单元表示\n所以输入层的单元数量通常等于类别的数量\n3.4.2没有明确的规则来设计最好有多少个隐藏层\n3.4.2.1根据实验测试和误差，以及准确度来实验并改进\n4. 交叉验证方法(Cross-Validation)\n![](2017-7-3-one/2.jpg)\nK-fold cross validation \n5. Backpropagation算法\n5.1通过迭代性的来处理训练集中的实例\n5.2对比经过神经网络后输入层预测值(predicted value)与真实值(target value)之间\n5.3反方向（从输出层=>隐藏层=>输入层）来以最小化误差(error)来更新每个连接的权重(weight)\n5.4算法详细介绍\n输入：D：数据集，l 学习率(learning rate)， 一个多层前向神经网络\n输入：一个训练好的神经网络(a trained neural network)\n5.4.1初始化权重(weights)和偏向(bias): 随机初始化在-1到1之间，或者-0.5到0.5之间，每个单元有          \n一个偏向\n5.4.2对于每一个训练实例X，执行以下步骤：\n5.4.2.1:由输入层向前传送\n![](2017-7-3-one/3.png)\n$I_j=\\sum_i w_{ij}O_i+\\theta j$\n![](2017-7-3-one/4.png)\n$O_j=\\frac{1}{1+e^{I_j}}$\n5.4.2.2根据误差(error)反向传送\n对于输出层：\n$Err_j=O_j(1-O_j)(T_j-O_j)$\n对于隐藏层：\n$Err_j=O_j(1-O_j)\\sum{Err_kw_{jk}}$\n$\\bigtriangleup w_{ij}=(l) Err_jO_i$\n权重更新：\n$w_{ij}=w_{ij}+\\bigtriangleup w_{ij}$  \n偏向更新    \n$\\bigtriangleup \\theta_j=(l) Err_j$ \n$\\theta_j=\\theta_j+\\bigtriangleup \\theta_j$ \n5.4.3终止条件\n5.4.3.1权重的更新低于某个阈值\n5.4.3.2预测的错误率低于某个阈值\n5.4.3.3达到预设一定的循环次数\n6.  Backpropagation 算法举例\n![](2017-7-3-one/5.png)\n对于输出层：\n$Err_j=O_j(1-O_j)(T_j-O_j)$\n对于隐藏层：\n$Err_j=O_j(1-O_j)\\sum{Err_kw_{jk}}$\n$\\bigtriangleup w_{ij}=(l) Err_jO_i$\n权重更新：\n$w_{ij}=w_{ij}+\\bigtriangleup w_{ij}$  \n偏向更新    \n$\\bigtriangleup \\theta_j=(l) Err_j$ \n$\\theta_j=\\theta_j+\\bigtriangleup \\theta_j$ \n![](2017-7-3-one/6.png)\n","source":"_posts/2017-7-3-one.md","raw":"---\ntitle: 机器学习笔记（十）神经网络原理\ndate: 2017-07-03 17:02:17\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 背景:\n1.1以人脑中的神经网络为启发，历史上出现过很多不同版本\n1.2最著名的算法是1980年的 backpropagation \n2. 多层向前神经网络(Multilayer Feed-Forward Neural Network)\n2.1Backpropagation被使用在多层向前神经网络上\n2.2多层向前神经网络由以下部分组成：\n<!-- more -->\n输入层(input layer), 隐藏层 (hidden layers), 输入层 (output layers)\n![](2017-7-3-one/1.png)\n2.3每层由单元(units)组成\n2.4输入层(input layer)是由训练集的实例特征向量传入\n2.5经过连接结点的权重(weight)传入下一层，一层的输出是下一层的输入\n2.6隐藏层的个数可以是任意的，输入层有一层，输出层有一层\n2.7每个单元(unit)也可以被称作神经结点，根据生物学来源定义\n2.8以上成为2层的神经网络（输入层不算）\n2.8一层中加权的求和，然后根据非线性方程转化输出\n2.9作为多层向前神经网络，理论上，如果有足够多的隐藏层(hidden layers) 和足够大的训练集, 可以模拟出任何方程\n3. 设计神经网络结构\n3.1使用神经网络训练数据之前，必须确定神经网络的层数，以及每层单元的个数\n3.2特征向量在被传入输入层时通常被先标准化(normalize）到0和1之间 （为了加速学习过程）\n3.3离散型变量可以被编码成每一个输入单元对应一个特征值可能赋的值\n比如：特征值A可能取三个值（a0, a1, a2), 可以使用3个输入单元来代表A。\n如果A=a0, 那么代表a0的单元值就取1, 其他取0；\n如果A=a1, 那么代表a1de单元值就取1，其他取0，以此类推\n3.4神经网络即可以用来做分类(classification）问题，也可以解决回归(regression)问题\n3.4.1对于分类问题，如果是2类，可以用一个输出单元表示（0和1分别代表2类）\n如果多余2类，每一个类别用一个输出单元表示\n所以输入层的单元数量通常等于类别的数量\n3.4.2没有明确的规则来设计最好有多少个隐藏层\n3.4.2.1根据实验测试和误差，以及准确度来实验并改进\n4. 交叉验证方法(Cross-Validation)\n![](2017-7-3-one/2.jpg)\nK-fold cross validation \n5. Backpropagation算法\n5.1通过迭代性的来处理训练集中的实例\n5.2对比经过神经网络后输入层预测值(predicted value)与真实值(target value)之间\n5.3反方向（从输出层=>隐藏层=>输入层）来以最小化误差(error)来更新每个连接的权重(weight)\n5.4算法详细介绍\n输入：D：数据集，l 学习率(learning rate)， 一个多层前向神经网络\n输入：一个训练好的神经网络(a trained neural network)\n5.4.1初始化权重(weights)和偏向(bias): 随机初始化在-1到1之间，或者-0.5到0.5之间，每个单元有          \n一个偏向\n5.4.2对于每一个训练实例X，执行以下步骤：\n5.4.2.1:由输入层向前传送\n![](2017-7-3-one/3.png)\n$I_j=\\sum_i w_{ij}O_i+\\theta j$\n![](2017-7-3-one/4.png)\n$O_j=\\frac{1}{1+e^{I_j}}$\n5.4.2.2根据误差(error)反向传送\n对于输出层：\n$Err_j=O_j(1-O_j)(T_j-O_j)$\n对于隐藏层：\n$Err_j=O_j(1-O_j)\\sum{Err_kw_{jk}}$\n$\\bigtriangleup w_{ij}=(l) Err_jO_i$\n权重更新：\n$w_{ij}=w_{ij}+\\bigtriangleup w_{ij}$  \n偏向更新    \n$\\bigtriangleup \\theta_j=(l) Err_j$ \n$\\theta_j=\\theta_j+\\bigtriangleup \\theta_j$ \n5.4.3终止条件\n5.4.3.1权重的更新低于某个阈值\n5.4.3.2预测的错误率低于某个阈值\n5.4.3.3达到预设一定的循环次数\n6.  Backpropagation 算法举例\n![](2017-7-3-one/5.png)\n对于输出层：\n$Err_j=O_j(1-O_j)(T_j-O_j)$\n对于隐藏层：\n$Err_j=O_j(1-O_j)\\sum{Err_kw_{jk}}$\n$\\bigtriangleup w_{ij}=(l) Err_jO_i$\n权重更新：\n$w_{ij}=w_{ij}+\\bigtriangleup w_{ij}$  \n偏向更新    \n$\\bigtriangleup \\theta_j=(l) Err_j$ \n$\\theta_j=\\theta_j+\\bigtriangleup \\theta_j$ \n![](2017-7-3-one/6.png)\n","slug":"2017-7-3-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001dycvj9oylf9tr","content":"<ol>\n<li>背景:<br>1.1以人脑中的神经网络为启发，历史上出现过很多不同版本<br>1.2最著名的算法是1980年的 backpropagation </li>\n<li>多层向前神经网络(Multilayer Feed-Forward Neural Network)<br>2.1Backpropagation被使用在多层向前神经网络上<br>2.2多层向前神经网络由以下部分组成：<a id=\"more\"></a>\n输入层(input layer), 隐藏层 (hidden layers), 输入层 (output layers)<br><img src=\"/2017/07/03/2017-7-3-one/1.png\" alt=\"\"><br>2.3每层由单元(units)组成<br>2.4输入层(input layer)是由训练集的实例特征向量传入<br>2.5经过连接结点的权重(weight)传入下一层，一层的输出是下一层的输入<br>2.6隐藏层的个数可以是任意的，输入层有一层，输出层有一层<br>2.7每个单元(unit)也可以被称作神经结点，根据生物学来源定义<br>2.8以上成为2层的神经网络（输入层不算）<br>2.8一层中加权的求和，然后根据非线性方程转化输出<br>2.9作为多层向前神经网络，理论上，如果有足够多的隐藏层(hidden layers) 和足够大的训练集, 可以模拟出任何方程</li>\n<li>设计神经网络结构<br>3.1使用神经网络训练数据之前，必须确定神经网络的层数，以及每层单元的个数<br>3.2特征向量在被传入输入层时通常被先标准化(normalize）到0和1之间 （为了加速学习过程）<br>3.3离散型变量可以被编码成每一个输入单元对应一个特征值可能赋的值<br>比如：特征值A可能取三个值（a0, a1, a2), 可以使用3个输入单元来代表A。<br>如果A=a0, 那么代表a0的单元值就取1, 其他取0；<br>如果A=a1, 那么代表a1de单元值就取1，其他取0，以此类推<br>3.4神经网络即可以用来做分类(classification）问题，也可以解决回归(regression)问题<br>3.4.1对于分类问题，如果是2类，可以用一个输出单元表示（0和1分别代表2类）<br>如果多余2类，每一个类别用一个输出单元表示<br>所以输入层的单元数量通常等于类别的数量<br>3.4.2没有明确的规则来设计最好有多少个隐藏层<br>3.4.2.1根据实验测试和误差，以及准确度来实验并改进</li>\n<li>交叉验证方法(Cross-Validation)<br><img src=\"/2017/07/03/2017-7-3-one/2.jpg\" alt=\"\"><br>K-fold cross validation </li>\n<li>Backpropagation算法<br>5.1通过迭代性的来处理训练集中的实例<br>5.2对比经过神经网络后输入层预测值(predicted value)与真实值(target value)之间<br>5.3反方向（从输出层=&gt;隐藏层=&gt;输入层）来以最小化误差(error)来更新每个连接的权重(weight)<br>5.4算法详细介绍<br>输入：D：数据集，l 学习率(learning rate)， 一个多层前向神经网络<br>输入：一个训练好的神经网络(a trained neural network)<br>5.4.1初始化权重(weights)和偏向(bias): 随机初始化在-1到1之间，或者-0.5到0.5之间，每个单元有<br>一个偏向<br>5.4.2对于每一个训练实例X，执行以下步骤：<br>5.4.2.1:由输入层向前传送<br><img src=\"/2017/07/03/2017-7-3-one/3.png\" alt=\"\"><br>$I_j=\\sum_i w_{ij}O_i+\\theta j$<br><img src=\"/2017/07/03/2017-7-3-one/4.png\" alt=\"\"><br>$O_j=\\frac{1}{1+e^{I_j}}$<br>5.4.2.2根据误差(error)反向传送<br>对于输出层：<br>$Err_j=O_j(1-O_j)(T_j-O_j)$<br>对于隐藏层：<br>$Err_j=O_j(1-O_j)\\sum{Err_kw_{jk}}$<br>$\\bigtriangleup w_{ij}=(l) Err_jO_i$<br>权重更新：<br>$w_{ij}=w_{ij}+\\bigtriangleup w_{ij}$<br>偏向更新<br>$\\bigtriangleup \\theta_j=(l) Err_j$<br>$\\theta_j=\\theta_j+\\bigtriangleup \\theta_j$<br>5.4.3终止条件<br>5.4.3.1权重的更新低于某个阈值<br>5.4.3.2预测的错误率低于某个阈值<br>5.4.3.3达到预设一定的循环次数</li>\n<li>Backpropagation 算法举例<br><img src=\"/2017/07/03/2017-7-3-one/5.png\" alt=\"\"><br>对于输出层：<br>$Err_j=O_j(1-O_j)(T_j-O_j)$<br>对于隐藏层：<br>$Err_j=O_j(1-O_j)\\sum{Err_kw_{jk}}$<br>$\\bigtriangleup w_{ij}=(l) Err_jO_i$<br>权重更新：<br>$w_{ij}=w_{ij}+\\bigtriangleup w_{ij}$<br>偏向更新<br>$\\bigtriangleup \\theta_j=(l) Err_j$<br>$\\theta_j=\\theta_j+\\bigtriangleup \\theta_j$<br><img src=\"/2017/07/03/2017-7-3-one/6.png\" alt=\"\"></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>背景:<br>1.1以人脑中的神经网络为启发，历史上出现过很多不同版本<br>1.2最著名的算法是1980年的 backpropagation </li>\n<li>多层向前神经网络(Multilayer Feed-Forward Neural Network)<br>2.1Backpropagation被使用在多层向前神经网络上<br>2.2多层向前神经网络由以下部分组成：</li></ol>","more":"输入层(input layer), 隐藏层 (hidden layers), 输入层 (output layers)<br><img src=\"/2017/07/03/2017-7-3-one/1.png\" alt=\"\"><br>2.3每层由单元(units)组成<br>2.4输入层(input layer)是由训练集的实例特征向量传入<br>2.5经过连接结点的权重(weight)传入下一层，一层的输出是下一层的输入<br>2.6隐藏层的个数可以是任意的，输入层有一层，输出层有一层<br>2.7每个单元(unit)也可以被称作神经结点，根据生物学来源定义<br>2.8以上成为2层的神经网络（输入层不算）<br>2.8一层中加权的求和，然后根据非线性方程转化输出<br>2.9作为多层向前神经网络，理论上，如果有足够多的隐藏层(hidden layers) 和足够大的训练集, 可以模拟出任何方程\n<li>设计神经网络结构<br>3.1使用神经网络训练数据之前，必须确定神经网络的层数，以及每层单元的个数<br>3.2特征向量在被传入输入层时通常被先标准化(normalize）到0和1之间 （为了加速学习过程）<br>3.3离散型变量可以被编码成每一个输入单元对应一个特征值可能赋的值<br>比如：特征值A可能取三个值（a0, a1, a2), 可以使用3个输入单元来代表A。<br>如果A=a0, 那么代表a0的单元值就取1, 其他取0；<br>如果A=a1, 那么代表a1de单元值就取1，其他取0，以此类推<br>3.4神经网络即可以用来做分类(classification）问题，也可以解决回归(regression)问题<br>3.4.1对于分类问题，如果是2类，可以用一个输出单元表示（0和1分别代表2类）<br>如果多余2类，每一个类别用一个输出单元表示<br>所以输入层的单元数量通常等于类别的数量<br>3.4.2没有明确的规则来设计最好有多少个隐藏层<br>3.4.2.1根据实验测试和误差，以及准确度来实验并改进</li>\n<li>交叉验证方法(Cross-Validation)<br><img src=\"/2017/07/03/2017-7-3-one/2.jpg\" alt=\"\"><br>K-fold cross validation </li>\n<li>Backpropagation算法<br>5.1通过迭代性的来处理训练集中的实例<br>5.2对比经过神经网络后输入层预测值(predicted value)与真实值(target value)之间<br>5.3反方向（从输出层=&gt;隐藏层=&gt;输入层）来以最小化误差(error)来更新每个连接的权重(weight)<br>5.4算法详细介绍<br>输入：D：数据集，l 学习率(learning rate)， 一个多层前向神经网络<br>输入：一个训练好的神经网络(a trained neural network)<br>5.4.1初始化权重(weights)和偏向(bias): 随机初始化在-1到1之间，或者-0.5到0.5之间，每个单元有<br>一个偏向<br>5.4.2对于每一个训练实例X，执行以下步骤：<br>5.4.2.1:由输入层向前传送<br><img src=\"/2017/07/03/2017-7-3-one/3.png\" alt=\"\"><br>$I_j=\\sum_i w_{ij}O_i+\\theta j$<br><img src=\"/2017/07/03/2017-7-3-one/4.png\" alt=\"\"><br>$O_j=\\frac{1}{1+e^{I_j}}$<br>5.4.2.2根据误差(error)反向传送<br>对于输出层：<br>$Err_j=O_j(1-O_j)(T_j-O_j)$<br>对于隐藏层：<br>$Err_j=O_j(1-O_j)\\sum{Err_kw_{jk}}$<br>$\\bigtriangleup w_{ij}=(l) Err_jO_i$<br>权重更新：<br>$w_{ij}=w_{ij}+\\bigtriangleup w_{ij}$<br>偏向更新<br>$\\bigtriangleup \\theta_j=(l) Err_j$<br>$\\theta_j=\\theta_j+\\bigtriangleup \\theta_j$<br>5.4.3终止条件<br>5.4.3.1权重的更新低于某个阈值<br>5.4.3.2预测的错误率低于某个阈值<br>5.4.3.3达到预设一定的循环次数</li>\n<li>Backpropagation 算法举例<br><img src=\"/2017/07/03/2017-7-3-one/5.png\" alt=\"\"><br>对于输出层：<br>$Err_j=O_j(1-O_j)(T_j-O_j)$<br>对于隐藏层：<br>$Err_j=O_j(1-O_j)\\sum{Err_kw_{jk}}$<br>$\\bigtriangleup w_{ij}=(l) Err_jO_i$<br>权重更新：<br>$w_{ij}=w_{ij}+\\bigtriangleup w_{ij}$<br>偏向更新<br>$\\bigtriangleup \\theta_j=(l) Err_j$<br>$\\theta_j=\\theta_j+\\bigtriangleup \\theta_j$<br><img src=\"/2017/07/03/2017-7-3-one/6.png\" alt=\"\"></li>\n"},{"title":"机器学习笔记（十一）神经网络应用","date":"2017-07-03T13:08:39.000Z","comments":1,"reward":true,"_content":"1. 关于非线性转化方程(non-linear transformation function)\nsigmoid函数(S 曲线)用来作为activation function:\n1.1双曲函数(tanh)\n1.2逻辑函数(logistic function)\n2. 用类实现一个简单的神经网络算法\n<!-- more -->\n``` bash\nimport numpy as np\ndef tanh(x):  \n    return np.tanh(x)\ndef tanh_deriv(x):  \n    return 1.0 - np.tanh(x)*np.tanh(x)\ndef logistic(x):  \n    return 1/(1 + np.exp(-x))\ndef logistic_derivative(x):  \n    return logistic(x)*(1-logistic(x))\nclass NeuralNetwork:   \n    def __init__(self, layers, activation='tanh'):  \n        \"\"\"  \n        :param layers: A list containing the number of units in each layer.\n        Should be at least two values  \n        :param activation: The activation function to be used. Can be\n        \"logistic\" or \"tanh\"  \n        \"\"\"  \n        if activation == 'logistic':  \n            self.activation = logistic  \n            self.activation_deriv = logistic_derivative  \n        elif activation == 'tanh':  \n            self.activation = tanh  \n            self.activation_deriv = tanh_deriv\n    \n        self.weights = []  \n        for i in range(1, len(layers) - 1):  \n            self.weights.append((2*np.random.random((layers[i - 1] + 1, layers[i] + 1))-1)*0.25)  \n            self.weights.append((2*np.random.random((layers[i] + 1, layers[i + 1]))-1)*0.25)\n            \n            \n    def fit(self, X, y, learning_rate=0.2, epochs=10000):         \n        X = np.atleast_2d(X)         \n        temp = np.ones([X.shape[0], X.shape[1]+1])         \n        temp[:, 0:-1] = X  # adding the bias unit to the input layer         \n        X = temp         \n        y = np.array(y)\n    \n        for k in range(epochs):  \n            i = np.random.randint(X.shape[0])  \n            a = [X[i]]\n    \n            for l in range(len(self.weights)):  #going forward network, for each layer\n                a.append(self.activation(np.dot(a[l], self.weights[l])))  #Computer the node value for each layer (O_i) using activation function\n            error = y[i] - a[-1]  #Computer the error at the top layer\n            deltas = [error * self.activation_deriv(a[-1])] #For output layer, Err calculation (delta is updated error)\n            \n            #Staring backprobagation\n            for l in range(len(a) - 2, 0, -1): # we need to begin at the second to last layer \n                #Compute the updated error (i,e, deltas) for each node going from top layer to input layer \n                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))  \n            deltas.reverse()  \n            for i in range(len(self.weights)):  \n                layer = np.atleast_2d(a[i])  \n                delta = np.atleast_2d(deltas[i])  \n                self.weights[i] += learning_rate * layer.T.dot(delta)\n                \n                \n    def predict(self, x):         \n        x = np.array(x)         \n        temp = np.ones(x.shape[0]+1)         \n        temp[0:-1] = x         \n        a = temp         \n        for l in range(0, len(self.weights)):             \n            a = self.activation(np.dot(a, self.weights[l]))         \n        return a\n```\n3. 简单非线性关系数据集测试(XOR):\nX:                  Y\n0 0                 0\n0 1                 1\n1 0                 1\n1 1                 0\n``` bash\nfrom NeuralNetwork import NeuralNetwork\nimport numpy as np\nnn = NeuralNetwork([2,2,1], 'tanh')     \nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])     \ny = np.array([0, 1, 1, 0])     \nnn.fit(X, y)     \nfor i in [[0, 0], [0, 1], [1, 0], [1,1]]:    \n    print(i, nn.predict(i))\n```\n4. 手写数字识别：\n每个图片8x8 \n识别数字：0,1,2,3,4,5,6,7,8,9\n``` bash\nimport numpy as np \nfrom sklearn.datasets import load_digits \nfrom sklearn.metrics import confusion_matrix, classification_report \nfrom sklearn.preprocessing import LabelBinarizer \nfrom NeuralNetwork import NeuralNetwork\nfrom sklearn.cross_validation import train_test_split\ndigits = load_digits()  \nX = digits.data  \ny = digits.target  \nX -= X.min() # normalize the values to bring them into the range 0-1  \nX /= X.max()\nnn = NeuralNetwork([64,100,10],'logistic')  \nX_train, X_test, y_train, y_test = train_test_split(X, y)  \nlabels_train = LabelBinarizer().fit_transform(y_train)  \nlabels_test = LabelBinarizer().fit_transform(y_test)\nprint \"start fitting\"\nnn.fit(X_train,labels_train,epochs=3000)  \npredictions = []  \nfor i in range(X_test.shape[0]):  \n    o = nn.predict(X_test[i] )  \n    predictions.append(np.argmax(o))  \nprint confusion_matrix(y_test,predictions)  \nprint classification_report(y_test,predictions)\n```","source":"_posts/2017-7-3-three.md","raw":"---\ntitle: 机器学习笔记（十一）神经网络应用\ndate: 2017-07-03 21:08:39\ncomments: true\nreward: true\ntags: \n - 机器学习\n---\n1. 关于非线性转化方程(non-linear transformation function)\nsigmoid函数(S 曲线)用来作为activation function:\n1.1双曲函数(tanh)\n1.2逻辑函数(logistic function)\n2. 用类实现一个简单的神经网络算法\n<!-- more -->\n``` bash\nimport numpy as np\ndef tanh(x):  \n    return np.tanh(x)\ndef tanh_deriv(x):  \n    return 1.0 - np.tanh(x)*np.tanh(x)\ndef logistic(x):  \n    return 1/(1 + np.exp(-x))\ndef logistic_derivative(x):  \n    return logistic(x)*(1-logistic(x))\nclass NeuralNetwork:   \n    def __init__(self, layers, activation='tanh'):  \n        \"\"\"  \n        :param layers: A list containing the number of units in each layer.\n        Should be at least two values  \n        :param activation: The activation function to be used. Can be\n        \"logistic\" or \"tanh\"  \n        \"\"\"  \n        if activation == 'logistic':  \n            self.activation = logistic  \n            self.activation_deriv = logistic_derivative  \n        elif activation == 'tanh':  \n            self.activation = tanh  \n            self.activation_deriv = tanh_deriv\n    \n        self.weights = []  \n        for i in range(1, len(layers) - 1):  \n            self.weights.append((2*np.random.random((layers[i - 1] + 1, layers[i] + 1))-1)*0.25)  \n            self.weights.append((2*np.random.random((layers[i] + 1, layers[i + 1]))-1)*0.25)\n            \n            \n    def fit(self, X, y, learning_rate=0.2, epochs=10000):         \n        X = np.atleast_2d(X)         \n        temp = np.ones([X.shape[0], X.shape[1]+1])         \n        temp[:, 0:-1] = X  # adding the bias unit to the input layer         \n        X = temp         \n        y = np.array(y)\n    \n        for k in range(epochs):  \n            i = np.random.randint(X.shape[0])  \n            a = [X[i]]\n    \n            for l in range(len(self.weights)):  #going forward network, for each layer\n                a.append(self.activation(np.dot(a[l], self.weights[l])))  #Computer the node value for each layer (O_i) using activation function\n            error = y[i] - a[-1]  #Computer the error at the top layer\n            deltas = [error * self.activation_deriv(a[-1])] #For output layer, Err calculation (delta is updated error)\n            \n            #Staring backprobagation\n            for l in range(len(a) - 2, 0, -1): # we need to begin at the second to last layer \n                #Compute the updated error (i,e, deltas) for each node going from top layer to input layer \n                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))  \n            deltas.reverse()  \n            for i in range(len(self.weights)):  \n                layer = np.atleast_2d(a[i])  \n                delta = np.atleast_2d(deltas[i])  \n                self.weights[i] += learning_rate * layer.T.dot(delta)\n                \n                \n    def predict(self, x):         \n        x = np.array(x)         \n        temp = np.ones(x.shape[0]+1)         \n        temp[0:-1] = x         \n        a = temp         \n        for l in range(0, len(self.weights)):             \n            a = self.activation(np.dot(a, self.weights[l]))         \n        return a\n```\n3. 简单非线性关系数据集测试(XOR):\nX:                  Y\n0 0                 0\n0 1                 1\n1 0                 1\n1 1                 0\n``` bash\nfrom NeuralNetwork import NeuralNetwork\nimport numpy as np\nnn = NeuralNetwork([2,2,1], 'tanh')     \nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])     \ny = np.array([0, 1, 1, 0])     \nnn.fit(X, y)     \nfor i in [[0, 0], [0, 1], [1, 0], [1,1]]:    \n    print(i, nn.predict(i))\n```\n4. 手写数字识别：\n每个图片8x8 \n识别数字：0,1,2,3,4,5,6,7,8,9\n``` bash\nimport numpy as np \nfrom sklearn.datasets import load_digits \nfrom sklearn.metrics import confusion_matrix, classification_report \nfrom sklearn.preprocessing import LabelBinarizer \nfrom NeuralNetwork import NeuralNetwork\nfrom sklearn.cross_validation import train_test_split\ndigits = load_digits()  \nX = digits.data  \ny = digits.target  \nX -= X.min() # normalize the values to bring them into the range 0-1  \nX /= X.max()\nnn = NeuralNetwork([64,100,10],'logistic')  \nX_train, X_test, y_train, y_test = train_test_split(X, y)  \nlabels_train = LabelBinarizer().fit_transform(y_train)  \nlabels_test = LabelBinarizer().fit_transform(y_test)\nprint \"start fitting\"\nnn.fit(X_train,labels_train,epochs=3000)  \npredictions = []  \nfor i in range(X_test.shape[0]):  \n    o = nn.predict(X_test[i] )  \n    predictions.append(np.argmax(o))  \nprint confusion_matrix(y_test,predictions)  \nprint classification_report(y_test,predictions)\n```","slug":"2017-7-3-three","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001fycvjaezexm6k","content":"<ol>\n<li>关于非线性转化方程(non-linear transformation function)<br>sigmoid函数(S 曲线)用来作为activation function:<br>1.1双曲函数(tanh)<br>1.2逻辑函数(logistic function)</li>\n<li><p>用类实现一个简单的神经网络算法</p>\n<a id=\"more\"></a>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">def tanh(x):  </span><br><span class=\"line\">    <span class=\"built_in\">return</span> np.tanh(x)</span><br><span class=\"line\">def tanh_deriv(x):  </span><br><span class=\"line\">    <span class=\"built_in\">return</span> 1.0 - np.tanh(x)*np.tanh(x)</span><br><span class=\"line\">def logistic(x):  </span><br><span class=\"line\">    <span class=\"built_in\">return</span> 1/(1 + np.exp(-x))</span><br><span class=\"line\">def logistic_derivative(x):  </span><br><span class=\"line\">    <span class=\"built_in\">return</span> logistic(x)*(1-logistic(x))</span><br><span class=\"line\">class NeuralNetwork:   </span><br><span class=\"line\">    def __init__(self, layers, activation=<span class=\"string\">'tanh'</span>):  </span><br><span class=\"line\">        <span class=\"string\">\"\"</span><span class=\"string\">\"  </span></span><br><span class=\"line\"><span class=\"string\">        :param layers: A list containing the number of units in each layer.</span></span><br><span class=\"line\"><span class=\"string\">        Should be at least two values  </span></span><br><span class=\"line\"><span class=\"string\">        :param activation: The activation function to be used. Can be</span></span><br><span class=\"line\"><span class=\"string\">        \"</span>logistic<span class=\"string\">\" or \"</span>tanh<span class=\"string\">\"  </span></span><br><span class=\"line\"><span class=\"string\">        \"</span><span class=\"string\">\"\"</span>  </span><br><span class=\"line\">        <span class=\"keyword\">if</span> activation == <span class=\"string\">'logistic'</span>:  </span><br><span class=\"line\">            self.activation = logistic  </span><br><span class=\"line\">            self.activation_deriv = logistic_derivative  </span><br><span class=\"line\">        <span class=\"keyword\">elif</span> activation == <span class=\"string\">'tanh'</span>:  </span><br><span class=\"line\">            self.activation = tanh  </span><br><span class=\"line\">            self.activation_deriv = tanh_deriv</span><br><span class=\"line\">    </span><br><span class=\"line\">        self.weights = []  </span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1, len(layers) - 1):  </span><br><span class=\"line\">            self.weights.append((2*np.random.random((layers[i - 1] + 1, layers[i] + 1))-1)*0.25)  </span><br><span class=\"line\">            self.weights.append((2*np.random.random((layers[i] + 1, layers[i + 1]))-1)*0.25)</span><br><span class=\"line\">            </span><br><span class=\"line\">            </span><br><span class=\"line\">    def fit(self, X, y, learning_rate=0.2, epochs=10000):         </span><br><span class=\"line\">        X = np.atleast_2d(X)         </span><br><span class=\"line\">        temp = np.ones([X.shape[0], X.shape[1]+1])         </span><br><span class=\"line\">        temp[:, 0:-1] = X  <span class=\"comment\"># adding the bias unit to the input layer         </span></span><br><span class=\"line\">        X = temp         </span><br><span class=\"line\">        y = np.array(y)</span><br><span class=\"line\">    </span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(epochs):  </span><br><span class=\"line\">            i = np.random.randint(X.shape[0])  </span><br><span class=\"line\">            a = [X[i]]</span><br><span class=\"line\">    </span><br><span class=\"line\">            <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(len(self.weights)):  <span class=\"comment\">#going forward network, for each layer</span></span><br><span class=\"line\">                a.append(self.activation(np.dot(a[l], self.weights[l])))  <span class=\"comment\">#Computer the node value for each layer (O_i) using activation function</span></span><br><span class=\"line\">            error = y[i] - a[-1]  <span class=\"comment\">#Computer the error at the top layer</span></span><br><span class=\"line\">            deltas = [error * self.activation_deriv(a[-1])] <span class=\"comment\">#For output layer, Err calculation (delta is updated error)</span></span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\">#Staring backprobagation</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(len(a) - 2, 0, -1): <span class=\"comment\"># we need to begin at the second to last layer </span></span><br><span class=\"line\">                <span class=\"comment\">#Compute the updated error (i,e, deltas) for each node going from top layer to input layer </span></span><br><span class=\"line\">                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))  </span><br><span class=\"line\">            deltas.reverse()  </span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(self.weights)):  </span><br><span class=\"line\">                layer = np.atleast_2d(a[i])  </span><br><span class=\"line\">                delta = np.atleast_2d(deltas[i])  </span><br><span class=\"line\">                self.weights[i] += learning_rate * layer.T.dot(delta)</span><br><span class=\"line\">                </span><br><span class=\"line\">                </span><br><span class=\"line\">    def predict(self, x):         </span><br><span class=\"line\">        x = np.array(x)         </span><br><span class=\"line\">        temp = np.ones(x.shape[0]+1)         </span><br><span class=\"line\">        temp[0:-1] = x         </span><br><span class=\"line\">        a = temp         </span><br><span class=\"line\">        <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(0, len(self.weights)):             </span><br><span class=\"line\">            a = self.activation(np.dot(a, self.weights[l]))         </span><br><span class=\"line\">        <span class=\"built_in\">return</span> a</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>简单非线性关系数据集测试(XOR):<br>X:                  Y<br>0 0                 0<br>0 1                 1<br>1 0                 1<br>1 1                 0</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from NeuralNetwork import NeuralNetwork</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">nn = NeuralNetwork([2,2,1], <span class=\"string\">'tanh'</span>)     </span><br><span class=\"line\">X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])     </span><br><span class=\"line\">y = np.array([0, 1, 1, 0])     </span><br><span class=\"line\">nn.fit(X, y)     </span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> [[0, 0], [0, 1], [1, 0], [1,1]]:    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(i, nn.predict(i))</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>手写数字识别：<br>每个图片8x8<br>识别数字：0,1,2,3,4,5,6,7,8,9</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np </span><br><span class=\"line\">from sklearn.datasets import load_digits </span><br><span class=\"line\">from sklearn.metrics import confusion_matrix, classification_report </span><br><span class=\"line\">from sklearn.preprocessing import LabelBinarizer </span><br><span class=\"line\">from NeuralNetwork import NeuralNetwork</span><br><span class=\"line\">from sklearn.cross_validation import train_test_split</span><br><span class=\"line\">digits = load_digits()  </span><br><span class=\"line\">X = digits.data  </span><br><span class=\"line\">y = digits.target  </span><br><span class=\"line\">X -= X.min() <span class=\"comment\"># normalize the values to bring them into the range 0-1  </span></span><br><span class=\"line\">X /= X.max()</span><br><span class=\"line\">nn = NeuralNetwork([64,100,10],<span class=\"string\">'logistic'</span>)  </span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y)  </span><br><span class=\"line\">labels_train = LabelBinarizer().fit_transform(y_train)  </span><br><span class=\"line\">labels_test = LabelBinarizer().fit_transform(y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"start fitting\"</span></span><br><span class=\"line\">nn.fit(X_train,labels_train,epochs=3000)  </span><br><span class=\"line\">predictions = []  </span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(X_test.shape[0]):  </span><br><span class=\"line\">    o = nn.predict(X_test[i] )  </span><br><span class=\"line\">    predictions.append(np.argmax(o))  </span><br><span class=\"line\"><span class=\"built_in\">print</span> confusion_matrix(y_test,predictions)  </span><br><span class=\"line\"><span class=\"built_in\">print</span> classification_report(y_test,predictions)</span><br></pre></td></tr></table></figure></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>关于非线性转化方程(non-linear transformation function)<br>sigmoid函数(S 曲线)用来作为activation function:<br>1.1双曲函数(tanh)<br>1.2逻辑函数(logistic function)</li>\n<li><p>用类实现一个简单的神经网络算法</p></li></ol>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">def tanh(x):  </span><br><span class=\"line\">    <span class=\"built_in\">return</span> np.tanh(x)</span><br><span class=\"line\">def tanh_deriv(x):  </span><br><span class=\"line\">    <span class=\"built_in\">return</span> 1.0 - np.tanh(x)*np.tanh(x)</span><br><span class=\"line\">def logistic(x):  </span><br><span class=\"line\">    <span class=\"built_in\">return</span> 1/(1 + np.exp(-x))</span><br><span class=\"line\">def logistic_derivative(x):  </span><br><span class=\"line\">    <span class=\"built_in\">return</span> logistic(x)*(1-logistic(x))</span><br><span class=\"line\">class NeuralNetwork:   </span><br><span class=\"line\">    def __init__(self, layers, activation=<span class=\"string\">'tanh'</span>):  </span><br><span class=\"line\">        <span class=\"string\">\"\"</span><span class=\"string\">\"  </span></span><br><span class=\"line\"><span class=\"string\">        :param layers: A list containing the number of units in each layer.</span></span><br><span class=\"line\"><span class=\"string\">        Should be at least two values  </span></span><br><span class=\"line\"><span class=\"string\">        :param activation: The activation function to be used. Can be</span></span><br><span class=\"line\"><span class=\"string\">        \"</span>logistic<span class=\"string\">\" or \"</span>tanh<span class=\"string\">\"  </span></span><br><span class=\"line\"><span class=\"string\">        \"</span><span class=\"string\">\"\"</span>  </span><br><span class=\"line\">        <span class=\"keyword\">if</span> activation == <span class=\"string\">'logistic'</span>:  </span><br><span class=\"line\">            self.activation = logistic  </span><br><span class=\"line\">            self.activation_deriv = logistic_derivative  </span><br><span class=\"line\">        <span class=\"keyword\">elif</span> activation == <span class=\"string\">'tanh'</span>:  </span><br><span class=\"line\">            self.activation = tanh  </span><br><span class=\"line\">            self.activation_deriv = tanh_deriv</span><br><span class=\"line\">    </span><br><span class=\"line\">        self.weights = []  </span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1, len(layers) - 1):  </span><br><span class=\"line\">            self.weights.append((2*np.random.random((layers[i - 1] + 1, layers[i] + 1))-1)*0.25)  </span><br><span class=\"line\">            self.weights.append((2*np.random.random((layers[i] + 1, layers[i + 1]))-1)*0.25)</span><br><span class=\"line\">            </span><br><span class=\"line\">            </span><br><span class=\"line\">    def fit(self, X, y, learning_rate=0.2, epochs=10000):         </span><br><span class=\"line\">        X = np.atleast_2d(X)         </span><br><span class=\"line\">        temp = np.ones([X.shape[0], X.shape[1]+1])         </span><br><span class=\"line\">        temp[:, 0:-1] = X  <span class=\"comment\"># adding the bias unit to the input layer         </span></span><br><span class=\"line\">        X = temp         </span><br><span class=\"line\">        y = np.array(y)</span><br><span class=\"line\">    </span><br><span class=\"line\">        <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> range(epochs):  </span><br><span class=\"line\">            i = np.random.randint(X.shape[0])  </span><br><span class=\"line\">            a = [X[i]]</span><br><span class=\"line\">    </span><br><span class=\"line\">            <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(len(self.weights)):  <span class=\"comment\">#going forward network, for each layer</span></span><br><span class=\"line\">                a.append(self.activation(np.dot(a[l], self.weights[l])))  <span class=\"comment\">#Computer the node value for each layer (O_i) using activation function</span></span><br><span class=\"line\">            error = y[i] - a[-1]  <span class=\"comment\">#Computer the error at the top layer</span></span><br><span class=\"line\">            deltas = [error * self.activation_deriv(a[-1])] <span class=\"comment\">#For output layer, Err calculation (delta is updated error)</span></span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\">#Staring backprobagation</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(len(a) - 2, 0, -1): <span class=\"comment\"># we need to begin at the second to last layer </span></span><br><span class=\"line\">                <span class=\"comment\">#Compute the updated error (i,e, deltas) for each node going from top layer to input layer </span></span><br><span class=\"line\">                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))  </span><br><span class=\"line\">            deltas.reverse()  </span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(self.weights)):  </span><br><span class=\"line\">                layer = np.atleast_2d(a[i])  </span><br><span class=\"line\">                delta = np.atleast_2d(deltas[i])  </span><br><span class=\"line\">                self.weights[i] += learning_rate * layer.T.dot(delta)</span><br><span class=\"line\">                </span><br><span class=\"line\">                </span><br><span class=\"line\">    def predict(self, x):         </span><br><span class=\"line\">        x = np.array(x)         </span><br><span class=\"line\">        temp = np.ones(x.shape[0]+1)         </span><br><span class=\"line\">        temp[0:-1] = x         </span><br><span class=\"line\">        a = temp         </span><br><span class=\"line\">        <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> range(0, len(self.weights)):             </span><br><span class=\"line\">            a = self.activation(np.dot(a, self.weights[l]))         </span><br><span class=\"line\">        <span class=\"built_in\">return</span> a</span><br></pre></td></tr></table></figure>\n\n<li><p>简单非线性关系数据集测试(XOR):<br>X:                  Y<br>0 0                 0<br>0 1                 1<br>1 0                 1<br>1 1                 0</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from NeuralNetwork import NeuralNetwork</span><br><span class=\"line\">import numpy as np</span><br><span class=\"line\">nn = NeuralNetwork([2,2,1], <span class=\"string\">'tanh'</span>)     </span><br><span class=\"line\">X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])     </span><br><span class=\"line\">y = np.array([0, 1, 1, 0])     </span><br><span class=\"line\">nn.fit(X, y)     </span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> [[0, 0], [0, 1], [1, 0], [1,1]]:    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(i, nn.predict(i))</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>手写数字识别：<br>每个图片8x8<br>识别数字：0,1,2,3,4,5,6,7,8,9</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np </span><br><span class=\"line\">from sklearn.datasets import load_digits </span><br><span class=\"line\">from sklearn.metrics import confusion_matrix, classification_report </span><br><span class=\"line\">from sklearn.preprocessing import LabelBinarizer </span><br><span class=\"line\">from NeuralNetwork import NeuralNetwork</span><br><span class=\"line\">from sklearn.cross_validation import train_test_split</span><br><span class=\"line\">digits = load_digits()  </span><br><span class=\"line\">X = digits.data  </span><br><span class=\"line\">y = digits.target  </span><br><span class=\"line\">X -= X.min() <span class=\"comment\"># normalize the values to bring them into the range 0-1  </span></span><br><span class=\"line\">X /= X.max()</span><br><span class=\"line\">nn = NeuralNetwork([64,100,10],<span class=\"string\">'logistic'</span>)  </span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y)  </span><br><span class=\"line\">labels_train = LabelBinarizer().fit_transform(y_train)  </span><br><span class=\"line\">labels_test = LabelBinarizer().fit_transform(y_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"start fitting\"</span></span><br><span class=\"line\">nn.fit(X_train,labels_train,epochs=3000)  </span><br><span class=\"line\">predictions = []  </span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(X_test.shape[0]):  </span><br><span class=\"line\">    o = nn.predict(X_test[i] )  </span><br><span class=\"line\">    predictions.append(np.argmax(o))  </span><br><span class=\"line\"><span class=\"built_in\">print</span> confusion_matrix(y_test,predictions)  </span><br><span class=\"line\"><span class=\"built_in\">print</span> classification_report(y_test,predictions)</span><br></pre></td></tr></table></figure></li>\n"},{"title":"解决hexo数学公式编辑不正确的问题","date":"2017-07-03T12:58:10.000Z","comments":1,"reward":true,"_content":"hexo在编译数学公式时有时会将_渲染错误造成｛｝内多个下标无法正确识别的情况，本文给出解决办法.\n找到marked.js文件 去掉对_渲染的部分，修改之后如下图\n<!-- more -->\n![](2017-7-3-two/1.png)","source":"_posts/2017-7-3-two.md","raw":"---\ntitle: 解决hexo数学公式编辑不正确的问题\ndate: 2017-07-03 20:58:10\ncomments: true\nreward: true\ntags: \n - hexo \n---\nhexo在编译数学公式时有时会将_渲染错误造成｛｝内多个下标无法正确识别的情况，本文给出解决办法.\n找到marked.js文件 去掉对_渲染的部分，修改之后如下图\n<!-- more -->\n![](2017-7-3-two/1.png)","slug":"2017-7-3-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001hycvjl4aw80qg","content":"<p>hexo在编译数学公式时有时会将_渲染错误造成｛｝内多个下标无法正确识别的情况，本文给出解决办法.<br>找到marked.js文件 去掉对_渲染的部分，修改之后如下图<br><a id=\"more\"></a><br><img src=\"/2017/07/03/2017-7-3-two/1.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"<p>hexo在编译数学公式时有时会将_渲染错误造成｛｝内多个下标无法正确识别的情况，本文给出解决办法.<br>找到marked.js文件 去掉对_渲染的部分，修改之后如下图<br></p>","more":"<br><img src=\"/2017/07/03/2017-7-3-two/1.png\" alt=\"\"><p></p>"},{"title":"机器学习笔记（十二）简单线性回归原理","date":"2017-07-08T05:36:21.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 为什么需要统计量？\n统计量：描述数据特征\n1.1集中趋势衡量\n1.1.1均值（平均数，平均值）（mean）\n$\\overline x = \\sum_{i=1}^{n}x_i$\n{6, 2, 9, 1, 2}\n(6 + 2 + 9 + 1 + 2) / 5 = 20 / 5 = 4\n1.1.2中位数 （median）: 将数据中的各个数值按照大小顺序排列，居于中间位置的变量\n1.1.2.1给数据排序：1， 2， 2， 6， 9\n1.1.2.2找出位置处于中间的变量：2\n当n为基数的时候：直接取位置处于中间的变量\n当n为偶数的时候，取中间两个量的平均值\n1.1.2众数 （mode）：数据中出现次数最多的数\n<!-- more -->\n1.2\n1.2.1离散程度衡量\n1.2.1.1方差（variance)\n$s^2=\\frac{\\sum_{i=1}^n(x_i-\\overline x)^2}{n-1}$\n{6, 2, 9, 1, 2}\n(1) (6 - 4)^2 + (2 - 4) ^2 + (9 - 4)^2 + (1 - 4)^2 + (2 - 4)^2 \n   = 4 + 4 + 25 + 9 + 4\n   = 46\n(2) n - 1 = 5 - 1 = 4\n(3) 46 / 4 = 11.5\n1.2.1.2标准差 (standard deviation)\n$s=\\sqrt{s^2}$\ns = sqrt(11.5) = 3.39  \n2. 简单线性回归(Simple Linear Regression)\n2.1很多做决定过过程通常是根据两个或者多个变量之间的关系\n2.2回归分析(regression analysis)用来建立方程模拟两个或者多个变量之间如何关联\n2.3被预测的变量叫做：因变量(dependent variable), y, 输出(output)\n2.4被用来进行预测的变量叫做： 自变量(independent variable), x, 输入(input)\n3. 简单线性回归介绍\n3.1简单线性回归包含一个自变量(x)和一个因变量(y)\n3.2以上两个变量的关系用一条直线来模拟\n3.3如果包含两个以上的自变量，则称作多元回归分析(multiple regression)\n4. 简单线性回归模型\n4.1被用来描述因变量(y)和自变量(X)以及偏差(error)之间关系的方程叫做回归模型\n4.2简单线性回归的模型是:\n$y=\\beta_0+\\beta_1x+\\varepsilon$     \n5. 简单线性回归方程\nE(y) = β0+β1x \n这个方程对应的图像是一条直线，称作回归线\n其中，β0是回归线的截距\nβ1是回归线的斜率  \nE(y)是在一个给定x值下y的期望值（均值）\n6. 正向线性关系：\n![](2017-7-8-one/1.png)   \n7. 负向线性关系：\n![](2017-7-8-one/2.png)\n8. 无关系\n![](2017-7-8-one/3.png)\n9. 估计的简单线性回归方程\nŷ=b0+b1x\n这个方程叫做估计线性方程(estimated regression line)\n其中，b0是估计线性方程的纵截距\nb1是估计线性方程的斜率\nŷ是在自变量x等于一个给定值的时候，y的估计值\n10. 线性回归分析流程：\n![](2017-7-8-one/4.png)    \n11. 关于偏差ε的假定\n11.1是一个随机的变量，均值为0\n11.2ε的方差(variance)对于所有的自变量x是一样的\n11.3ε的值是独立的\n11.4ε满足正态分布\n                    ","source":"_posts/2017-7-8-one.md","raw":"---\ntitle: 机器学习笔记（十二）简单线性回归原理\ndate: 2017-07-08 13:36:21\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 为什么需要统计量？\n统计量：描述数据特征\n1.1集中趋势衡量\n1.1.1均值（平均数，平均值）（mean）\n$\\overline x = \\sum_{i=1}^{n}x_i$\n{6, 2, 9, 1, 2}\n(6 + 2 + 9 + 1 + 2) / 5 = 20 / 5 = 4\n1.1.2中位数 （median）: 将数据中的各个数值按照大小顺序排列，居于中间位置的变量\n1.1.2.1给数据排序：1， 2， 2， 6， 9\n1.1.2.2找出位置处于中间的变量：2\n当n为基数的时候：直接取位置处于中间的变量\n当n为偶数的时候，取中间两个量的平均值\n1.1.2众数 （mode）：数据中出现次数最多的数\n<!-- more -->\n1.2\n1.2.1离散程度衡量\n1.2.1.1方差（variance)\n$s^2=\\frac{\\sum_{i=1}^n(x_i-\\overline x)^2}{n-1}$\n{6, 2, 9, 1, 2}\n(1) (6 - 4)^2 + (2 - 4) ^2 + (9 - 4)^2 + (1 - 4)^2 + (2 - 4)^2 \n   = 4 + 4 + 25 + 9 + 4\n   = 46\n(2) n - 1 = 5 - 1 = 4\n(3) 46 / 4 = 11.5\n1.2.1.2标准差 (standard deviation)\n$s=\\sqrt{s^2}$\ns = sqrt(11.5) = 3.39  \n2. 简单线性回归(Simple Linear Regression)\n2.1很多做决定过过程通常是根据两个或者多个变量之间的关系\n2.2回归分析(regression analysis)用来建立方程模拟两个或者多个变量之间如何关联\n2.3被预测的变量叫做：因变量(dependent variable), y, 输出(output)\n2.4被用来进行预测的变量叫做： 自变量(independent variable), x, 输入(input)\n3. 简单线性回归介绍\n3.1简单线性回归包含一个自变量(x)和一个因变量(y)\n3.2以上两个变量的关系用一条直线来模拟\n3.3如果包含两个以上的自变量，则称作多元回归分析(multiple regression)\n4. 简单线性回归模型\n4.1被用来描述因变量(y)和自变量(X)以及偏差(error)之间关系的方程叫做回归模型\n4.2简单线性回归的模型是:\n$y=\\beta_0+\\beta_1x+\\varepsilon$     \n5. 简单线性回归方程\nE(y) = β0+β1x \n这个方程对应的图像是一条直线，称作回归线\n其中，β0是回归线的截距\nβ1是回归线的斜率  \nE(y)是在一个给定x值下y的期望值（均值）\n6. 正向线性关系：\n![](2017-7-8-one/1.png)   \n7. 负向线性关系：\n![](2017-7-8-one/2.png)\n8. 无关系\n![](2017-7-8-one/3.png)\n9. 估计的简单线性回归方程\nŷ=b0+b1x\n这个方程叫做估计线性方程(estimated regression line)\n其中，b0是估计线性方程的纵截距\nb1是估计线性方程的斜率\nŷ是在自变量x等于一个给定值的时候，y的估计值\n10. 线性回归分析流程：\n![](2017-7-8-one/4.png)    \n11. 关于偏差ε的假定\n11.1是一个随机的变量，均值为0\n11.2ε的方差(variance)对于所有的自变量x是一样的\n11.3ε的值是独立的\n11.4ε满足正态分布\n                    ","slug":"2017-7-8-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001jycvjv5pa7k6k","content":"<ol>\n<li>为什么需要统计量？<br>统计量：描述数据特征<br>1.1集中趋势衡量<br>1.1.1均值（平均数，平均值）（mean）<br>$\\overline x = \\sum_{i=1}^{n}x_i$<br>{6, 2, 9, 1, 2}<br>(6 + 2 + 9 + 1 + 2) / 5 = 20 / 5 = 4<br>1.1.2中位数 （median）: 将数据中的各个数值按照大小顺序排列，居于中间位置的变量<br>1.1.2.1给数据排序：1， 2， 2， 6， 9<br>1.1.2.2找出位置处于中间的变量：2<br>当n为基数的时候：直接取位置处于中间的变量<br>当n为偶数的时候，取中间两个量的平均值<br>1.1.2众数 （mode）：数据中出现次数最多的数<a id=\"more\"></a>\n1.2<br>1.2.1离散程度衡量<br>1.2.1.1方差（variance)<br>$s^2=\\frac{\\sum_{i=1}^n(x_i-\\overline x)^2}{n-1}$<br>{6, 2, 9, 1, 2}<br>(1) (6 - 4)^2 + (2 - 4) ^2 + (9 - 4)^2 + (1 - 4)^2 + (2 - 4)^2<br>= 4 + 4 + 25 + 9 + 4<br>= 46<br>(2) n - 1 = 5 - 1 = 4<br>(3) 46 / 4 = 11.5<br>1.2.1.2标准差 (standard deviation)<br>$s=\\sqrt{s^2}$<br>s = sqrt(11.5) = 3.39  </li>\n<li>简单线性回归(Simple Linear Regression)<br>2.1很多做决定过过程通常是根据两个或者多个变量之间的关系<br>2.2回归分析(regression analysis)用来建立方程模拟两个或者多个变量之间如何关联<br>2.3被预测的变量叫做：因变量(dependent variable), y, 输出(output)<br>2.4被用来进行预测的变量叫做： 自变量(independent variable), x, 输入(input)</li>\n<li>简单线性回归介绍<br>3.1简单线性回归包含一个自变量(x)和一个因变量(y)<br>3.2以上两个变量的关系用一条直线来模拟<br>3.3如果包含两个以上的自变量，则称作多元回归分析(multiple regression)</li>\n<li>简单线性回归模型<br>4.1被用来描述因变量(y)和自变量(X)以及偏差(error)之间关系的方程叫做回归模型<br>4.2简单线性回归的模型是:<br>$y=\\beta_0+\\beta_1x+\\varepsilon$     </li>\n<li>简单线性回归方程<br>E(y) = β0+β1x<br>这个方程对应的图像是一条直线，称作回归线<br>其中，β0是回归线的截距<br>β1是回归线的斜率<br>E(y)是在一个给定x值下y的期望值（均值）</li>\n<li>正向线性关系：<br><img src=\"/2017/07/08/2017-7-8-one/1.png\" alt=\"\">   </li>\n<li>负向线性关系：<br><img src=\"/2017/07/08/2017-7-8-one/2.png\" alt=\"\"></li>\n<li>无关系<br><img src=\"/2017/07/08/2017-7-8-one/3.png\" alt=\"\"></li>\n<li>估计的简单线性回归方程<br>ŷ=b0+b1x<br>这个方程叫做估计线性方程(estimated regression line)<br>其中，b0是估计线性方程的纵截距<br>b1是估计线性方程的斜率<br>ŷ是在自变量x等于一个给定值的时候，y的估计值</li>\n<li>线性回归分析流程：<br><img src=\"/2017/07/08/2017-7-8-one/4.png\" alt=\"\">    </li>\n<li>关于偏差ε的假定<br>11.1是一个随机的变量，均值为0<br>11.2ε的方差(variance)对于所有的自变量x是一样的<br>11.3ε的值是独立的<br>11.4ε满足正态分布</li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>为什么需要统计量？<br>统计量：描述数据特征<br>1.1集中趋势衡量<br>1.1.1均值（平均数，平均值）（mean）<br>$\\overline x = \\sum_{i=1}^{n}x_i$<br>{6, 2, 9, 1, 2}<br>(6 + 2 + 9 + 1 + 2) / 5 = 20 / 5 = 4<br>1.1.2中位数 （median）: 将数据中的各个数值按照大小顺序排列，居于中间位置的变量<br>1.1.2.1给数据排序：1， 2， 2， 6， 9<br>1.1.2.2找出位置处于中间的变量：2<br>当n为基数的时候：直接取位置处于中间的变量<br>当n为偶数的时候，取中间两个量的平均值<br>1.1.2众数 （mode）：数据中出现次数最多的数</li></ol>","more":"1.2<br>1.2.1离散程度衡量<br>1.2.1.1方差（variance)<br>$s^2=\\frac{\\sum_{i=1}^n(x_i-\\overline x)^2}{n-1}$<br>{6, 2, 9, 1, 2}<br>(1) (6 - 4)^2 + (2 - 4) ^2 + (9 - 4)^2 + (1 - 4)^2 + (2 - 4)^2<br>= 4 + 4 + 25 + 9 + 4<br>= 46<br>(2) n - 1 = 5 - 1 = 4<br>(3) 46 / 4 = 11.5<br>1.2.1.2标准差 (standard deviation)<br>$s=\\sqrt{s^2}$<br>s = sqrt(11.5) = 3.39  \n<li>简单线性回归(Simple Linear Regression)<br>2.1很多做决定过过程通常是根据两个或者多个变量之间的关系<br>2.2回归分析(regression analysis)用来建立方程模拟两个或者多个变量之间如何关联<br>2.3被预测的变量叫做：因变量(dependent variable), y, 输出(output)<br>2.4被用来进行预测的变量叫做： 自变量(independent variable), x, 输入(input)</li>\n<li>简单线性回归介绍<br>3.1简单线性回归包含一个自变量(x)和一个因变量(y)<br>3.2以上两个变量的关系用一条直线来模拟<br>3.3如果包含两个以上的自变量，则称作多元回归分析(multiple regression)</li>\n<li>简单线性回归模型<br>4.1被用来描述因变量(y)和自变量(X)以及偏差(error)之间关系的方程叫做回归模型<br>4.2简单线性回归的模型是:<br>$y=\\beta_0+\\beta_1x+\\varepsilon$     </li>\n<li>简单线性回归方程<br>E(y) = β0+β1x<br>这个方程对应的图像是一条直线，称作回归线<br>其中，β0是回归线的截距<br>β1是回归线的斜率<br>E(y)是在一个给定x值下y的期望值（均值）</li>\n<li>正向线性关系：<br><img src=\"/2017/07/08/2017-7-8-one/1.png\" alt=\"\">   </li>\n<li>负向线性关系：<br><img src=\"/2017/07/08/2017-7-8-one/2.png\" alt=\"\"></li>\n<li>无关系<br><img src=\"/2017/07/08/2017-7-8-one/3.png\" alt=\"\"></li>\n<li>估计的简单线性回归方程<br>ŷ=b0+b1x<br>这个方程叫做估计线性方程(estimated regression line)<br>其中，b0是估计线性方程的纵截距<br>b1是估计线性方程的斜率<br>ŷ是在自变量x等于一个给定值的时候，y的估计值</li>\n<li>线性回归分析流程：<br><img src=\"/2017/07/08/2017-7-8-one/4.png\" alt=\"\">    </li>\n<li>关于偏差ε的假定<br>11.1是一个随机的变量，均值为0<br>11.2ε的方差(variance)对于所有的自变量x是一样的<br>11.3ε的值是独立的<br>11.4ε满足正态分布</li>\n"},{"title":"机器学习笔记（十三）简单线性回归应用","date":"2017-07-08T08:35:16.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 简单线性回归模型举例：\n汽车卖家做电视广告数量与卖出的汽车数量：\n![](2017-7-8-two/1.png) \n1.1 如何练处适合简单线性回归模型的最佳回归线？\n<!-- more -->  \n![](2017-7-8-two/2.png)  \nmin$\\sum(y_i-\\hat y_i)^2$\n使sum of squares最小\n1.1.2 计算\n![](2017-7-8-two/1.png)  \n$b_1=\\frac{\\sum(x_i-\\overline x)(y_i-\\overline y)}{\\sum(x_i-\\overline x)^2}$\n$b_0=\\overline y-b_1\\overline x$\n分子 = (1-2)(14-20)+(3-2)(24-20)+(2-2)(18-20)+(1-2)(17-20)+(3-2)(27-20)\n= 6 + 4 + 0 + 3 + 7\n= 20\n分母 = （1-2）^2 + (3-2)^2 + (2-2)^2 + (1-2)^2 + (3-2)^2\n= 1 + 1 + 0 + 1 + 1\n= 4\nb1 = 20/4  =5\nb0 = 20 - 5$\\times$2 = 20 - 10 = 10\n1.2 预测：\n假设有一周广告数量为6，预测的汽车销售量是多少？\n![](2017-7-8-two/2.png)  \nx_given = 6\nY_hat = 5$\\times$6 + 10 = 40\n1.3 Python实现：\n``` bash\nimport numpy as np\ndef fitSLR(x, y):\n    n = len(x)\n    dinominator = 0\n    numerator = 0\n    for i in range(0, n):\n        numerator += (x[i] - np.mean(x))*(y[i] - np.mean(y))\n        dinominator += (x[i] - np.mean(x))**2\n    b1 = numerator/float(dinominator)\n    b0 = np.mean(y)-b1*float(np.mean(x))\n    return b0, b1\ndef predict(x, b0, b1):\n    return b0 + x*b1\nx = [1, 3, 2, 1, 3]\ny = [14, 24, 18, 17, 27]    \nb0, b1 = fitSLR(x, y)\nprint \"intercept:\", b0, \" slope:\", b1\nx_test = 6\ny_test = predict(6, b0, b1)\nprint \"y_test:\", y_test\n```","source":"_posts/2017-7-8-two.md","raw":"---\ntitle: 机器学习笔记（十三）简单线性回归应用\ndate: 2017-07-08 16:35:16\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 简单线性回归模型举例：\n汽车卖家做电视广告数量与卖出的汽车数量：\n![](2017-7-8-two/1.png) \n1.1 如何练处适合简单线性回归模型的最佳回归线？\n<!-- more -->  \n![](2017-7-8-two/2.png)  \nmin$\\sum(y_i-\\hat y_i)^2$\n使sum of squares最小\n1.1.2 计算\n![](2017-7-8-two/1.png)  \n$b_1=\\frac{\\sum(x_i-\\overline x)(y_i-\\overline y)}{\\sum(x_i-\\overline x)^2}$\n$b_0=\\overline y-b_1\\overline x$\n分子 = (1-2)(14-20)+(3-2)(24-20)+(2-2)(18-20)+(1-2)(17-20)+(3-2)(27-20)\n= 6 + 4 + 0 + 3 + 7\n= 20\n分母 = （1-2）^2 + (3-2)^2 + (2-2)^2 + (1-2)^2 + (3-2)^2\n= 1 + 1 + 0 + 1 + 1\n= 4\nb1 = 20/4  =5\nb0 = 20 - 5$\\times$2 = 20 - 10 = 10\n1.2 预测：\n假设有一周广告数量为6，预测的汽车销售量是多少？\n![](2017-7-8-two/2.png)  \nx_given = 6\nY_hat = 5$\\times$6 + 10 = 40\n1.3 Python实现：\n``` bash\nimport numpy as np\ndef fitSLR(x, y):\n    n = len(x)\n    dinominator = 0\n    numerator = 0\n    for i in range(0, n):\n        numerator += (x[i] - np.mean(x))*(y[i] - np.mean(y))\n        dinominator += (x[i] - np.mean(x))**2\n    b1 = numerator/float(dinominator)\n    b0 = np.mean(y)-b1*float(np.mean(x))\n    return b0, b1\ndef predict(x, b0, b1):\n    return b0 + x*b1\nx = [1, 3, 2, 1, 3]\ny = [14, 24, 18, 17, 27]    \nb0, b1 = fitSLR(x, y)\nprint \"intercept:\", b0, \" slope:\", b1\nx_test = 6\ny_test = predict(6, b0, b1)\nprint \"y_test:\", y_test\n```","slug":"2017-7-8-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001lycvj67fl57va","content":"<ol>\n<li>简单线性回归模型举例：<br>汽车卖家做电视广告数量与卖出的汽车数量：<br><img src=\"/2017/07/08/2017-7-8-two/1.png\" alt=\"\"><br>1.1 如何练处适合简单线性回归模型的最佳回归线？<a id=\"more\"></a>  \n<img src=\"/2017/07/08/2017-7-8-two/2.png\" alt=\"\"><br>min$\\sum(y_i-\\hat y_i)^2$<br>使sum of squares最小<br>1.1.2 计算<br><img src=\"/2017/07/08/2017-7-8-two/1.png\" alt=\"\"><br>$b_1=\\frac{\\sum(x_i-\\overline x)(y_i-\\overline y)}{\\sum(x_i-\\overline x)^2}$<br>$b_0=\\overline y-b_1\\overline x$<br>分子 = (1-2)(14-20)+(3-2)(24-20)+(2-2)(18-20)+(1-2)(17-20)+(3-2)(27-20)<br>= 6 + 4 + 0 + 3 + 7<br>= 20<br>分母 = （1-2）^2 + (3-2)^2 + (2-2)^2 + (1-2)^2 + (3-2)^2<br>= 1 + 1 + 0 + 1 + 1<br>= 4<br>b1 = 20/4  =5<br>b0 = 20 - 5$\\times$2 = 20 - 10 = 10<br>1.2 预测：<br>假设有一周广告数量为6，预测的汽车销售量是多少？<br><img src=\"/2017/07/08/2017-7-8-two/2.png\" alt=\"\"><br>x_given = 6<br>Y_hat = 5$\\times$6 + 10 = 40<br>1.3 Python实现：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">def fitSLR(x, y):</span><br><span class=\"line\">    n = len(x)</span><br><span class=\"line\">    dinominator = 0</span><br><span class=\"line\">    numerator = 0</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0, n):</span><br><span class=\"line\">        numerator += (x[i] - np.mean(x))*(y[i] - np.mean(y))</span><br><span class=\"line\">        dinominator += (x[i] - np.mean(x))**2</span><br><span class=\"line\">    b1 = numerator/<span class=\"built_in\">float</span>(dinominator)</span><br><span class=\"line\">    b0 = np.mean(y)-b1*<span class=\"built_in\">float</span>(np.mean(x))</span><br><span class=\"line\">    <span class=\"built_in\">return</span> b0, b1</span><br><span class=\"line\">def predict(x, b0, b1):</span><br><span class=\"line\">    <span class=\"built_in\">return</span> b0 + x*b1</span><br><span class=\"line\">x = [1, 3, 2, 1, 3]</span><br><span class=\"line\">y = [14, 24, 18, 17, 27]    </span><br><span class=\"line\">b0, b1 = fitSLR(x, y)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"intercept:\"</span>, b0, <span class=\"string\">\" slope:\"</span>, b1</span><br><span class=\"line\">x_test = 6</span><br><span class=\"line\">y_test = predict(6, b0, b1)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"y_test:\"</span>, y_test</span><br></pre></td></tr></table></figure></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>简单线性回归模型举例：<br>汽车卖家做电视广告数量与卖出的汽车数量：<br><img src=\"/2017/07/08/2017-7-8-two/1.png\" alt=\"\"><br>1.1 如何练处适合简单线性回归模型的最佳回归线？</li></ol>","more":"<img src=\"/2017/07/08/2017-7-8-two/2.png\" alt=\"\"><br>min$\\sum(y_i-\\hat y_i)^2$<br>使sum of squares最小<br>1.1.2 计算<br><img src=\"/2017/07/08/2017-7-8-two/1.png\" alt=\"\"><br>$b_1=\\frac{\\sum(x_i-\\overline x)(y_i-\\overline y)}{\\sum(x_i-\\overline x)^2}$<br>$b_0=\\overline y-b_1\\overline x$<br>分子 = (1-2)(14-20)+(3-2)(24-20)+(2-2)(18-20)+(1-2)(17-20)+(3-2)(27-20)<br>= 6 + 4 + 0 + 3 + 7<br>= 20<br>分母 = （1-2）^2 + (3-2)^2 + (2-2)^2 + (1-2)^2 + (3-2)^2<br>= 1 + 1 + 0 + 1 + 1<br>= 4<br>b1 = 20/4  =5<br>b0 = 20 - 5$\\times$2 = 20 - 10 = 10<br>1.2 预测：<br>假设有一周广告数量为6，预测的汽车销售量是多少？<br><img src=\"/2017/07/08/2017-7-8-two/2.png\" alt=\"\"><br>x_given = 6<br>Y_hat = 5$\\times$6 + 10 = 40<br>1.3 Python实现：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">def fitSLR(x, y):</span><br><span class=\"line\">    n = len(x)</span><br><span class=\"line\">    dinominator = 0</span><br><span class=\"line\">    numerator = 0</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0, n):</span><br><span class=\"line\">        numerator += (x[i] - np.mean(x))*(y[i] - np.mean(y))</span><br><span class=\"line\">        dinominator += (x[i] - np.mean(x))**2</span><br><span class=\"line\">    b1 = numerator/<span class=\"built_in\">float</span>(dinominator)</span><br><span class=\"line\">    b0 = np.mean(y)-b1*<span class=\"built_in\">float</span>(np.mean(x))</span><br><span class=\"line\">    <span class=\"built_in\">return</span> b0, b1</span><br><span class=\"line\">def predict(x, b0, b1):</span><br><span class=\"line\">    <span class=\"built_in\">return</span> b0 + x*b1</span><br><span class=\"line\">x = [1, 3, 2, 1, 3]</span><br><span class=\"line\">y = [14, 24, 18, 17, 27]    </span><br><span class=\"line\">b0, b1 = fitSLR(x, y)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"intercept:\"</span>, b0, <span class=\"string\">\" slope:\"</span>, b1</span><br><span class=\"line\">x_test = 6</span><br><span class=\"line\">y_test = predict(6, b0, b1)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"y_test:\"</span>, y_test</span><br></pre></td></tr></table></figure>\n"},{"title":"机器学习笔记（十四）多元回归分析","date":"2017-08-12T07:36:18.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 与简单线性回归区别(simple linear regression)\n多个自变量(x)\n2. 多元回归模型\ny=β0＋β１x1+β2x2+ ... +βpxp+ε\n其中：β0，β１，β2... βp是参数\nε是误差值\n3. 多元回归方程\nE(y)=β0＋β１x1+β2x2+ ... +βpxp\n4. 估计多元回归方程:\ny_hat=b0＋b１x1+b2x2+ ... +bpxp\n一个样本被用来计算β0，β１，β2... βp的点估计b0, b1, b2,..., bp\n<!-- more --> \n5. 估计流程  (与简单线性回归类似）\n![](2017-8-12-one/1.png)  \n6. 估计方法\n使sum of squares最小    \n![](2017-8-12-one/2.png) \n运算与简单线性回归类似，涉及到线性代数和矩阵代数的运算\n7. 例子\n一家快递公司送货：X1： 运输里程 X2： 运输次数   Y：总运输时间   \nDriving \nAssignment Traveled\tX1=Miles X2=Number of Deliveries Y= Travel Time (Hours)\t\n1\t100\t4\t9.3\n2\t50\t3\t4.8\n3\t100\t4\t8.9\n4\t100\t2\t6.5\n5\t50\t2\t4.2\n6\t80\t2\t6.2\n7\t75\t3\t7.4\n8\t65\t4\t6.0\n9\t90\t3\t7.6\n10\t90\t2\t6.1\nTime = b0+ b1*Miles + b2 * Deliveries \nTime = -0.869 + 0.0611 Miles + 0.923 Deliveries\n8. 描述参数含义\nb0: 平均每多运送一英里，运输时间延长0.0611 小时\nb1: 平均每多一次运输，运输时间延长 0.923 小时\n9. 预测\n如果一个运输任务是跑102英里，运输6次，预计多少小时？\nTime = -0.869 +0.0611 *102+ 0.923 * 6\n= 10.9 (小时）\n10. 如果自变量中有分类型变量(categorical data) , 如何处理？\n英里数\t次数\t车型\t时间\n100\t4\t1\t9.3\n50\t3\t0\t4.8\n100\t4\t1\t8.9\n100\t2\t2\t6.5\n50\t2\t2\t4.2\n80\t2\t1\t6.2\n75\t3\t1\t7.4\n65\t4\t0\t6\n90\t3\t0\t7.6\n11. 关于误差的分布\n误差ε是一个随机变量，均值为0\nε的方差对于所有的自变量来说相等\n所有ε的值是独立的\nε满足正态分布，并且通过β0＋β１x1+β2x2+ ... +βpxp反映y的期望值","source":"_posts/2017-8-12-one.md","raw":"---\ntitle: 机器学习笔记（十四）多元回归分析\ndate: 2017-08-12 15:36:18\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 与简单线性回归区别(simple linear regression)\n多个自变量(x)\n2. 多元回归模型\ny=β0＋β１x1+β2x2+ ... +βpxp+ε\n其中：β0，β１，β2... βp是参数\nε是误差值\n3. 多元回归方程\nE(y)=β0＋β１x1+β2x2+ ... +βpxp\n4. 估计多元回归方程:\ny_hat=b0＋b１x1+b2x2+ ... +bpxp\n一个样本被用来计算β0，β１，β2... βp的点估计b0, b1, b2,..., bp\n<!-- more --> \n5. 估计流程  (与简单线性回归类似）\n![](2017-8-12-one/1.png)  \n6. 估计方法\n使sum of squares最小    \n![](2017-8-12-one/2.png) \n运算与简单线性回归类似，涉及到线性代数和矩阵代数的运算\n7. 例子\n一家快递公司送货：X1： 运输里程 X2： 运输次数   Y：总运输时间   \nDriving \nAssignment Traveled\tX1=Miles X2=Number of Deliveries Y= Travel Time (Hours)\t\n1\t100\t4\t9.3\n2\t50\t3\t4.8\n3\t100\t4\t8.9\n4\t100\t2\t6.5\n5\t50\t2\t4.2\n6\t80\t2\t6.2\n7\t75\t3\t7.4\n8\t65\t4\t6.0\n9\t90\t3\t7.6\n10\t90\t2\t6.1\nTime = b0+ b1*Miles + b2 * Deliveries \nTime = -0.869 + 0.0611 Miles + 0.923 Deliveries\n8. 描述参数含义\nb0: 平均每多运送一英里，运输时间延长0.0611 小时\nb1: 平均每多一次运输，运输时间延长 0.923 小时\n9. 预测\n如果一个运输任务是跑102英里，运输6次，预计多少小时？\nTime = -0.869 +0.0611 *102+ 0.923 * 6\n= 10.9 (小时）\n10. 如果自变量中有分类型变量(categorical data) , 如何处理？\n英里数\t次数\t车型\t时间\n100\t4\t1\t9.3\n50\t3\t0\t4.8\n100\t4\t1\t8.9\n100\t2\t2\t6.5\n50\t2\t2\t4.2\n80\t2\t1\t6.2\n75\t3\t1\t7.4\n65\t4\t0\t6\n90\t3\t0\t7.6\n11. 关于误差的分布\n误差ε是一个随机变量，均值为0\nε的方差对于所有的自变量来说相等\n所有ε的值是独立的\nε满足正态分布，并且通过β0＋β１x1+β2x2+ ... +βpxp反映y的期望值","slug":"2017-8-12-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001nycvj7wy7wt65","content":"<ol>\n<li>与简单线性回归区别(simple linear regression)<br>多个自变量(x)</li>\n<li>多元回归模型<br>y=β0＋β１x1+β2x2+ … +βpxp+ε<br>其中：β0，β１，β2… βp是参数<br>ε是误差值</li>\n<li>多元回归方程<br>E(y)=β0＋β１x1+β2x2+ … +βpxp</li>\n<li>估计多元回归方程:<br>y_hat=b0＋b１x1+b2x2+ … +bpxp<br>一个样本被用来计算β0，β１，β2… βp的点估计b0, b1, b2,…, bp<a id=\"more\"></a> </li>\n<li>估计流程  (与简单线性回归类似）<br><img src=\"/2017/08/12/2017-8-12-one/1.png\" alt=\"\">  </li>\n<li>估计方法<br>使sum of squares最小<br><img src=\"/2017/08/12/2017-8-12-one/2.png\" alt=\"\"><br>运算与简单线性回归类似，涉及到线性代数和矩阵代数的运算</li>\n<li>例子<br>一家快递公司送货：X1： 运输里程 X2： 运输次数   Y：总运输时间<br>Driving<br>Assignment Traveled    X1=Miles X2=Number of Deliveries Y= Travel Time (Hours)<br>1    100    4    9.3<br>2    50    3    4.8<br>3    100    4    8.9<br>4    100    2    6.5<br>5    50    2    4.2<br>6    80    2    6.2<br>7    75    3    7.4<br>8    65    4    6.0<br>9    90    3    7.6<br>10    90    2    6.1<br>Time = b0+ b1<em>Miles + b2 </em> Deliveries<br>Time = -0.869 + 0.0611 Miles + 0.923 Deliveries</li>\n<li>描述参数含义<br>b0: 平均每多运送一英里，运输时间延长0.0611 小时<br>b1: 平均每多一次运输，运输时间延长 0.923 小时</li>\n<li>预测<br>如果一个运输任务是跑102英里，运输6次，预计多少小时？<br>Time = -0.869 +0.0611 <em>102+ 0.923 </em> 6<br>= 10.9 (小时）</li>\n<li>如果自变量中有分类型变量(categorical data) , 如何处理？<br>英里数    次数    车型    时间<br>100    4    1    9.3<br>50    3    0    4.8<br>100    4    1    8.9<br>100    2    2    6.5<br>50    2    2    4.2<br>80    2    1    6.2<br>75    3    1    7.4<br>65    4    0    6<br>90    3    0    7.6</li>\n<li>关于误差的分布<br>误差ε是一个随机变量，均值为0<br>ε的方差对于所有的自变量来说相等<br>所有ε的值是独立的<br>ε满足正态分布，并且通过β0＋β１x1+β2x2+ … +βpxp反映y的期望值</li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>与简单线性回归区别(simple linear regression)<br>多个自变量(x)</li>\n<li>多元回归模型<br>y=β0＋β１x1+β2x2+ … +βpxp+ε<br>其中：β0，β１，β2… βp是参数<br>ε是误差值</li>\n<li>多元回归方程<br>E(y)=β0＋β１x1+β2x2+ … +βpxp</li>\n<li>估计多元回归方程:<br>y_hat=b0＋b１x1+b2x2+ … +bpxp<br>一个样本被用来计算β0，β１，β2… βp的点估计b0, b1, b2,…, bp</li></ol>","more":"\n<li>估计流程  (与简单线性回归类似）<br><img src=\"/2017/08/12/2017-8-12-one/1.png\" alt=\"\">  </li>\n<li>估计方法<br>使sum of squares最小<br><img src=\"/2017/08/12/2017-8-12-one/2.png\" alt=\"\"><br>运算与简单线性回归类似，涉及到线性代数和矩阵代数的运算</li>\n<li>例子<br>一家快递公司送货：X1： 运输里程 X2： 运输次数   Y：总运输时间<br>Driving<br>Assignment Traveled    X1=Miles X2=Number of Deliveries Y= Travel Time (Hours)<br>1    100    4    9.3<br>2    50    3    4.8<br>3    100    4    8.9<br>4    100    2    6.5<br>5    50    2    4.2<br>6    80    2    6.2<br>7    75    3    7.4<br>8    65    4    6.0<br>9    90    3    7.6<br>10    90    2    6.1<br>Time = b0+ b1<em>Miles + b2 </em> Deliveries<br>Time = -0.869 + 0.0611 Miles + 0.923 Deliveries</li>\n<li>描述参数含义<br>b0: 平均每多运送一英里，运输时间延长0.0611 小时<br>b1: 平均每多一次运输，运输时间延长 0.923 小时</li>\n<li>预测<br>如果一个运输任务是跑102英里，运输6次，预计多少小时？<br>Time = -0.869 +0.0611 <em>102+ 0.923 </em> 6<br>= 10.9 (小时）</li>\n<li>如果自变量中有分类型变量(categorical data) , 如何处理？<br>英里数    次数    车型    时间<br>100    4    1    9.3<br>50    3    0    4.8<br>100    4    1    8.9<br>100    2    2    6.5<br>50    2    2    4.2<br>80    2    1    6.2<br>75    3    1    7.4<br>65    4    0    6<br>90    3    0    7.6</li>\n<li>关于误差的分布<br>误差ε是一个随机变量，均值为0<br>ε的方差对于所有的自变量来说相等<br>所有ε的值是独立的<br>ε满足正态分布，并且通过β0＋β１x1+β2x2+ … +βpxp反映y的期望值</li>\n"},{"title":"多电脑间github同步hexo博文","date":"2017-08-31T03:26:00.000Z","comments":1,"reward":true,"mathjax":true,"_content":"远程仓库及分支建立方法参照博文：https://righere.github.io/2016/10/10/install-hexo/\n完成远程仓库建立\n这样在另一台没有任何博文资料的电脑上可以同步github数据，先建立SSH连接，确保github账户关联，然后参照一下代码\n``` bash\ngit pull origin hexo  //先pull完成本地与远端的融合\nhexo new post \" new blog name\"\ngit add .//.的话就只增加更新的文章 \ngit commit -m \"XX\"//此处为github说明\ngit push origin hexo\nhexo d -g //编译发布\n```","source":"_posts/2017-8-31-one.md","raw":"---\ntitle: 多电脑间github同步hexo博文\ndate: 2017-08-31 11:26:00\ncomments: true\nreward: true\nmathjax: true\ntags: \n - hexo\n---\n远程仓库及分支建立方法参照博文：https://righere.github.io/2016/10/10/install-hexo/\n完成远程仓库建立\n这样在另一台没有任何博文资料的电脑上可以同步github数据，先建立SSH连接，确保github账户关联，然后参照一下代码\n``` bash\ngit pull origin hexo  //先pull完成本地与远端的融合\nhexo new post \" new blog name\"\ngit add .//.的话就只增加更新的文章 \ngit commit -m \"XX\"//此处为github说明\ngit push origin hexo\nhexo d -g //编译发布\n```","slug":"2017-8-31-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001pycvjkionkmz9","content":"<p>远程仓库及分支建立方法参照博文：<a href=\"https://righere.github.io/2016/10/10/install-hexo/\" target=\"_blank\" rel=\"noopener\">https://righere.github.io/2016/10/10/install-hexo/</a><br>完成远程仓库建立<br>这样在另一台没有任何博文资料的电脑上可以同步github数据，先建立SSH连接，确保github账户关联，然后参照一下代码<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git pull origin hexo  //先pull完成本地与远端的融合</span><br><span class=\"line\">hexo new post <span class=\"string\">\" new blog name\"</span></span><br><span class=\"line\">git add .//.的话就只增加更新的文章 </span><br><span class=\"line\">git commit -m <span class=\"string\">\"XX\"</span>//此处为github说明</span><br><span class=\"line\">git push origin hexo</span><br><span class=\"line\">hexo d -g //编译发布</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<p>远程仓库及分支建立方法参照博文：<a href=\"https://righere.github.io/2016/10/10/install-hexo/\" target=\"_blank\" rel=\"noopener\">https://righere.github.io/2016/10/10/install-hexo/</a><br>完成远程仓库建立<br>这样在另一台没有任何博文资料的电脑上可以同步github数据，先建立SSH连接，确保github账户关联，然后参照一下代码<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git pull origin hexo  //先pull完成本地与远端的融合</span><br><span class=\"line\">hexo new post <span class=\"string\">\" new blog name\"</span></span><br><span class=\"line\">git add .//.的话就只增加更新的文章 </span><br><span class=\"line\">git commit -m <span class=\"string\">\"XX\"</span>//此处为github说明</span><br><span class=\"line\">git push origin hexo</span><br><span class=\"line\">hexo d -g //编译发布</span><br></pre></td></tr></table></figure></p>\n"},{"title":"机器学习笔记（十五）多元回归分析应用","date":"2017-08-12T07:57:38.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 例子\n一家快递公司送货：X1： 运输里程 X2： 运输次数   Y：总运输时间   \n<!-- more --> \nDriving Assignment X1=Miles Traveled X2=Number of Deliveries Y= Travel Time (Hours)\n1\t100\t4\t9.3\n2\t50\t3\t4.8\n3\t100\t4\t8.9\n4\t100\t2\t6.5\n5\t50\t2\t4.2\n6\t80\t2\t6.2\n7\t75\t3\t7.4\n8\t65\t4\t6.0\n9\t90\t3\t7.6\n10\t90\t2\t6.1\n目的，求出b0, b1,.... bp：\ny_hat=b0＋b１x1+b2x2+ ... +bpxp\n2. Python代码：\n``` bash\nfrom numpy import genfromtxt\nfrom sklearn import linear_model\ndataPath = r\"Delivery.csv\"\ndeliveryData = genfromtxt(dataPath,delimiter=',')\nprint \"data\"\nprint deliveryData\nx= deliveryData[:,:-1]\ny = deliveryData[:,-1]\nprint x\nprint y\nlr = linear_model.LinearRegression()\nlr.fit(x, y)\nprint lr\nprint(\"coefficients:\")\nprint lr.coef_\nprint(\"intercept:\")\nprint lr.intercept_\nxPredict = [102,6] \nyPredict = lr.predict(xPredict)\nprint(\"predict:\")\nprint yPredict\n# 如果需要多个车型分开则增加N维二进制数组输入 然后预测 如：xPredict =  [90,2,0,0,1]\n```","source":"_posts/2017-8-12-two.md","raw":"---\ntitle: 机器学习笔记（十五）多元回归分析应用\ndate: 2017-08-12 15:57:38\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 例子\n一家快递公司送货：X1： 运输里程 X2： 运输次数   Y：总运输时间   \n<!-- more --> \nDriving Assignment X1=Miles Traveled X2=Number of Deliveries Y= Travel Time (Hours)\n1\t100\t4\t9.3\n2\t50\t3\t4.8\n3\t100\t4\t8.9\n4\t100\t2\t6.5\n5\t50\t2\t4.2\n6\t80\t2\t6.2\n7\t75\t3\t7.4\n8\t65\t4\t6.0\n9\t90\t3\t7.6\n10\t90\t2\t6.1\n目的，求出b0, b1,.... bp：\ny_hat=b0＋b１x1+b2x2+ ... +bpxp\n2. Python代码：\n``` bash\nfrom numpy import genfromtxt\nfrom sklearn import linear_model\ndataPath = r\"Delivery.csv\"\ndeliveryData = genfromtxt(dataPath,delimiter=',')\nprint \"data\"\nprint deliveryData\nx= deliveryData[:,:-1]\ny = deliveryData[:,-1]\nprint x\nprint y\nlr = linear_model.LinearRegression()\nlr.fit(x, y)\nprint lr\nprint(\"coefficients:\")\nprint lr.coef_\nprint(\"intercept:\")\nprint lr.intercept_\nxPredict = [102,6] \nyPredict = lr.predict(xPredict)\nprint(\"predict:\")\nprint yPredict\n# 如果需要多个车型分开则增加N维二进制数组输入 然后预测 如：xPredict =  [90,2,0,0,1]\n```","slug":"2017-8-12-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001rycvjgxpug8j1","content":"<ol>\n<li>例子<br>一家快递公司送货：X1： 运输里程 X2： 运输次数   Y：总运输时间   <a id=\"more\"></a> \nDriving Assignment X1=Miles Traveled X2=Number of Deliveries Y= Travel Time (Hours)<br>1    100    4    9.3<br>2    50    3    4.8<br>3    100    4    8.9<br>4    100    2    6.5<br>5    50    2    4.2<br>6    80    2    6.2<br>7    75    3    7.4<br>8    65    4    6.0<br>9    90    3    7.6<br>10    90    2    6.1<br>目的，求出b0, b1,…. bp：<br>y_hat=b0＋b１x1+b2x2+ … +bpxp</li>\n<li>Python代码：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from numpy import genfromtxt</span><br><span class=\"line\">from sklearn import linear_model</span><br><span class=\"line\">dataPath = r<span class=\"string\">\"Delivery.csv\"</span></span><br><span class=\"line\">deliveryData = genfromtxt(dataPath,delimiter=<span class=\"string\">','</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"data\"</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> deliveryData</span><br><span class=\"line\">x= deliveryData[:,:-1]</span><br><span class=\"line\">y = deliveryData[:,-1]</span><br><span class=\"line\"><span class=\"built_in\">print</span> x</span><br><span class=\"line\"><span class=\"built_in\">print</span> y</span><br><span class=\"line\">lr = linear_model.LinearRegression()</span><br><span class=\"line\">lr.fit(x, y)</span><br><span class=\"line\"><span class=\"built_in\">print</span> lr</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"coefficients:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> lr.coef_</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"intercept:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> lr.intercept_</span><br><span class=\"line\">xPredict = [102,6] </span><br><span class=\"line\">yPredict = lr.predict(xPredict)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"predict:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> yPredict</span><br><span class=\"line\"><span class=\"comment\"># 如果需要多个车型分开则增加N维二进制数组输入 然后预测 如：xPredict =  [90,2,0,0,1]</span></span><br></pre></td></tr></table></figure></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>例子<br>一家快递公司送货：X1： 运输里程 X2： 运输次数   Y：总运输时间</li></ol>","more":"Driving Assignment X1=Miles Traveled X2=Number of Deliveries Y= Travel Time (Hours)<br>1    100    4    9.3<br>2    50    3    4.8<br>3    100    4    8.9<br>4    100    2    6.5<br>5    50    2    4.2<br>6    80    2    6.2<br>7    75    3    7.4<br>8    65    4    6.0<br>9    90    3    7.6<br>10    90    2    6.1<br>目的，求出b0, b1,…. bp：<br>y_hat=b0＋b１x1+b2x2+ … +bpxp\n<li>Python代码：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from numpy import genfromtxt</span><br><span class=\"line\">from sklearn import linear_model</span><br><span class=\"line\">dataPath = r<span class=\"string\">\"Delivery.csv\"</span></span><br><span class=\"line\">deliveryData = genfromtxt(dataPath,delimiter=<span class=\"string\">','</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"data\"</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> deliveryData</span><br><span class=\"line\">x= deliveryData[:,:-1]</span><br><span class=\"line\">y = deliveryData[:,-1]</span><br><span class=\"line\"><span class=\"built_in\">print</span> x</span><br><span class=\"line\"><span class=\"built_in\">print</span> y</span><br><span class=\"line\">lr = linear_model.LinearRegression()</span><br><span class=\"line\">lr.fit(x, y)</span><br><span class=\"line\"><span class=\"built_in\">print</span> lr</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"coefficients:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> lr.coef_</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"intercept:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> lr.intercept_</span><br><span class=\"line\">xPredict = [102,6] </span><br><span class=\"line\">yPredict = lr.predict(xPredict)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"predict:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> yPredict</span><br><span class=\"line\"><span class=\"comment\"># 如果需要多个车型分开则增加N维二进制数组输入 然后预测 如：xPredict =  [90,2,0,0,1]</span></span><br></pre></td></tr></table></figure></li>\n"},{"title":"机器学习笔记（十六）非线性回归原理","date":"2017-09-12T07:03:47.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 概率：\n1.1 定义   概率(P)robability: 对一件事情发生的可能性的衡量\n1.2 范围   0 <= P <= 1\n1.3 计算方法： \n1.3.1 根据个人置信\n1.3.2 根据历史数据\n1.3.3 根据模拟数据\n<!-- more --> \n1.4 条件概率：\n$P(A|B)=\\frac{P(A\\cap B)}{P(B)}$                         \n2. Logistic Regression (逻辑回归)\n2.1 例子\n![](2017-9-12-one/1.png)                      \nh(x) > 0.5\n![](2017-9-12-one/2.png)             \nh(x) > 0.2\n2.2 基本模型\n测试数据为X(x0，x1，x2···xn)\n要学习的参数为： Θ(θ0，θ1，θ2，···θn) \n$Z=\\theta_0 x_0+\\theta_1 x_1\\theta_2 x_2+\\cdots \\theta_n x_n$   \n向量表示\n$Z=\\Theta^TX$   \n处理二值数据，引入Sigmoid函数时曲线平滑化\n$g(Z)=\\frac{1}{1+e^{-Z}}$   \n预测函数:\n$h_\\theta(X)=g(\\Theta^TX)=\\frac{1}{1+e^{-\\Theta^TX}}$  \n 用概率表示:\n正例(y=1): \n$h_\\theta(X)=P(y=1|X;\\Theta)$   \n反例(y=0): \n$1-h_\\theta(X)=P(y=0|X;\\Theta)$   \n2.3 Cost函数\n线性回归: \n![](2017-9-12-one/3.jpg) \n$\\sum_{i=1}^m(h_\\theta (x^{(i)})-y^{(i)})^2$ \n$h_\\theta(x^{(i)})=\\theta_0+\\theta_1x^{(i)}$ \n找到合适的 θ0，θ1使上式最小\nLogistic regression: \n![](2017-9-12-one/44.jpg) \nCost函数: \n目标：找到合适的 θ0，θ1使上式最小\n2.4 解法：梯度下降（gradient decent)\n![](2017-9-12-one/5.jpg) ![](2017-9-12-one/6.jpg) \n$\\theta_j=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta),(j=0\\cdots n)$ \n更新法则: \n$\\theta_j=\\theta_j-\\alpha \\sum_{i=1}^m(h_\\theta (x^{(i)})-y^{(i)})x_j^{(i)},(j=0\\cdots n)$   \n学习率\n同时对所有的θ进行更新\n重复更新直到收敛   ","source":"_posts/2017-9-12-one.md","raw":"---\ntitle: 机器学习笔记（十六）非线性回归原理\ndate: 2017-09-12 15:03:47\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 概率：\n1.1 定义   概率(P)robability: 对一件事情发生的可能性的衡量\n1.2 范围   0 <= P <= 1\n1.3 计算方法： \n1.3.1 根据个人置信\n1.3.2 根据历史数据\n1.3.3 根据模拟数据\n<!-- more --> \n1.4 条件概率：\n$P(A|B)=\\frac{P(A\\cap B)}{P(B)}$                         \n2. Logistic Regression (逻辑回归)\n2.1 例子\n![](2017-9-12-one/1.png)                      \nh(x) > 0.5\n![](2017-9-12-one/2.png)             \nh(x) > 0.2\n2.2 基本模型\n测试数据为X(x0，x1，x2···xn)\n要学习的参数为： Θ(θ0，θ1，θ2，···θn) \n$Z=\\theta_0 x_0+\\theta_1 x_1\\theta_2 x_2+\\cdots \\theta_n x_n$   \n向量表示\n$Z=\\Theta^TX$   \n处理二值数据，引入Sigmoid函数时曲线平滑化\n$g(Z)=\\frac{1}{1+e^{-Z}}$   \n预测函数:\n$h_\\theta(X)=g(\\Theta^TX)=\\frac{1}{1+e^{-\\Theta^TX}}$  \n 用概率表示:\n正例(y=1): \n$h_\\theta(X)=P(y=1|X;\\Theta)$   \n反例(y=0): \n$1-h_\\theta(X)=P(y=0|X;\\Theta)$   \n2.3 Cost函数\n线性回归: \n![](2017-9-12-one/3.jpg) \n$\\sum_{i=1}^m(h_\\theta (x^{(i)})-y^{(i)})^2$ \n$h_\\theta(x^{(i)})=\\theta_0+\\theta_1x^{(i)}$ \n找到合适的 θ0，θ1使上式最小\nLogistic regression: \n![](2017-9-12-one/44.jpg) \nCost函数: \n目标：找到合适的 θ0，θ1使上式最小\n2.4 解法：梯度下降（gradient decent)\n![](2017-9-12-one/5.jpg) ![](2017-9-12-one/6.jpg) \n$\\theta_j=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta),(j=0\\cdots n)$ \n更新法则: \n$\\theta_j=\\theta_j-\\alpha \\sum_{i=1}^m(h_\\theta (x^{(i)})-y^{(i)})x_j^{(i)},(j=0\\cdots n)$   \n学习率\n同时对所有的θ进行更新\n重复更新直到收敛   ","slug":"2017-9-12-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va31001tycvjywsaaihg","content":"<ol>\n<li>概率：<br>1.1 定义   概率(P)robability: 对一件事情发生的可能性的衡量<br>1.2 范围   0 &lt;= P &lt;= 1<br>1.3 计算方法：<br>1.3.1 根据个人置信<br>1.3.2 根据历史数据<br>1.3.3 根据模拟数据<a id=\"more\"></a> \n1.4 条件概率：<br>$P(A|B)=\\frac{P(A\\cap B)}{P(B)}$                         </li>\n<li>Logistic Regression (逻辑回归)<br>2.1 例子<br><img src=\"/2017/09/12/2017-9-12-one/1.png\" alt=\"\"><br>h(x) &gt; 0.5<br><img src=\"/2017/09/12/2017-9-12-one/2.png\" alt=\"\"><br>h(x) &gt; 0.2<br>2.2 基本模型<br>测试数据为X(x0，x1，x2···xn)<br>要学习的参数为： Θ(θ0，θ1，θ2，···θn)<br>$Z=\\theta_0 x_0+\\theta_1 x_1\\theta_2 x_2+\\cdots \\theta_n x_n$<br>向量表示<br>$Z=\\Theta^TX$<br>处理二值数据，引入Sigmoid函数时曲线平滑化<br>$g(Z)=\\frac{1}{1+e^{-Z}}$<br>预测函数:<br>$h_\\theta(X)=g(\\Theta^TX)=\\frac{1}{1+e^{-\\Theta^TX}}$<br>用概率表示:<br>正例(y=1):<br>$h_\\theta(X)=P(y=1|X;\\Theta)$<br>反例(y=0):<br>$1-h_\\theta(X)=P(y=0|X;\\Theta)$<br>2.3 Cost函数<br>线性回归:<br><img src=\"/2017/09/12/2017-9-12-one/3.jpg\" alt=\"\"><br>$\\sum_{i=1}^m(h_\\theta (x^{(i)})-y^{(i)})^2$<br>$h_\\theta(x^{(i)})=\\theta_0+\\theta_1x^{(i)}$<br>找到合适的 θ0，θ1使上式最小<br>Logistic regression:<br><img src=\"/2017/09/12/2017-9-12-one/44.jpg\" alt=\"\"><br>Cost函数:<br>目标：找到合适的 θ0，θ1使上式最小<br>2.4 解法：梯度下降（gradient decent)<br><img src=\"/2017/09/12/2017-9-12-one/5.jpg\" alt=\"\"> <img src=\"/2017/09/12/2017-9-12-one/6.jpg\" alt=\"\"><br>$\\theta_j=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta),(j=0\\cdots n)$<br>更新法则:<br>$\\theta_j=\\theta_j-\\alpha \\sum_{i=1}^m(h_\\theta (x^{(i)})-y^{(i)})x_j^{(i)},(j=0\\cdots n)$<br>学习率<br>同时对所有的θ进行更新<br>重复更新直到收敛   </li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>概率：<br>1.1 定义   概率(P)robability: 对一件事情发生的可能性的衡量<br>1.2 范围   0 &lt;= P &lt;= 1<br>1.3 计算方法：<br>1.3.1 根据个人置信<br>1.3.2 根据历史数据<br>1.3.3 根据模拟数据</li></ol>","more":"1.4 条件概率：<br>$P(A|B)=\\frac{P(A\\cap B)}{P(B)}$                         \n<li>Logistic Regression (逻辑回归)<br>2.1 例子<br><img src=\"/2017/09/12/2017-9-12-one/1.png\" alt=\"\"><br>h(x) &gt; 0.5<br><img src=\"/2017/09/12/2017-9-12-one/2.png\" alt=\"\"><br>h(x) &gt; 0.2<br>2.2 基本模型<br>测试数据为X(x0，x1，x2···xn)<br>要学习的参数为： Θ(θ0，θ1，θ2，···θn)<br>$Z=\\theta_0 x_0+\\theta_1 x_1\\theta_2 x_2+\\cdots \\theta_n x_n$<br>向量表示<br>$Z=\\Theta^TX$<br>处理二值数据，引入Sigmoid函数时曲线平滑化<br>$g(Z)=\\frac{1}{1+e^{-Z}}$<br>预测函数:<br>$h_\\theta(X)=g(\\Theta^TX)=\\frac{1}{1+e^{-\\Theta^TX}}$<br>用概率表示:<br>正例(y=1):<br>$h_\\theta(X)=P(y=1|X;\\Theta)$<br>反例(y=0):<br>$1-h_\\theta(X)=P(y=0|X;\\Theta)$<br>2.3 Cost函数<br>线性回归:<br><img src=\"/2017/09/12/2017-9-12-one/3.jpg\" alt=\"\"><br>$\\sum_{i=1}^m(h_\\theta (x^{(i)})-y^{(i)})^2$<br>$h_\\theta(x^{(i)})=\\theta_0+\\theta_1x^{(i)}$<br>找到合适的 θ0，θ1使上式最小<br>Logistic regression:<br><img src=\"/2017/09/12/2017-9-12-one/44.jpg\" alt=\"\"><br>Cost函数:<br>目标：找到合适的 θ0，θ1使上式最小<br>2.4 解法：梯度下降（gradient decent)<br><img src=\"/2017/09/12/2017-9-12-one/5.jpg\" alt=\"\"> <img src=\"/2017/09/12/2017-9-12-one/6.jpg\" alt=\"\"><br>$\\theta_j=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta),(j=0\\cdots n)$<br>更新法则:<br>$\\theta_j=\\theta_j-\\alpha \\sum_{i=1}^m(h_\\theta (x^{(i)})-y^{(i)})x_j^{(i)},(j=0\\cdots n)$<br>学习率<br>同时对所有的θ进行更新<br>重复更新直到收敛   </li>\n"},{"title":"Latex符号大全","date":"2017-09-13T01:42:49.000Z","_content":"转载自\nhttp://blog.csdn.net/garfielder007/article/details/51646604\nmark一下备用","source":"_posts/2017-9-13-one.md","raw":"---\ntitle: Latex符号大全\ndate: 2017-09-13 09:42:49\ntags:\n - LATEX\n---\n转载自\nhttp://blog.csdn.net/garfielder007/article/details/51646604\nmark一下备用","slug":"2017-9-13-one","published":1,"updated":"2018-01-13T08:07:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjd71va3h001vycvj2a63vpgl","content":"<p>转载自<br><a href=\"http://blog.csdn.net/garfielder007/article/details/51646604\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/garfielder007/article/details/51646604</a><br>mark一下备用</p>\n","site":{"data":{}},"excerpt":"","more":"<p>转载自<br><a href=\"http://blog.csdn.net/garfielder007/article/details/51646604\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/garfielder007/article/details/51646604</a><br>mark一下备用</p>\n"},{"title":"机器学习笔记（十八）回归中的相关度和R平方值","date":"2017-09-14T01:42:49.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 皮尔逊相关系数 (Pearson Correlation Coefficient):\n1.1 衡量两个值线性相关强度的量\n1.2 取值范围 [-1, 1]: \n<!-- more -->\n正向相关: >0, 负向相关：<0, 无相关性：=0\n1.3 \n$\\rho=Cor(X,Y)=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}$         \n$r_{xy}=\\frac{\\sum(x-\\overline{x})(y-\\overline{y})}{\\sqrt{\\sum(x-\\overline{x})^2(y-\\overline{y})^2}}$    \n2. 计算方法举例：\nX\tY\n1\t10\n3\t12\n8\t24\n7\t21\n9\t34\n3. 其他例子：\n![](2017-9-14-one/1.png) \n4. R平方值:\n4.1 定义：决定系数，反应因变量的全部变异能通过回归关系被自变量解释的比例。\n4.2 描述：如R平方为0.8，则表示回归关系可以解释因变量80%的变异。换句话说，如果我们能控制自变量不变，则因变量的变异程度会减少80%\n4.3： 简单线性回归：R^2 = r * r\n      多元线性回归：\n$R^2=\\frac{SSR}{SST}=\\frac{\\sum(\\hat{y_i}-\\overline{y})^2}{\\sum(y_i-\\overline{y})^2}$   \n![](2017-9-14-one/2.jpg)                \n$SSE=\\sum(y_i-\\hat{y_i})^2$                    \n5. R平方也有其局限性：R平方随着自变量的增加会变大，R平方和样本量是有关系的。因此，我们要到R平方进行修正。修正的方法：\n$R^2=1-\\frac{(1-R^2)(N-1)}{N-P-1}$\np为预测数目\nN为样本数目         \n","source":"_posts/2017-9-14-one.md","raw":"---\ntitle: 机器学习笔记（十八）回归中的相关度和R平方值\ndate: 2017-09-14 09:42:49\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 皮尔逊相关系数 (Pearson Correlation Coefficient):\n1.1 衡量两个值线性相关强度的量\n1.2 取值范围 [-1, 1]: \n<!-- more -->\n正向相关: >0, 负向相关：<0, 无相关性：=0\n1.3 \n$\\rho=Cor(X,Y)=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}$         \n$r_{xy}=\\frac{\\sum(x-\\overline{x})(y-\\overline{y})}{\\sqrt{\\sum(x-\\overline{x})^2(y-\\overline{y})^2}}$    \n2. 计算方法举例：\nX\tY\n1\t10\n3\t12\n8\t24\n7\t21\n9\t34\n3. 其他例子：\n![](2017-9-14-one/1.png) \n4. R平方值:\n4.1 定义：决定系数，反应因变量的全部变异能通过回归关系被自变量解释的比例。\n4.2 描述：如R平方为0.8，则表示回归关系可以解释因变量80%的变异。换句话说，如果我们能控制自变量不变，则因变量的变异程度会减少80%\n4.3： 简单线性回归：R^2 = r * r\n      多元线性回归：\n$R^2=\\frac{SSR}{SST}=\\frac{\\sum(\\hat{y_i}-\\overline{y})^2}{\\sum(y_i-\\overline{y})^2}$   \n![](2017-9-14-one/2.jpg)                \n$SSE=\\sum(y_i-\\hat{y_i})^2$                    \n5. R平方也有其局限性：R平方随着自变量的增加会变大，R平方和样本量是有关系的。因此，我们要到R平方进行修正。修正的方法：\n$R^2=1-\\frac{(1-R^2)(N-1)}{N-P-1}$\np为预测数目\nN为样本数目         \n","slug":"2017-9-14-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va3h001xycvjvfnmo829","content":"<ol>\n<li>皮尔逊相关系数 (Pearson Correlation Coefficient):<br>1.1 衡量两个值线性相关强度的量<br>1.2 取值范围 [-1, 1]: <a id=\"more\"></a>\n正向相关: &gt;0, 负向相关：&lt;0, 无相关性：=0<br>1.3<br>$\\rho=Cor(X,Y)=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}$<br>$r_{xy}=\\frac{\\sum(x-\\overline{x})(y-\\overline{y})}{\\sqrt{\\sum(x-\\overline{x})^2(y-\\overline{y})^2}}$    </li>\n<li>计算方法举例：<br>X    Y<br>1    10<br>3    12<br>8    24<br>7    21<br>9    34</li>\n<li>其他例子：<br><img src=\"/2017/09/14/2017-9-14-one/1.png\" alt=\"\"> </li>\n<li>R平方值:<br>4.1 定义：决定系数，反应因变量的全部变异能通过回归关系被自变量解释的比例。<br>4.2 描述：如R平方为0.8，则表示回归关系可以解释因变量80%的变异。换句话说，如果我们能控制自变量不变，则因变量的变异程度会减少80%<br>4.3： 简单线性回归：R^2 = r * r<br>   多元线性回归：<br>$R^2=\\frac{SSR}{SST}=\\frac{\\sum(\\hat{y_i}-\\overline{y})^2}{\\sum(y_i-\\overline{y})^2}$<br><img src=\"/2017/09/14/2017-9-14-one/2.jpg\" alt=\"\"><br>$SSE=\\sum(y_i-\\hat{y_i})^2$                    </li>\n<li>R平方也有其局限性：R平方随着自变量的增加会变大，R平方和样本量是有关系的。因此，我们要到R平方进行修正。修正的方法：<br>$R^2=1-\\frac{(1-R^2)(N-1)}{N-P-1}$<br>p为预测数目<br>N为样本数目         </li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>皮尔逊相关系数 (Pearson Correlation Coefficient):<br>1.1 衡量两个值线性相关强度的量<br>1.2 取值范围 [-1, 1]:</li></ol>","more":"正向相关: &gt;0, 负向相关：&lt;0, 无相关性：=0<br>1.3<br>$\\rho=Cor(X,Y)=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}$<br>$r_{xy}=\\frac{\\sum(x-\\overline{x})(y-\\overline{y})}{\\sqrt{\\sum(x-\\overline{x})^2(y-\\overline{y})^2}}$    \n<li>计算方法举例：<br>X    Y<br>1    10<br>3    12<br>8    24<br>7    21<br>9    34</li>\n<li>其他例子：<br><img src=\"/2017/09/14/2017-9-14-one/1.png\" alt=\"\"> </li>\n<li>R平方值:<br>4.1 定义：决定系数，反应因变量的全部变异能通过回归关系被自变量解释的比例。<br>4.2 描述：如R平方为0.8，则表示回归关系可以解释因变量80%的变异。换句话说，如果我们能控制自变量不变，则因变量的变异程度会减少80%<br>4.3： 简单线性回归：R^2 = r * r<br>   多元线性回归：<br>$R^2=\\frac{SSR}{SST}=\\frac{\\sum(\\hat{y_i}-\\overline{y})^2}{\\sum(y_i-\\overline{y})^2}$<br><img src=\"/2017/09/14/2017-9-14-one/2.jpg\" alt=\"\"><br>$SSE=\\sum(y_i-\\hat{y_i})^2$                    </li>\n<li>R平方也有其局限性：R平方随着自变量的增加会变大，R平方和样本量是有关系的。因此，我们要到R平方进行修正。修正的方法：<br>$R^2=1-\\frac{(1-R^2)(N-1)}{N-P-1}$<br>p为预测数目<br>N为样本数目         </li>\n"},{"title":"机器学习笔记（十七）非线性回归应用","date":"2017-09-13T08:27:31.000Z","comments":1,"reward":true,"mathjax":true,"_content":"直接上一段简单的梯度下降算法代码\n<!-- more -->  \n``` bash\nimport numpy as np\nimport random\n\ndef genData(numPoints,bias,variance):\n    x = np.zeros(shape=(numPoints,2))\n    y = np.zeros(shape=(numPoints))\n    for i in range(0,numPoints):\n        x[i][0]=1\n        x[i][1]=i\n        y[i]=(i+bias)+random.uniform(0,1)+variance\n    return x,y\n\ndef gradientDescent(x,y,theta,alpha,m,numIterations):\n    xTran = np.transpose(x)\n    for i in range(numIterations):\n        hypothesis = np.dot(x,theta)\n        loss = hypothesis-y\n        cost = np.sum(loss**2)/(2*m)\n        gradient=np.dot(xTran,loss)/m\n        theta = theta-alpha*gradient\n    return theta\n\nx,y = genData(100, 25, 10)\nprint \"x:\"\nprint x\nprint \"y:\"\nprint y\n\nm,n = np.shape(x)\nn_y = np.shape(y)\n  \nprint(\"m:\"+str(m)+\" n:\"+str(n)+\" n_y:\"+str(n_y))\n  \nnumIterations = 100000\nalpha = 0.0005\ntheta = np.ones(n)\ntheta= gradientDescent(x, y, theta, alpha, m, numIterations)\nprint(theta)\n```\ncost由开始的60多下降到最后的3点几\n最后给出参数theta x数组第一列为1，所以theta[1]代表偏置,theta[2]为斜率","source":"_posts/2017-9-13-two.md","raw":"---\ntitle: 机器学习笔记（十七）非线性回归应用\ndate: 2017-09-13 16:27:31\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n直接上一段简单的梯度下降算法代码\n<!-- more -->  \n``` bash\nimport numpy as np\nimport random\n\ndef genData(numPoints,bias,variance):\n    x = np.zeros(shape=(numPoints,2))\n    y = np.zeros(shape=(numPoints))\n    for i in range(0,numPoints):\n        x[i][0]=1\n        x[i][1]=i\n        y[i]=(i+bias)+random.uniform(0,1)+variance\n    return x,y\n\ndef gradientDescent(x,y,theta,alpha,m,numIterations):\n    xTran = np.transpose(x)\n    for i in range(numIterations):\n        hypothesis = np.dot(x,theta)\n        loss = hypothesis-y\n        cost = np.sum(loss**2)/(2*m)\n        gradient=np.dot(xTran,loss)/m\n        theta = theta-alpha*gradient\n    return theta\n\nx,y = genData(100, 25, 10)\nprint \"x:\"\nprint x\nprint \"y:\"\nprint y\n\nm,n = np.shape(x)\nn_y = np.shape(y)\n  \nprint(\"m:\"+str(m)+\" n:\"+str(n)+\" n_y:\"+str(n_y))\n  \nnumIterations = 100000\nalpha = 0.0005\ntheta = np.ones(n)\ntheta= gradientDescent(x, y, theta, alpha, m, numIterations)\nprint(theta)\n```\ncost由开始的60多下降到最后的3点几\n最后给出参数theta x数组第一列为1，所以theta[1]代表偏置,theta[2]为斜率","slug":"2017-9-13-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va3h001zycvjxxs31u7f","content":"<p>直接上一段简单的梯度下降算法代码<br><a id=\"more\"></a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">import random</span><br><span class=\"line\"></span><br><span class=\"line\">def genData(numPoints,bias,variance):</span><br><span class=\"line\">    x = np.zeros(shape=(numPoints,2))</span><br><span class=\"line\">    y = np.zeros(shape=(numPoints))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0,numPoints):</span><br><span class=\"line\">        x[i][0]=1</span><br><span class=\"line\">        x[i][1]=i</span><br><span class=\"line\">        y[i]=(i+bias)+random.uniform(0,1)+variance</span><br><span class=\"line\">    <span class=\"built_in\">return</span> x,y</span><br><span class=\"line\"></span><br><span class=\"line\">def gradientDescent(x,y,theta,alpha,m,numIterations):</span><br><span class=\"line\">    xTran = np.transpose(x)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(numIterations):</span><br><span class=\"line\">        hypothesis = np.dot(x,theta)</span><br><span class=\"line\">        loss = hypothesis-y</span><br><span class=\"line\">        cost = np.sum(loss**2)/(2*m)</span><br><span class=\"line\">        gradient=np.dot(xTran,loss)/m</span><br><span class=\"line\">        theta = theta-alpha*gradient</span><br><span class=\"line\">    <span class=\"built_in\">return</span> theta</span><br><span class=\"line\"></span><br><span class=\"line\">x,y = genData(100, 25, 10)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"x:\"</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> x</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"y:\"</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> y</span><br><span class=\"line\"></span><br><span class=\"line\">m,n = np.shape(x)</span><br><span class=\"line\">n_y = np.shape(y)</span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"m:\"</span>+str(m)+<span class=\"string\">\" n:\"</span>+str(n)+<span class=\"string\">\" n_y:\"</span>+str(n_y))</span><br><span class=\"line\">  </span><br><span class=\"line\">numIterations = 100000</span><br><span class=\"line\">alpha = 0.0005</span><br><span class=\"line\">theta = np.ones(n)</span><br><span class=\"line\">theta= gradientDescent(x, y, theta, alpha, m, numIterations)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(theta)</span><br></pre></td></tr></table></figure></p>\n<p>cost由开始的60多下降到最后的3点几<br>最后给出参数theta x数组第一列为1，所以theta[1]代表偏置,theta[2]为斜率</p>\n","site":{"data":{}},"excerpt":"<p>直接上一段简单的梯度下降算法代码<br></p>","more":"<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">import random</span><br><span class=\"line\"></span><br><span class=\"line\">def genData(numPoints,bias,variance):</span><br><span class=\"line\">    x = np.zeros(shape=(numPoints,2))</span><br><span class=\"line\">    y = np.zeros(shape=(numPoints))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0,numPoints):</span><br><span class=\"line\">        x[i][0]=1</span><br><span class=\"line\">        x[i][1]=i</span><br><span class=\"line\">        y[i]=(i+bias)+random.uniform(0,1)+variance</span><br><span class=\"line\">    <span class=\"built_in\">return</span> x,y</span><br><span class=\"line\"></span><br><span class=\"line\">def gradientDescent(x,y,theta,alpha,m,numIterations):</span><br><span class=\"line\">    xTran = np.transpose(x)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(numIterations):</span><br><span class=\"line\">        hypothesis = np.dot(x,theta)</span><br><span class=\"line\">        loss = hypothesis-y</span><br><span class=\"line\">        cost = np.sum(loss**2)/(2*m)</span><br><span class=\"line\">        gradient=np.dot(xTran,loss)/m</span><br><span class=\"line\">        theta = theta-alpha*gradient</span><br><span class=\"line\">    <span class=\"built_in\">return</span> theta</span><br><span class=\"line\"></span><br><span class=\"line\">x,y = genData(100, 25, 10)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"x:\"</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> x</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"y:\"</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> y</span><br><span class=\"line\"></span><br><span class=\"line\">m,n = np.shape(x)</span><br><span class=\"line\">n_y = np.shape(y)</span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"m:\"</span>+str(m)+<span class=\"string\">\" n:\"</span>+str(n)+<span class=\"string\">\" n_y:\"</span>+str(n_y))</span><br><span class=\"line\">  </span><br><span class=\"line\">numIterations = 100000</span><br><span class=\"line\">alpha = 0.0005</span><br><span class=\"line\">theta = np.ones(n)</span><br><span class=\"line\">theta= gradientDescent(x, y, theta, alpha, m, numIterations)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(theta)</span><br></pre></td></tr></table></figure><p></p>\n<p>cost由开始的60多下降到最后的3点几<br>最后给出参数theta x数组第一列为1，所以theta[1]代表偏置,theta[2]为斜率</p>"},{"title":"机器学习笔记（十九）回归中的相关度和R平方值代码","date":"2017-09-14T07:31:24.000Z","comments":1,"reward":true,"mathjax":true,"_content":"线性回归计算R平方值和相关度python代码：\n<!-- more -->\n``` bash\nimport numpy as np\nfrom astropy.units import Ybarn\nimport math\n\ndef computeCorrelation(X, Y):\n    xBar = np.mean(X)\n    yBar = np.mean(Y)\n    SSR = 0\n    varX = 0\n    varY = 0\n    for i in range(0 , len(X)):\n        diffXXBar = X[i] - xBar\n        diffYYBar = Y[i] - yBar\n        SSR += (diffXXBar * diffYYBar)\n        varX +=  diffXXBar**2\n        varY += diffYYBar**2\n    \n    SST = math.sqrt(varX * varY)\n    return SSR / SST\ndef polyfit(x,y,degree):\n    results={}\n    coeffs=np.polyfit(x,y,degree)\n    results['polinoial']=coeffs.tolist()\n    p=np.poly1d(coeffs)\n    yhat=p(x)\n    ybar=np.mean(y)\n    ssr=np.sum((yhat-ybar)**2)\n    sst=np.sum((y-ybar)**2)\n    results['determination']=ssr/sst;\n    return results\n    \ntestX = [1, 3, 8, 7, 9]\ntestY = [10, 12, 24, 21, 34]\n\nprint computeCorrelation(testX, testY) **2\nprint polyfit(testX, testY, 1)  \n```\n打印结果均为0.884   ","source":"_posts/2017-9-14-two.md","raw":"---\ntitle: 机器学习笔记（十九）回归中的相关度和R平方值代码\ndate: 2017-09-14 15:31:24\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n线性回归计算R平方值和相关度python代码：\n<!-- more -->\n``` bash\nimport numpy as np\nfrom astropy.units import Ybarn\nimport math\n\ndef computeCorrelation(X, Y):\n    xBar = np.mean(X)\n    yBar = np.mean(Y)\n    SSR = 0\n    varX = 0\n    varY = 0\n    for i in range(0 , len(X)):\n        diffXXBar = X[i] - xBar\n        diffYYBar = Y[i] - yBar\n        SSR += (diffXXBar * diffYYBar)\n        varX +=  diffXXBar**2\n        varY += diffYYBar**2\n    \n    SST = math.sqrt(varX * varY)\n    return SSR / SST\ndef polyfit(x,y,degree):\n    results={}\n    coeffs=np.polyfit(x,y,degree)\n    results['polinoial']=coeffs.tolist()\n    p=np.poly1d(coeffs)\n    yhat=p(x)\n    ybar=np.mean(y)\n    ssr=np.sum((yhat-ybar)**2)\n    sst=np.sum((y-ybar)**2)\n    results['determination']=ssr/sst;\n    return results\n    \ntestX = [1, 3, 8, 7, 9]\ntestY = [10, 12, 24, 21, 34]\n\nprint computeCorrelation(testX, testY) **2\nprint polyfit(testX, testY, 1)  \n```\n打印结果均为0.884   ","slug":"2017-9-14-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va3h0021ycvjn7xh86s4","content":"<p>线性回归计算R平方值和相关度python代码：<br><a id=\"more\"></a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">from astropy.units import Ybarn</span><br><span class=\"line\">import math</span><br><span class=\"line\"></span><br><span class=\"line\">def computeCorrelation(X, Y):</span><br><span class=\"line\">    xBar = np.mean(X)</span><br><span class=\"line\">    yBar = np.mean(Y)</span><br><span class=\"line\">    SSR = 0</span><br><span class=\"line\">    varX = 0</span><br><span class=\"line\">    varY = 0</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0 , len(X)):</span><br><span class=\"line\">        diffXXBar = X[i] - xBar</span><br><span class=\"line\">        diffYYBar = Y[i] - yBar</span><br><span class=\"line\">        SSR += (diffXXBar * diffYYBar)</span><br><span class=\"line\">        varX +=  diffXXBar**2</span><br><span class=\"line\">        varY += diffYYBar**2</span><br><span class=\"line\">    </span><br><span class=\"line\">    SST = math.sqrt(varX * varY)</span><br><span class=\"line\">    <span class=\"built_in\">return</span> SSR / SST</span><br><span class=\"line\">def polyfit(x,y,degree):</span><br><span class=\"line\">    results=&#123;&#125;</span><br><span class=\"line\">    coeffs=np.polyfit(x,y,degree)</span><br><span class=\"line\">    results[<span class=\"string\">'polinoial'</span>]=coeffs.tolist()</span><br><span class=\"line\">    p=np.poly1d(coeffs)</span><br><span class=\"line\">    yhat=p(x)</span><br><span class=\"line\">    ybar=np.mean(y)</span><br><span class=\"line\">    ssr=np.sum((yhat-ybar)**2)</span><br><span class=\"line\">    sst=np.sum((y-ybar)**2)</span><br><span class=\"line\">    results[<span class=\"string\">'determination'</span>]=ssr/sst;</span><br><span class=\"line\">    <span class=\"built_in\">return</span> results</span><br><span class=\"line\">    </span><br><span class=\"line\">testX = [1, 3, 8, 7, 9]</span><br><span class=\"line\">testY = [10, 12, 24, 21, 34]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span> computeCorrelation(testX, testY) **2</span><br><span class=\"line\"><span class=\"built_in\">print</span> polyfit(testX, testY, 1)</span><br></pre></td></tr></table></figure></p>\n<p>打印结果均为0.884   </p>\n","site":{"data":{}},"excerpt":"<p>线性回归计算R平方值和相关度python代码：<br></p>","more":"<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">from astropy.units import Ybarn</span><br><span class=\"line\">import math</span><br><span class=\"line\"></span><br><span class=\"line\">def computeCorrelation(X, Y):</span><br><span class=\"line\">    xBar = np.mean(X)</span><br><span class=\"line\">    yBar = np.mean(Y)</span><br><span class=\"line\">    SSR = 0</span><br><span class=\"line\">    varX = 0</span><br><span class=\"line\">    varY = 0</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0 , len(X)):</span><br><span class=\"line\">        diffXXBar = X[i] - xBar</span><br><span class=\"line\">        diffYYBar = Y[i] - yBar</span><br><span class=\"line\">        SSR += (diffXXBar * diffYYBar)</span><br><span class=\"line\">        varX +=  diffXXBar**2</span><br><span class=\"line\">        varY += diffYYBar**2</span><br><span class=\"line\">    </span><br><span class=\"line\">    SST = math.sqrt(varX * varY)</span><br><span class=\"line\">    <span class=\"built_in\">return</span> SSR / SST</span><br><span class=\"line\">def polyfit(x,y,degree):</span><br><span class=\"line\">    results=&#123;&#125;</span><br><span class=\"line\">    coeffs=np.polyfit(x,y,degree)</span><br><span class=\"line\">    results[<span class=\"string\">'polinoial'</span>]=coeffs.tolist()</span><br><span class=\"line\">    p=np.poly1d(coeffs)</span><br><span class=\"line\">    yhat=p(x)</span><br><span class=\"line\">    ybar=np.mean(y)</span><br><span class=\"line\">    ssr=np.sum((yhat-ybar)**2)</span><br><span class=\"line\">    sst=np.sum((y-ybar)**2)</span><br><span class=\"line\">    results[<span class=\"string\">'determination'</span>]=ssr/sst;</span><br><span class=\"line\">    <span class=\"built_in\">return</span> results</span><br><span class=\"line\">    </span><br><span class=\"line\">testX = [1, 3, 8, 7, 9]</span><br><span class=\"line\">testY = [10, 12, 24, 21, 34]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span> computeCorrelation(testX, testY) **2</span><br><span class=\"line\"><span class=\"built_in\">print</span> polyfit(testX, testY, 1)</span><br></pre></td></tr></table></figure><p></p>\n<p>打印结果均为0.884   </p>"},{"title":"机器学习笔记（二十）聚类(Clustering) K-means算法","date":"2017-09-15T02:47:16.000Z","comments":1,"reward":true,"mathjax":true,"_content":"1. 归类： \n聚类(clustering) 属于非监督学习 (unsupervised learning)\n无类别标记(class label)\n2. 举例：\n![](2017-9-15-one/1.jpg) \n<!-- more -->          \n3. K-means 算法：\n3.1 Clustering 中的经典算法，数据挖掘十大经典算法之一\n3.2 算法接受参数 k ；然后将事先输入的n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。\n3.3 算法思想：\n以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果\n3.4 算法描述：         \n（1）适当选择c个类的初始中心；\n（2）在第k次迭代中，对任意一个样本，求其到c各中心的距离，将该样本归到距离最短的中心所在的类；\n（3）利用均值等方法更新该类的中心值；\n（4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。\n3.5 算法流程：\n![](2017-9-15-one/2.jpg)             \n输入：k, data[n];\n（1） 选择k个初始中心点，例如c[0]=data[0],…c[k-1]=data[k-1];\n（2） 对于data[0]….data[n], 分别与c[0]…c[k-1]比较，假定与c[i]差值最少，就标记为i;\n（3） 对于所有标记为i点，重新计算c[i]={ 所有标记为i的data[j]之和}/标记为i的个数；\n（4） 重复(2)(3),直到所有c[i]值的变化小于给定阈值。\n4. 举例：\n![](2017-9-15-one/3.png)   \n![](2017-9-15-one/4.png) \n![](2017-9-15-one/5.png) \n![](2017-9-15-one/d0.png) \n![](2017-9-15-one/g0.png) \n![](2017-9-15-one/c2.png) \n![](2017-9-15-one/6.png)\n![](2017-9-15-one/d1.png)\n![](2017-9-15-one/g1.png)\n![](2017-9-15-one/c1andc2.png) \n![](2017-9-15-one/7.png) \n![](2017-9-15-one/d2.png) \n![](2017-9-15-one/g2.png)   \n停止        \n优点：速度快，简单\n缺点：最终结果跟初始点选择相关，容易陷入局部最优，需直到k值\nReference:http://croce.ggf.br/dados/K%20mean%20Clustering1.pdf","source":"_posts/2017-9-15-one.md","raw":"---\ntitle: 机器学习笔记（二十）聚类(Clustering) K-means算法\ndate: 2017-09-15 10:47:16\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n1. 归类： \n聚类(clustering) 属于非监督学习 (unsupervised learning)\n无类别标记(class label)\n2. 举例：\n![](2017-9-15-one/1.jpg) \n<!-- more -->          \n3. K-means 算法：\n3.1 Clustering 中的经典算法，数据挖掘十大经典算法之一\n3.2 算法接受参数 k ；然后将事先输入的n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。\n3.3 算法思想：\n以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果\n3.4 算法描述：         \n（1）适当选择c个类的初始中心；\n（2）在第k次迭代中，对任意一个样本，求其到c各中心的距离，将该样本归到距离最短的中心所在的类；\n（3）利用均值等方法更新该类的中心值；\n（4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。\n3.5 算法流程：\n![](2017-9-15-one/2.jpg)             \n输入：k, data[n];\n（1） 选择k个初始中心点，例如c[0]=data[0],…c[k-1]=data[k-1];\n（2） 对于data[0]….data[n], 分别与c[0]…c[k-1]比较，假定与c[i]差值最少，就标记为i;\n（3） 对于所有标记为i点，重新计算c[i]={ 所有标记为i的data[j]之和}/标记为i的个数；\n（4） 重复(2)(3),直到所有c[i]值的变化小于给定阈值。\n4. 举例：\n![](2017-9-15-one/3.png)   \n![](2017-9-15-one/4.png) \n![](2017-9-15-one/5.png) \n![](2017-9-15-one/d0.png) \n![](2017-9-15-one/g0.png) \n![](2017-9-15-one/c2.png) \n![](2017-9-15-one/6.png)\n![](2017-9-15-one/d1.png)\n![](2017-9-15-one/g1.png)\n![](2017-9-15-one/c1andc2.png) \n![](2017-9-15-one/7.png) \n![](2017-9-15-one/d2.png) \n![](2017-9-15-one/g2.png)   \n停止        \n优点：速度快，简单\n缺点：最终结果跟初始点选择相关，容易陷入局部最优，需直到k值\nReference:http://croce.ggf.br/dados/K%20mean%20Clustering1.pdf","slug":"2017-9-15-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va3h0023ycvjlsm52vi6","content":"<ol>\n<li>归类：<br>聚类(clustering) 属于非监督学习 (unsupervised learning)<br>无类别标记(class label)</li>\n<li>举例：<br><img src=\"/2017/09/15/2017-9-15-one/1.jpg\" alt=\"\"> <a id=\"more\"></a>          </li>\n<li>K-means 算法：<br>3.1 Clustering 中的经典算法，数据挖掘十大经典算法之一<br>3.2 算法接受参数 k ；然后将事先输入的n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。<br>3.3 算法思想：<br>以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果<br>3.4 算法描述：<br>（1）适当选择c个类的初始中心；<br>（2）在第k次迭代中，对任意一个样本，求其到c各中心的距离，将该样本归到距离最短的中心所在的类；<br>（3）利用均值等方法更新该类的中心值；<br>（4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。<br>3.5 算法流程：<br><img src=\"/2017/09/15/2017-9-15-one/2.jpg\" alt=\"\"><br>输入：k, data[n];<br>（1） 选择k个初始中心点，例如c[0]=data[0],…c[k-1]=data[k-1];<br>（2） 对于data[0]….data[n], 分别与c[0]…c[k-1]比较，假定与c[i]差值最少，就标记为i;<br>（3） 对于所有标记为i点，重新计算c[i]={ 所有标记为i的data[j]之和}/标记为i的个数；<br>（4） 重复(2)(3),直到所有c[i]值的变化小于给定阈值。</li>\n<li>举例：<br><img src=\"/2017/09/15/2017-9-15-one/3.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/4.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/5.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/d0.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/g0.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/c2.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/6.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/d1.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/g1.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/c1andc2.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/7.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/d2.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/g2.png\" alt=\"\"><br>停止<br>优点：速度快，简单<br>缺点：最终结果跟初始点选择相关，容易陷入局部最优，需直到k值<br>Reference:<a href=\"http://croce.ggf.br/dados/K%20mean%20Clustering1.pdf\" target=\"_blank\" rel=\"noopener\">http://croce.ggf.br/dados/K%20mean%20Clustering1.pdf</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<ol>\n<li>归类：<br>聚类(clustering) 属于非监督学习 (unsupervised learning)<br>无类别标记(class label)</li>\n<li>举例：<br><img src=\"/2017/09/15/2017-9-15-one/1.jpg\" alt=\"\"></li></ol>","more":"\n<li>K-means 算法：<br>3.1 Clustering 中的经典算法，数据挖掘十大经典算法之一<br>3.2 算法接受参数 k ；然后将事先输入的n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。<br>3.3 算法思想：<br>以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果<br>3.4 算法描述：<br>（1）适当选择c个类的初始中心；<br>（2）在第k次迭代中，对任意一个样本，求其到c各中心的距离，将该样本归到距离最短的中心所在的类；<br>（3）利用均值等方法更新该类的中心值；<br>（4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。<br>3.5 算法流程：<br><img src=\"/2017/09/15/2017-9-15-one/2.jpg\" alt=\"\"><br>输入：k, data[n];<br>（1） 选择k个初始中心点，例如c[0]=data[0],…c[k-1]=data[k-1];<br>（2） 对于data[0]….data[n], 分别与c[0]…c[k-1]比较，假定与c[i]差值最少，就标记为i;<br>（3） 对于所有标记为i点，重新计算c[i]={ 所有标记为i的data[j]之和}/标记为i的个数；<br>（4） 重复(2)(3),直到所有c[i]值的变化小于给定阈值。</li>\n<li>举例：<br><img src=\"/2017/09/15/2017-9-15-one/3.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/4.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/5.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/d0.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/g0.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/c2.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/6.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/d1.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/g1.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/c1andc2.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/7.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/d2.png\" alt=\"\"><br><img src=\"/2017/09/15/2017-9-15-one/g2.png\" alt=\"\"><br>停止<br>优点：速度快，简单<br>缺点：最终结果跟初始点选择相关，容易陷入局部最优，需直到k值<br>Reference:<a href=\"http://croce.ggf.br/dados/K%20mean%20Clustering1.pdf\" target=\"_blank\" rel=\"noopener\">http://croce.ggf.br/dados/K%20mean%20Clustering1.pdf</a></li>\n"},{"title":"机器学习笔记（二十一）聚类(Clustering) K-means算法应用","date":"2017-09-18T01:51:50.000Z","comments":1,"reward":true,"mathjax":true,"_content":"KMeans聚类算法python代码：\n<!-- more -->\n``` bash\nimport numpy as np\n\n# Function: K Means\n# -------------\n# K-Means is an algorithm that takes in a dataset and a constant\n# k and returns k centroids (which define clusters of data in the\n# dataset which are similar to one another).\ndef kmeans(X, k, maxIt):\n    \n    numPoints, numDim = X.shape\n    \n    dataSet = np.zeros((numPoints, numDim + 1))\n    dataSet[:, :-1] = X\n    \n    # Initialize centroids randomly\n    centroids = dataSet[np.random.randint(numPoints, size = k), :]\n    centroids = dataSet[0:2, :]\n    #Randomly assign labels to initial centorid\n    centroids[:, -1] = range(1, k +1)\n    \n    # Initialize book keeping vars.\n    iterations = 0\n    oldCentroids = None\n    \n    # Run the main k-means algorithm\n    while not shouldStop(oldCentroids, centroids, iterations, maxIt):\n        print \"iteration: \\n\", iterations\n        print \"dataSet: \\n\", dataSet\n        print \"centroids: \\n\", centroids\n        # Save old centroids for convergence test. Book keeping.\n        oldCentroids = np.copy(centroids)\n        iterations += 1\n        \n        # Assign labels to each datapoint based on centroids\n        updateLabels(dataSet, centroids)\n        \n        # Assign centroids based on datapoint labels\n        centroids = getCentroids(dataSet, k)\n        \n    # We can get the labels too by calling getLabels(dataSet, centroids)\n    return dataSet\n# Function: Should Stop\n# -------------\n# Returns True or False if k-means is done. K-means terminates either\n# because it has run a maximum number of iterations OR the centroids\n# stop changing.\ndef shouldStop(oldCentroids, centroids, iterations, maxIt):\n    if iterations > maxIt:\n        return True\n    return np.array_equal(oldCentroids, centroids)  \n# Function: Get Labels\n# -------------\n# Update a label for each piece of data in the dataset. \ndef updateLabels(dataSet, centroids):\n    # For each element in the dataset, chose the closest centroid. \n    # Make that centroid the element's label.\n    numPoints, numDim = dataSet.shape\n    for i in range(0, numPoints):\n        dataSet[i, -1] = getLabelFromClosestCentroid(dataSet[i, :-1], centroids)\n    \n    \ndef getLabelFromClosestCentroid(dataSetRow, centroids):\n    label = centroids[0, -1];\n    minDist = np.linalg.norm(dataSetRow - centroids[0, :-1])\n    for i in range(1 , centroids.shape[0]):\n        dist = np.linalg.norm(dataSetRow - centroids[i, :-1])\n        if dist < minDist:\n            minDist = dist\n            label = centroids[i, -1]\n    print \"minDist:\", minDist\n    return label\n    \n        \n    \n# Function: Get Centroids\n# -------------\n# Returns k random centroids, each of dimension n.\ndef getCentroids(dataSet, k):\n    # Each centroid is the geometric mean of the points that\n    # have that centroid's label. Important: If a centroid is empty (no points have\n    # that centroid's label) you should randomly re-initialize it.\n    result = np.zeros((k, dataSet.shape[1]))\n    for i in range(1, k + 1):\n        oneCluster = dataSet[dataSet[:, -1] == i, :-1]\n        result[i - 1, :-1] = np.mean(oneCluster, axis = 0)\n        result[i - 1, -1] = i\n    \n    return result\n    \n    \nx1 = np.array([1, 1])\nx2 = np.array([2, 1])\nx3 = np.array([4, 3])\nx4 = np.array([5, 4])\ntestX = np.vstack((x1, x2, x3, x4))\n\nresult = kmeans(testX, 2, 10)\nprint \"final result:\"\nprint result\n```\n打印结果均为[1,1],[2,1]为一组，[4，3][5,4]为一组，与手算结果一致 ","source":"_posts/2017-9-18-one.md","raw":"---\ntitle: 机器学习笔记（二十一）聚类(Clustering) K-means算法应用\ndate: 2017-09-18 09:51:50\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\nKMeans聚类算法python代码：\n<!-- more -->\n``` bash\nimport numpy as np\n\n# Function: K Means\n# -------------\n# K-Means is an algorithm that takes in a dataset and a constant\n# k and returns k centroids (which define clusters of data in the\n# dataset which are similar to one another).\ndef kmeans(X, k, maxIt):\n    \n    numPoints, numDim = X.shape\n    \n    dataSet = np.zeros((numPoints, numDim + 1))\n    dataSet[:, :-1] = X\n    \n    # Initialize centroids randomly\n    centroids = dataSet[np.random.randint(numPoints, size = k), :]\n    centroids = dataSet[0:2, :]\n    #Randomly assign labels to initial centorid\n    centroids[:, -1] = range(1, k +1)\n    \n    # Initialize book keeping vars.\n    iterations = 0\n    oldCentroids = None\n    \n    # Run the main k-means algorithm\n    while not shouldStop(oldCentroids, centroids, iterations, maxIt):\n        print \"iteration: \\n\", iterations\n        print \"dataSet: \\n\", dataSet\n        print \"centroids: \\n\", centroids\n        # Save old centroids for convergence test. Book keeping.\n        oldCentroids = np.copy(centroids)\n        iterations += 1\n        \n        # Assign labels to each datapoint based on centroids\n        updateLabels(dataSet, centroids)\n        \n        # Assign centroids based on datapoint labels\n        centroids = getCentroids(dataSet, k)\n        \n    # We can get the labels too by calling getLabels(dataSet, centroids)\n    return dataSet\n# Function: Should Stop\n# -------------\n# Returns True or False if k-means is done. K-means terminates either\n# because it has run a maximum number of iterations OR the centroids\n# stop changing.\ndef shouldStop(oldCentroids, centroids, iterations, maxIt):\n    if iterations > maxIt:\n        return True\n    return np.array_equal(oldCentroids, centroids)  \n# Function: Get Labels\n# -------------\n# Update a label for each piece of data in the dataset. \ndef updateLabels(dataSet, centroids):\n    # For each element in the dataset, chose the closest centroid. \n    # Make that centroid the element's label.\n    numPoints, numDim = dataSet.shape\n    for i in range(0, numPoints):\n        dataSet[i, -1] = getLabelFromClosestCentroid(dataSet[i, :-1], centroids)\n    \n    \ndef getLabelFromClosestCentroid(dataSetRow, centroids):\n    label = centroids[0, -1];\n    minDist = np.linalg.norm(dataSetRow - centroids[0, :-1])\n    for i in range(1 , centroids.shape[0]):\n        dist = np.linalg.norm(dataSetRow - centroids[i, :-1])\n        if dist < minDist:\n            minDist = dist\n            label = centroids[i, -1]\n    print \"minDist:\", minDist\n    return label\n    \n        \n    \n# Function: Get Centroids\n# -------------\n# Returns k random centroids, each of dimension n.\ndef getCentroids(dataSet, k):\n    # Each centroid is the geometric mean of the points that\n    # have that centroid's label. Important: If a centroid is empty (no points have\n    # that centroid's label) you should randomly re-initialize it.\n    result = np.zeros((k, dataSet.shape[1]))\n    for i in range(1, k + 1):\n        oneCluster = dataSet[dataSet[:, -1] == i, :-1]\n        result[i - 1, :-1] = np.mean(oneCluster, axis = 0)\n        result[i - 1, -1] = i\n    \n    return result\n    \n    \nx1 = np.array([1, 1])\nx2 = np.array([2, 1])\nx3 = np.array([4, 3])\nx4 = np.array([5, 4])\ntestX = np.vstack((x1, x2, x3, x4))\n\nresult = kmeans(testX, 2, 10)\nprint \"final result:\"\nprint result\n```\n打印结果均为[1,1],[2,1]为一组，[4，3][5,4]为一组，与手算结果一致 ","slug":"2017-9-18-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va3h0025ycvjhtecjcrf","content":"<p>KMeans聚类算法python代码：<br><a id=\"more\"></a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Function: K Means</span></span><br><span class=\"line\"><span class=\"comment\"># -------------</span></span><br><span class=\"line\"><span class=\"comment\"># K-Means is an algorithm that takes in a dataset and a constant</span></span><br><span class=\"line\"><span class=\"comment\"># k and returns k centroids (which define clusters of data in the</span></span><br><span class=\"line\"><span class=\"comment\"># dataset which are similar to one another).</span></span><br><span class=\"line\">def kmeans(X, k, maxIt):</span><br><span class=\"line\">    </span><br><span class=\"line\">    numPoints, numDim = X.shape</span><br><span class=\"line\">    </span><br><span class=\"line\">    dataSet = np.zeros((numPoints, numDim + 1))</span><br><span class=\"line\">    dataSet[:, :-1] = X</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize centroids randomly</span></span><br><span class=\"line\">    centroids = dataSet[np.random.randint(numPoints, size = k), :]</span><br><span class=\"line\">    centroids = dataSet[0:2, :]</span><br><span class=\"line\">    <span class=\"comment\">#Randomly assign labels to initial centorid</span></span><br><span class=\"line\">    centroids[:, -1] = range(1, k +1)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize book keeping vars.</span></span><br><span class=\"line\">    iterations = 0</span><br><span class=\"line\">    oldCentroids = None</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Run the main k-means algorithm</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> not shouldStop(oldCentroids, centroids, iterations, maxIt):</span><br><span class=\"line\">        <span class=\"built_in\">print</span> <span class=\"string\">\"iteration: \\n\"</span>, iterations</span><br><span class=\"line\">        <span class=\"built_in\">print</span> <span class=\"string\">\"dataSet: \\n\"</span>, dataSet</span><br><span class=\"line\">        <span class=\"built_in\">print</span> <span class=\"string\">\"centroids: \\n\"</span>, centroids</span><br><span class=\"line\">        <span class=\"comment\"># Save old centroids for convergence test. Book keeping.</span></span><br><span class=\"line\">        oldCentroids = np.copy(centroids)</span><br><span class=\"line\">        iterations += 1</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># Assign labels to each datapoint based on centroids</span></span><br><span class=\"line\">        updateLabels(dataSet, centroids)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># Assign centroids based on datapoint labels</span></span><br><span class=\"line\">        centroids = getCentroids(dataSet, k)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"comment\"># We can get the labels too by calling getLabels(dataSet, centroids)</span></span><br><span class=\"line\">    <span class=\"built_in\">return</span> dataSet</span><br><span class=\"line\"><span class=\"comment\"># Function: Should Stop</span></span><br><span class=\"line\"><span class=\"comment\"># -------------</span></span><br><span class=\"line\"><span class=\"comment\"># Returns True or False if k-means is done. K-means terminates either</span></span><br><span class=\"line\"><span class=\"comment\"># because it has run a maximum number of iterations OR the centroids</span></span><br><span class=\"line\"><span class=\"comment\"># stop changing.</span></span><br><span class=\"line\">def shouldStop(oldCentroids, centroids, iterations, maxIt):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> iterations &gt; maxIt:</span><br><span class=\"line\">        <span class=\"built_in\">return</span> True</span><br><span class=\"line\">    <span class=\"built_in\">return</span> np.array_equal(oldCentroids, centroids)  </span><br><span class=\"line\"><span class=\"comment\"># Function: Get Labels</span></span><br><span class=\"line\"><span class=\"comment\"># -------------</span></span><br><span class=\"line\"><span class=\"comment\"># Update a label for each piece of data in the dataset. </span></span><br><span class=\"line\">def updateLabels(dataSet, centroids):</span><br><span class=\"line\">    <span class=\"comment\"># For each element in the dataset, chose the closest centroid. </span></span><br><span class=\"line\">    <span class=\"comment\"># Make that centroid the element's label.</span></span><br><span class=\"line\">    numPoints, numDim = dataSet.shape</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0, numPoints):</span><br><span class=\"line\">        dataSet[i, -1] = getLabelFromClosestCentroid(dataSet[i, :-1], centroids)</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">def getLabelFromClosestCentroid(dataSetRow, centroids):</span><br><span class=\"line\">    label = centroids[0, -1];</span><br><span class=\"line\">    minDist = np.linalg.norm(dataSetRow - centroids[0, :-1])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1 , centroids.shape[0]):</span><br><span class=\"line\">        dist = np.linalg.norm(dataSetRow - centroids[i, :-1])</span><br><span class=\"line\">        <span class=\"keyword\">if</span> dist &lt; minDist:</span><br><span class=\"line\">            minDist = dist</span><br><span class=\"line\">            label = centroids[i, -1]</span><br><span class=\"line\">    <span class=\"built_in\">print</span> <span class=\"string\">\"minDist:\"</span>, minDist</span><br><span class=\"line\">    <span class=\"built_in\">return</span> label</span><br><span class=\"line\">    </span><br><span class=\"line\">        </span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># Function: Get Centroids</span></span><br><span class=\"line\"><span class=\"comment\"># -------------</span></span><br><span class=\"line\"><span class=\"comment\"># Returns k random centroids, each of dimension n.</span></span><br><span class=\"line\">def getCentroids(dataSet, k):</span><br><span class=\"line\">    <span class=\"comment\"># Each centroid is the geometric mean of the points that</span></span><br><span class=\"line\">    <span class=\"comment\"># have that centroid's label. Important: If a centroid is empty (no points have</span></span><br><span class=\"line\">    <span class=\"comment\"># that centroid's label) you should randomly re-initialize it.</span></span><br><span class=\"line\">    result = np.zeros((k, dataSet.shape[1]))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1, k + 1):</span><br><span class=\"line\">        oneCluster = dataSet[dataSet[:, -1] == i, :-1]</span><br><span class=\"line\">        result[i - 1, :-1] = np.mean(oneCluster, axis = 0)</span><br><span class=\"line\">        result[i - 1, -1] = i</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">return</span> result</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">x1 = np.array([1, 1])</span><br><span class=\"line\">x2 = np.array([2, 1])</span><br><span class=\"line\">x3 = np.array([4, 3])</span><br><span class=\"line\">x4 = np.array([5, 4])</span><br><span class=\"line\">testX = np.vstack((x1, x2, x3, x4))</span><br><span class=\"line\"></span><br><span class=\"line\">result = kmeans(testX, 2, 10)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"final result:\"</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> result</span><br></pre></td></tr></table></figure></p>\n<p>打印结果均为[1,1],[2,1]为一组，[4，3][5,4]为一组，与手算结果一致 </p>\n","site":{"data":{}},"excerpt":"<p>KMeans聚类算法python代码：<br></p>","more":"<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Function: K Means</span></span><br><span class=\"line\"><span class=\"comment\"># -------------</span></span><br><span class=\"line\"><span class=\"comment\"># K-Means is an algorithm that takes in a dataset and a constant</span></span><br><span class=\"line\"><span class=\"comment\"># k and returns k centroids (which define clusters of data in the</span></span><br><span class=\"line\"><span class=\"comment\"># dataset which are similar to one another).</span></span><br><span class=\"line\">def kmeans(X, k, maxIt):</span><br><span class=\"line\">    </span><br><span class=\"line\">    numPoints, numDim = X.shape</span><br><span class=\"line\">    </span><br><span class=\"line\">    dataSet = np.zeros((numPoints, numDim + 1))</span><br><span class=\"line\">    dataSet[:, :-1] = X</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize centroids randomly</span></span><br><span class=\"line\">    centroids = dataSet[np.random.randint(numPoints, size = k), :]</span><br><span class=\"line\">    centroids = dataSet[0:2, :]</span><br><span class=\"line\">    <span class=\"comment\">#Randomly assign labels to initial centorid</span></span><br><span class=\"line\">    centroids[:, -1] = range(1, k +1)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Initialize book keeping vars.</span></span><br><span class=\"line\">    iterations = 0</span><br><span class=\"line\">    oldCentroids = None</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Run the main k-means algorithm</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> not shouldStop(oldCentroids, centroids, iterations, maxIt):</span><br><span class=\"line\">        <span class=\"built_in\">print</span> <span class=\"string\">\"iteration: \\n\"</span>, iterations</span><br><span class=\"line\">        <span class=\"built_in\">print</span> <span class=\"string\">\"dataSet: \\n\"</span>, dataSet</span><br><span class=\"line\">        <span class=\"built_in\">print</span> <span class=\"string\">\"centroids: \\n\"</span>, centroids</span><br><span class=\"line\">        <span class=\"comment\"># Save old centroids for convergence test. Book keeping.</span></span><br><span class=\"line\">        oldCentroids = np.copy(centroids)</span><br><span class=\"line\">        iterations += 1</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># Assign labels to each datapoint based on centroids</span></span><br><span class=\"line\">        updateLabels(dataSet, centroids)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># Assign centroids based on datapoint labels</span></span><br><span class=\"line\">        centroids = getCentroids(dataSet, k)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"comment\"># We can get the labels too by calling getLabels(dataSet, centroids)</span></span><br><span class=\"line\">    <span class=\"built_in\">return</span> dataSet</span><br><span class=\"line\"><span class=\"comment\"># Function: Should Stop</span></span><br><span class=\"line\"><span class=\"comment\"># -------------</span></span><br><span class=\"line\"><span class=\"comment\"># Returns True or False if k-means is done. K-means terminates either</span></span><br><span class=\"line\"><span class=\"comment\"># because it has run a maximum number of iterations OR the centroids</span></span><br><span class=\"line\"><span class=\"comment\"># stop changing.</span></span><br><span class=\"line\">def shouldStop(oldCentroids, centroids, iterations, maxIt):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> iterations &gt; maxIt:</span><br><span class=\"line\">        <span class=\"built_in\">return</span> True</span><br><span class=\"line\">    <span class=\"built_in\">return</span> np.array_equal(oldCentroids, centroids)  </span><br><span class=\"line\"><span class=\"comment\"># Function: Get Labels</span></span><br><span class=\"line\"><span class=\"comment\"># -------------</span></span><br><span class=\"line\"><span class=\"comment\"># Update a label for each piece of data in the dataset. </span></span><br><span class=\"line\">def updateLabels(dataSet, centroids):</span><br><span class=\"line\">    <span class=\"comment\"># For each element in the dataset, chose the closest centroid. </span></span><br><span class=\"line\">    <span class=\"comment\"># Make that centroid the element's label.</span></span><br><span class=\"line\">    numPoints, numDim = dataSet.shape</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0, numPoints):</span><br><span class=\"line\">        dataSet[i, -1] = getLabelFromClosestCentroid(dataSet[i, :-1], centroids)</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">def getLabelFromClosestCentroid(dataSetRow, centroids):</span><br><span class=\"line\">    label = centroids[0, -1];</span><br><span class=\"line\">    minDist = np.linalg.norm(dataSetRow - centroids[0, :-1])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1 , centroids.shape[0]):</span><br><span class=\"line\">        dist = np.linalg.norm(dataSetRow - centroids[i, :-1])</span><br><span class=\"line\">        <span class=\"keyword\">if</span> dist &lt; minDist:</span><br><span class=\"line\">            minDist = dist</span><br><span class=\"line\">            label = centroids[i, -1]</span><br><span class=\"line\">    <span class=\"built_in\">print</span> <span class=\"string\">\"minDist:\"</span>, minDist</span><br><span class=\"line\">    <span class=\"built_in\">return</span> label</span><br><span class=\"line\">    </span><br><span class=\"line\">        </span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># Function: Get Centroids</span></span><br><span class=\"line\"><span class=\"comment\"># -------------</span></span><br><span class=\"line\"><span class=\"comment\"># Returns k random centroids, each of dimension n.</span></span><br><span class=\"line\">def getCentroids(dataSet, k):</span><br><span class=\"line\">    <span class=\"comment\"># Each centroid is the geometric mean of the points that</span></span><br><span class=\"line\">    <span class=\"comment\"># have that centroid's label. Important: If a centroid is empty (no points have</span></span><br><span class=\"line\">    <span class=\"comment\"># that centroid's label) you should randomly re-initialize it.</span></span><br><span class=\"line\">    result = np.zeros((k, dataSet.shape[1]))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(1, k + 1):</span><br><span class=\"line\">        oneCluster = dataSet[dataSet[:, -1] == i, :-1]</span><br><span class=\"line\">        result[i - 1, :-1] = np.mean(oneCluster, axis = 0)</span><br><span class=\"line\">        result[i - 1, -1] = i</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">return</span> result</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">x1 = np.array([1, 1])</span><br><span class=\"line\">x2 = np.array([2, 1])</span><br><span class=\"line\">x3 = np.array([4, 3])</span><br><span class=\"line\">x4 = np.array([5, 4])</span><br><span class=\"line\">testX = np.vstack((x1, x2, x3, x4))</span><br><span class=\"line\"></span><br><span class=\"line\">result = kmeans(testX, 2, 10)</span><br><span class=\"line\"><span class=\"built_in\">print</span> <span class=\"string\">\"final result:\"</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> result</span><br></pre></td></tr></table></figure><p></p>\n<p>打印结果均为[1,1],[2,1]为一组，[4，3][5,4]为一组，与手算结果一致 </p>"},{"title":"机器学习笔记（二十二）hierarchical clustering 层次聚类","date":"2017-09-21T07:12:50.000Z","comments":1,"reward":true,"mathjax":true,"_content":"假设有N个待聚类的样本，对于层次聚类来说，步骤：\n1、（初始化）把每个样本归为一类，计算每两个类之间的距离，也就是样本与样本之间的相似度；\n2、寻找各个类之间最近的两个类，把他们归为一类（这样类的总数就少了一个）；\n3、重新计算新生成的这个类与各个旧类之间的相似度；\n4、重复2和3直到所有样本点都归为一类，结束\n<!-- more -->\n![](2017-9-21-one/1.png) \n整个聚类过程其实是建立了一棵树，在建立的过程中，可以通过在第二步上设置一个阈值，当最近的两个类的距离大于这个阈值，则认为迭代可以终止。另外关键的一步就是第三步，如何判断两个类之间的相似度有不少种方法。这里介绍一下三种：\nSingleLinkage：又叫做 nearest-neighbor ，就是取两个类中距离最近的两个样本的距离作为这两个集合的距离，也就是说，最近两个样本之间的距离越小，这两个类之间的相似度就越大。容易造成一种叫做 Chaining 的效果，两个 cluster 明明从“大局”上离得比较远，但是由于其中个别的点距离比较近就被合并了，并且这样合并之后 Chaining 效应会进一步扩大，最后会得到比较松散的 cluster 。\nCompleteLinkage：这个则完全是 Single Linkage 的反面极端，取两个集合中距离最远的两个点的距离作为两个集合的距离。其效果也是刚好相反的，限制非常大，两个 cluster 即使已经很接近了，但是只要有不配合的点存在，就顽固到底，老死不相合并，也是不太好的办法。这两种相似度的定义方法的共同问题就是指考虑了某个有特点的数据，而没有考虑类内数据的整体特点。\nAverage-linkage：这种方法就是把两个集合中的点两两的距离全部放在一起求一个平均值，相对也能得到合适一点的结果。\naverage-linkage的一个变种就是取两两距离的中值，与取均值相比更加能够解除个别偏离样本对结果的干扰。\n","source":"_posts/2017-9-21-one.md","raw":"---\ntitle: 机器学习笔记（二十二）hierarchical clustering 层次聚类\ndate: 2017-09-21 15:12:50\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\n假设有N个待聚类的样本，对于层次聚类来说，步骤：\n1、（初始化）把每个样本归为一类，计算每两个类之间的距离，也就是样本与样本之间的相似度；\n2、寻找各个类之间最近的两个类，把他们归为一类（这样类的总数就少了一个）；\n3、重新计算新生成的这个类与各个旧类之间的相似度；\n4、重复2和3直到所有样本点都归为一类，结束\n<!-- more -->\n![](2017-9-21-one/1.png) \n整个聚类过程其实是建立了一棵树，在建立的过程中，可以通过在第二步上设置一个阈值，当最近的两个类的距离大于这个阈值，则认为迭代可以终止。另外关键的一步就是第三步，如何判断两个类之间的相似度有不少种方法。这里介绍一下三种：\nSingleLinkage：又叫做 nearest-neighbor ，就是取两个类中距离最近的两个样本的距离作为这两个集合的距离，也就是说，最近两个样本之间的距离越小，这两个类之间的相似度就越大。容易造成一种叫做 Chaining 的效果，两个 cluster 明明从“大局”上离得比较远，但是由于其中个别的点距离比较近就被合并了，并且这样合并之后 Chaining 效应会进一步扩大，最后会得到比较松散的 cluster 。\nCompleteLinkage：这个则完全是 Single Linkage 的反面极端，取两个集合中距离最远的两个点的距离作为两个集合的距离。其效果也是刚好相反的，限制非常大，两个 cluster 即使已经很接近了，但是只要有不配合的点存在，就顽固到底，老死不相合并，也是不太好的办法。这两种相似度的定义方法的共同问题就是指考虑了某个有特点的数据，而没有考虑类内数据的整体特点。\nAverage-linkage：这种方法就是把两个集合中的点两两的距离全部放在一起求一个平均值，相对也能得到合适一点的结果。\naverage-linkage的一个变种就是取两两距离的中值，与取均值相比更加能够解除个别偏离样本对结果的干扰。\n","slug":"2017-9-21-one","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va3h0027ycvjyt5n17uc","content":"<p>假设有N个待聚类的样本，对于层次聚类来说，步骤：<br>1、（初始化）把每个样本归为一类，计算每两个类之间的距离，也就是样本与样本之间的相似度；<br>2、寻找各个类之间最近的两个类，把他们归为一类（这样类的总数就少了一个）；<br>3、重新计算新生成的这个类与各个旧类之间的相似度；<br>4、重复2和3直到所有样本点都归为一类，结束<br><a id=\"more\"></a><br><img src=\"/2017/09/21/2017-9-21-one/1.png\" alt=\"\"><br>整个聚类过程其实是建立了一棵树，在建立的过程中，可以通过在第二步上设置一个阈值，当最近的两个类的距离大于这个阈值，则认为迭代可以终止。另外关键的一步就是第三步，如何判断两个类之间的相似度有不少种方法。这里介绍一下三种：<br>SingleLinkage：又叫做 nearest-neighbor ，就是取两个类中距离最近的两个样本的距离作为这两个集合的距离，也就是说，最近两个样本之间的距离越小，这两个类之间的相似度就越大。容易造成一种叫做 Chaining 的效果，两个 cluster 明明从“大局”上离得比较远，但是由于其中个别的点距离比较近就被合并了，并且这样合并之后 Chaining 效应会进一步扩大，最后会得到比较松散的 cluster 。<br>CompleteLinkage：这个则完全是 Single Linkage 的反面极端，取两个集合中距离最远的两个点的距离作为两个集合的距离。其效果也是刚好相反的，限制非常大，两个 cluster 即使已经很接近了，但是只要有不配合的点存在，就顽固到底，老死不相合并，也是不太好的办法。这两种相似度的定义方法的共同问题就是指考虑了某个有特点的数据，而没有考虑类内数据的整体特点。<br>Average-linkage：这种方法就是把两个集合中的点两两的距离全部放在一起求一个平均值，相对也能得到合适一点的结果。<br>average-linkage的一个变种就是取两两距离的中值，与取均值相比更加能够解除个别偏离样本对结果的干扰。</p>\n","site":{"data":{}},"excerpt":"<p>假设有N个待聚类的样本，对于层次聚类来说，步骤：<br>1、（初始化）把每个样本归为一类，计算每两个类之间的距离，也就是样本与样本之间的相似度；<br>2、寻找各个类之间最近的两个类，把他们归为一类（这样类的总数就少了一个）；<br>3、重新计算新生成的这个类与各个旧类之间的相似度；<br>4、重复2和3直到所有样本点都归为一类，结束<br></p>","more":"<br><img src=\"/2017/09/21/2017-9-21-one/1.png\" alt=\"\"><br>整个聚类过程其实是建立了一棵树，在建立的过程中，可以通过在第二步上设置一个阈值，当最近的两个类的距离大于这个阈值，则认为迭代可以终止。另外关键的一步就是第三步，如何判断两个类之间的相似度有不少种方法。这里介绍一下三种：<br>SingleLinkage：又叫做 nearest-neighbor ，就是取两个类中距离最近的两个样本的距离作为这两个集合的距离，也就是说，最近两个样本之间的距离越小，这两个类之间的相似度就越大。容易造成一种叫做 Chaining 的效果，两个 cluster 明明从“大局”上离得比较远，但是由于其中个别的点距离比较近就被合并了，并且这样合并之后 Chaining 效应会进一步扩大，最后会得到比较松散的 cluster 。<br>CompleteLinkage：这个则完全是 Single Linkage 的反面极端，取两个集合中距离最远的两个点的距离作为两个集合的距离。其效果也是刚好相反的，限制非常大，两个 cluster 即使已经很接近了，但是只要有不配合的点存在，就顽固到底，老死不相合并，也是不太好的办法。这两种相似度的定义方法的共同问题就是指考虑了某个有特点的数据，而没有考虑类内数据的整体特点。<br>Average-linkage：这种方法就是把两个集合中的点两两的距离全部放在一起求一个平均值，相对也能得到合适一点的结果。<br>average-linkage的一个变种就是取两两距离的中值，与取均值相比更加能够解除个别偏离样本对结果的干扰。<p></p>"},{"title":"机器学习笔记（二十三） hierarchical clustering 层次聚类应用（完）","date":"2017-09-21T07:27:19.000Z","comments":1,"reward":true,"mathjax":true,"_content":"hierarchical clustering聚类算法python代码：\nHierarchicalClustering.py\n<!-- more -->\n``` bash\nfrom numpy import *\n\n\"\"\"\nCode for hierarchical clustering, modified from \nProgramming Collective Intelligence by Toby Segaran \n(O'Reilly Media 2007, page 33). \n\"\"\"\n\nclass cluster_node:\n    def __init__(self,vec,left=None,right=None,distance=0.0,id=None,count=1):\n        self.left=left\n        self.right=right\n        self.vec=vec\n        self.id=id\n        self.distance=distance\n        self.count=count #only used for weighted average \n\ndef L2dist(v1,v2):\n    return sqrt(sum((v1-v2)**2))\n    \ndef L1dist(v1,v2):\n    return sum(abs(v1-v2))\n\n# def Chi2dist(v1,v2):\n#     return sqrt(sum((v1-v2)**2))\n\ndef hcluster(features,distance=L2dist):\n    #cluster the rows of the \"features\" matrix\n    distances={}\n    currentclustid=-1\n\n    # clusters are initially just the individual rows\n    clust=[cluster_node(array(features[i]),id=i) for i in range(len(features))]\n\n    while len(clust)>1:\n        lowestpair=(0,1)\n        closest=distance(clust[0].vec,clust[1].vec)\n    \n        # loop through every pair looking for the smallest distance\n        for i in range(len(clust)):\n            for j in range(i+1,len(clust)):\n                # distances is the cache of distance calculations\n                if (clust[i].id,clust[j].id) not in distances: \n                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n        \n                d=distances[(clust[i].id,clust[j].id)]\n        \n                if d<closest:\n                    closest=d\n                    lowestpair=(i,j)\n        \n        # calculate the average of the two clusters\n        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 \\\n            for i in range(len(clust[0].vec))]\n        \n        # create the new cluster\n        newcluster=cluster_node(array(mergevec),left=clust[lowestpair[0]],\n                             right=clust[lowestpair[1]],\n                             distance=closest,id=currentclustid)\n        \n        # cluster ids that weren't in the original set are negative\n        currentclustid-=1\n        del clust[lowestpair[1]]\n        del clust[lowestpair[0]]\n        clust.append(newcluster)\n\n    return clust[0]\n\n\ndef extract_clusters(clust,dist):\n    # extract list of sub-tree clusters from hcluster tree with distance<dist\n    clusters = {}\n    if clust.distance<dist:\n        # we have found a cluster subtree\n        return [clust] \n    else:\n        # check the right and left branches\n        cl = []\n        cr = []\n        if clust.left!=None: \n            cl = extract_clusters(clust.left,dist=dist)\n        if clust.right!=None: \n            cr = extract_clusters(clust.right,dist=dist)\n        return cl+cr \n        \ndef get_cluster_elements(clust):\n    # return ids for elements in a cluster sub-tree\n    if clust.id>=0:\n        # positive id means that this is a leaf\n        return [clust.id]\n    else:\n        # check the right and left branches\n        cl = []\n        cr = []\n        if clust.left!=None: \n            cl = get_cluster_elements(clust.left)\n        if clust.right!=None: \n            cr = get_cluster_elements(clust.right)\n        return cl+cr\n\n\ndef printclust(clust,labels=None,n=0):\n    # indent to make a hierarchy layout\n    for i in range(n): print ' ',\n    if clust.id<0:\n        # negative id means that this is branch\n        print '-'\n    else:\n        # positive id means that this is an endpoint\n        if labels==None: print clust.id\n        else: print labels[clust.id]\n    \n    # now print the right and left branches\n    if clust.left!=None: printclust(clust.left,labels=labels,n=n+1)\n    if clust.right!=None: printclust(clust.right,labels=labels,n=n+1)\n\n\n\ndef getheight(clust):\n    # Is this an endpoint? Then the height is just 1\n    if clust.left==None and clust.right==None: return 1\n    \n    # Otherwise the height is the same of the heights of\n    # each branch\n    return getheight(clust.left)+getheight(clust.right)\n\ndef getdepth(clust):\n    # The distance of an endpoint is 0.0\n    if clust.left==None and clust.right==None: return 0\n    \n    # The distance of a branch is the greater of its two sides\n    # plus its own distance\n    return max(getdepth(clust.left),getdepth(clust.right))+clust.distance\n``` \nTestHClustering.py   \n``` bash\nimport os\nfrom PIL import Image , ImageDraw\nfrom HierarchicalClustering import hcluster\nfrom HierarchicalClustering import getheight\nfrom HierarchicalClustering import getdepth\n\nimport numpy as np\nimport os\n\ndef drawdendrogram(clust,imlist, jpeg='clusters.jpg'):\n    h=getheight(clust)*20\n    w=1200\n    depth=getdepth(clust)\n    scaling=float(w-150)/depth\n    img=Image.new('RGB',(w,h),(255, 255, 255))\n    draw=ImageDraw.Draw(img)\n    draw.line((0,h/2,10,h/2),fill=(255,0,0))\n    drawnode(draw, clust, 10, int(h/2), scaling, imlist, img)\n    img.save(jpeg)\n    \ndef drawnode(draw,clust, x, y, scaling,imlist,img):\n    if clust.id<0:\n        h1=getheight(clust.left)*20\n        h2=getheight(clust.right)*20\n        top=y-(h1+h2)/2\n        bottom=y+(h1+h2)/2\n        ll=clust.distance*scaling\n        draw.line((x,top+h1/2,x,bottom-h2/2),fill=(255,0,0))\n        draw.line((x,top+h1/2,x+ll,top+h1/2),fill=(255,0,0))\n        draw.line((x,bottom-h2/2,x+ll,bottom-h2/2),fill=(255,0,0))\n        drawnode(draw,clust.left,x+ll,top+h1/2,scaling,imlist,img)\n        drawnode(draw,clust.right,x+ll,bottom-h2/2,scaling,imlist,img)\n    else:\n        nodeim=Image.open(imlist[clust.id])\n        nodeim.thumbnail((20,20))\n        ns=nodeim.size\n        print x,y-ns[1]//2\n        print x+ns[0]\n        print\n        img.paste(nodeim,(int(x),int(y-ns[1]//2),int(x+ns[0]),int(y+ns[1]-ns[1]//2))) \nimlist=[]\nfolderPath=r'C:\\Users\\Administrator\\Desktop\\picture'\nfor filename in os.listdir(folderPath):\n    if os.path.splitext(filename)[1]=='.jpg':\n        imlist.append(os.path.join(folderPath,filename))\nn=len(imlist)\nfeatures = np.zeros((n,3))\nfor i in range(n):\n    im=np.array(Image.open(imlist[i]))\n    R=np.mean(im[:,:,0].flatten())\n    G=np.mean(im[:,:,1].flatten())\n    B=np.mean(im[:,:,2].flatten())\n    features[i]=np.array([R,G,B])\ntree=hcluster(features)\ndrawdendrogram(tree,imlist,jpeg='clusters.jpg')  \n``` \n归类结果：\n![](2017-9-21-two/1.jpg)","source":"_posts/2017-9-21-two.md","raw":"---\ntitle: 机器学习笔记（二十三） hierarchical clustering 层次聚类应用（完）\ndate: 2017-09-21 15:27:19\ncomments: true\nreward: true\nmathjax: true\ntags: \n - 机器学习\n---\nhierarchical clustering聚类算法python代码：\nHierarchicalClustering.py\n<!-- more -->\n``` bash\nfrom numpy import *\n\n\"\"\"\nCode for hierarchical clustering, modified from \nProgramming Collective Intelligence by Toby Segaran \n(O'Reilly Media 2007, page 33). \n\"\"\"\n\nclass cluster_node:\n    def __init__(self,vec,left=None,right=None,distance=0.0,id=None,count=1):\n        self.left=left\n        self.right=right\n        self.vec=vec\n        self.id=id\n        self.distance=distance\n        self.count=count #only used for weighted average \n\ndef L2dist(v1,v2):\n    return sqrt(sum((v1-v2)**2))\n    \ndef L1dist(v1,v2):\n    return sum(abs(v1-v2))\n\n# def Chi2dist(v1,v2):\n#     return sqrt(sum((v1-v2)**2))\n\ndef hcluster(features,distance=L2dist):\n    #cluster the rows of the \"features\" matrix\n    distances={}\n    currentclustid=-1\n\n    # clusters are initially just the individual rows\n    clust=[cluster_node(array(features[i]),id=i) for i in range(len(features))]\n\n    while len(clust)>1:\n        lowestpair=(0,1)\n        closest=distance(clust[0].vec,clust[1].vec)\n    \n        # loop through every pair looking for the smallest distance\n        for i in range(len(clust)):\n            for j in range(i+1,len(clust)):\n                # distances is the cache of distance calculations\n                if (clust[i].id,clust[j].id) not in distances: \n                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n        \n                d=distances[(clust[i].id,clust[j].id)]\n        \n                if d<closest:\n                    closest=d\n                    lowestpair=(i,j)\n        \n        # calculate the average of the two clusters\n        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 \\\n            for i in range(len(clust[0].vec))]\n        \n        # create the new cluster\n        newcluster=cluster_node(array(mergevec),left=clust[lowestpair[0]],\n                             right=clust[lowestpair[1]],\n                             distance=closest,id=currentclustid)\n        \n        # cluster ids that weren't in the original set are negative\n        currentclustid-=1\n        del clust[lowestpair[1]]\n        del clust[lowestpair[0]]\n        clust.append(newcluster)\n\n    return clust[0]\n\n\ndef extract_clusters(clust,dist):\n    # extract list of sub-tree clusters from hcluster tree with distance<dist\n    clusters = {}\n    if clust.distance<dist:\n        # we have found a cluster subtree\n        return [clust] \n    else:\n        # check the right and left branches\n        cl = []\n        cr = []\n        if clust.left!=None: \n            cl = extract_clusters(clust.left,dist=dist)\n        if clust.right!=None: \n            cr = extract_clusters(clust.right,dist=dist)\n        return cl+cr \n        \ndef get_cluster_elements(clust):\n    # return ids for elements in a cluster sub-tree\n    if clust.id>=0:\n        # positive id means that this is a leaf\n        return [clust.id]\n    else:\n        # check the right and left branches\n        cl = []\n        cr = []\n        if clust.left!=None: \n            cl = get_cluster_elements(clust.left)\n        if clust.right!=None: \n            cr = get_cluster_elements(clust.right)\n        return cl+cr\n\n\ndef printclust(clust,labels=None,n=0):\n    # indent to make a hierarchy layout\n    for i in range(n): print ' ',\n    if clust.id<0:\n        # negative id means that this is branch\n        print '-'\n    else:\n        # positive id means that this is an endpoint\n        if labels==None: print clust.id\n        else: print labels[clust.id]\n    \n    # now print the right and left branches\n    if clust.left!=None: printclust(clust.left,labels=labels,n=n+1)\n    if clust.right!=None: printclust(clust.right,labels=labels,n=n+1)\n\n\n\ndef getheight(clust):\n    # Is this an endpoint? Then the height is just 1\n    if clust.left==None and clust.right==None: return 1\n    \n    # Otherwise the height is the same of the heights of\n    # each branch\n    return getheight(clust.left)+getheight(clust.right)\n\ndef getdepth(clust):\n    # The distance of an endpoint is 0.0\n    if clust.left==None and clust.right==None: return 0\n    \n    # The distance of a branch is the greater of its two sides\n    # plus its own distance\n    return max(getdepth(clust.left),getdepth(clust.right))+clust.distance\n``` \nTestHClustering.py   \n``` bash\nimport os\nfrom PIL import Image , ImageDraw\nfrom HierarchicalClustering import hcluster\nfrom HierarchicalClustering import getheight\nfrom HierarchicalClustering import getdepth\n\nimport numpy as np\nimport os\n\ndef drawdendrogram(clust,imlist, jpeg='clusters.jpg'):\n    h=getheight(clust)*20\n    w=1200\n    depth=getdepth(clust)\n    scaling=float(w-150)/depth\n    img=Image.new('RGB',(w,h),(255, 255, 255))\n    draw=ImageDraw.Draw(img)\n    draw.line((0,h/2,10,h/2),fill=(255,0,0))\n    drawnode(draw, clust, 10, int(h/2), scaling, imlist, img)\n    img.save(jpeg)\n    \ndef drawnode(draw,clust, x, y, scaling,imlist,img):\n    if clust.id<0:\n        h1=getheight(clust.left)*20\n        h2=getheight(clust.right)*20\n        top=y-(h1+h2)/2\n        bottom=y+(h1+h2)/2\n        ll=clust.distance*scaling\n        draw.line((x,top+h1/2,x,bottom-h2/2),fill=(255,0,0))\n        draw.line((x,top+h1/2,x+ll,top+h1/2),fill=(255,0,0))\n        draw.line((x,bottom-h2/2,x+ll,bottom-h2/2),fill=(255,0,0))\n        drawnode(draw,clust.left,x+ll,top+h1/2,scaling,imlist,img)\n        drawnode(draw,clust.right,x+ll,bottom-h2/2,scaling,imlist,img)\n    else:\n        nodeim=Image.open(imlist[clust.id])\n        nodeim.thumbnail((20,20))\n        ns=nodeim.size\n        print x,y-ns[1]//2\n        print x+ns[0]\n        print\n        img.paste(nodeim,(int(x),int(y-ns[1]//2),int(x+ns[0]),int(y+ns[1]-ns[1]//2))) \nimlist=[]\nfolderPath=r'C:\\Users\\Administrator\\Desktop\\picture'\nfor filename in os.listdir(folderPath):\n    if os.path.splitext(filename)[1]=='.jpg':\n        imlist.append(os.path.join(folderPath,filename))\nn=len(imlist)\nfeatures = np.zeros((n,3))\nfor i in range(n):\n    im=np.array(Image.open(imlist[i]))\n    R=np.mean(im[:,:,0].flatten())\n    G=np.mean(im[:,:,1].flatten())\n    B=np.mean(im[:,:,2].flatten())\n    features[i]=np.array([R,G,B])\ntree=hcluster(features)\ndrawdendrogram(tree,imlist,jpeg='clusters.jpg')  \n``` \n归类结果：\n![](2017-9-21-two/1.jpg)","slug":"2017-9-21-two","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va3h0029ycvjdojs31kg","content":"<p>hierarchical clustering聚类算法python代码：<br>HierarchicalClustering.py<br><a id=\"more\"></a></p>\n<pre><code class=\"bash\">from numpy import *\n\n<span class=\"string\">\"\"</span><span class=\"string\">\"</span>\n<span class=\"string\">Code for hierarchical clustering, modified from </span>\n<span class=\"string\">Programming Collective Intelligence by Toby Segaran </span>\n<span class=\"string\">(O'Reilly Media 2007, page 33). </span>\n<span class=\"string\">\"</span><span class=\"string\">\"\"</span>\n\nclass cluster_node:\n    def __init__(self,vec,left=None,right=None,distance=0.0,id=None,count=1):\n        self.left=left\n        self.right=right\n        self.vec=vec\n        self.id=id\n        self.distance=distance\n        self.count=count <span class=\"comment\">#only used for weighted average </span>\n\ndef L2dist(v1,v2):\n    <span class=\"built_in\">return</span> sqrt(sum((v1-v2)**2))\n\ndef L1dist(v1,v2):\n    <span class=\"built_in\">return</span> sum(abs(v1-v2))\n\n<span class=\"comment\"># def Chi2dist(v1,v2):</span>\n<span class=\"comment\">#     return sqrt(sum((v1-v2)**2))</span>\n\ndef hcluster(features,distance=L2dist):\n    <span class=\"comment\">#cluster the rows of the \"features\" matrix</span>\n    distances={}\n    currentclustid=-1\n\n    <span class=\"comment\"># clusters are initially just the individual rows</span>\n    clust=[cluster_node(array(features[i]),id=i) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(features))]\n\n    <span class=\"keyword\">while</span> len(clust)&gt;1:\n        lowestpair=(0,1)\n        closest=distance(clust[0].vec,clust[1].vec)\n\n        <span class=\"comment\"># loop through every pair looking for the smallest distance</span>\n        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(clust)):\n            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(i+1,len(clust)):\n                <span class=\"comment\"># distances is the cache of distance calculations</span>\n                <span class=\"keyword\">if</span> (clust[i].id,clust[j].id) not <span class=\"keyword\">in</span> distances: \n                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n\n                d=distances[(clust[i].id,clust[j].id)]\n\n                <span class=\"keyword\">if</span> d&lt;closest:\n                    closest=d\n                    lowestpair=(i,j)\n\n        <span class=\"comment\"># calculate the average of the two clusters</span>\n        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 \\\n            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(clust[0].vec))]\n\n        <span class=\"comment\"># create the new cluster</span>\n        newcluster=cluster_node(array(mergevec),left=clust[lowestpair[0]],\n                             right=clust[lowestpair[1]],\n                             distance=closest,id=currentclustid)\n\n        <span class=\"comment\"># cluster ids that weren't in the original set are negative</span>\n        currentclustid-=1\n        del clust[lowestpair[1]]\n        del clust[lowestpair[0]]\n        clust.append(newcluster)\n\n    <span class=\"built_in\">return</span> clust[0]\n\n\ndef extract_clusters(clust,dist):\n    <span class=\"comment\"># extract list of sub-tree clusters from hcluster tree with distance&lt;dist</span>\n    clusters = {}\n    <span class=\"keyword\">if</span> clust.distance&lt;dist:\n        <span class=\"comment\"># we have found a cluster subtree</span>\n        <span class=\"built_in\">return</span> [clust] \n    <span class=\"keyword\">else</span>:\n        <span class=\"comment\"># check the right and left branches</span>\n        cl = []\n        cr = []\n        <span class=\"keyword\">if</span> clust.left!=None: \n            cl = extract_clusters(clust.left,dist=dist)\n        <span class=\"keyword\">if</span> clust.right!=None: \n            cr = extract_clusters(clust.right,dist=dist)\n        <span class=\"built_in\">return</span> cl+cr \n\ndef get_cluster_elements(clust):\n    <span class=\"comment\"># return ids for elements in a cluster sub-tree</span>\n    <span class=\"keyword\">if</span> clust.id&gt;=0:\n        <span class=\"comment\"># positive id means that this is a leaf</span>\n        <span class=\"built_in\">return</span> [clust.id]\n    <span class=\"keyword\">else</span>:\n        <span class=\"comment\"># check the right and left branches</span>\n        cl = []\n        cr = []\n        <span class=\"keyword\">if</span> clust.left!=None: \n            cl = get_cluster_elements(clust.left)\n        <span class=\"keyword\">if</span> clust.right!=None: \n            cr = get_cluster_elements(clust.right)\n        <span class=\"built_in\">return</span> cl+cr\n\n\ndef printclust(clust,labels=None,n=0):\n    <span class=\"comment\"># indent to make a hierarchy layout</span>\n    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n): <span class=\"built_in\">print</span> <span class=\"string\">' '</span>,\n    <span class=\"keyword\">if</span> clust.id&lt;0:\n        <span class=\"comment\"># negative id means that this is branch</span>\n        <span class=\"built_in\">print</span> <span class=\"string\">'-'</span>\n    <span class=\"keyword\">else</span>:\n        <span class=\"comment\"># positive id means that this is an endpoint</span>\n        <span class=\"keyword\">if</span> labels==None: <span class=\"built_in\">print</span> clust.id\n        <span class=\"keyword\">else</span>: <span class=\"built_in\">print</span> labels[clust.id]\n\n    <span class=\"comment\"># now print the right and left branches</span>\n    <span class=\"keyword\">if</span> clust.left!=None: printclust(clust.left,labels=labels,n=n+1)\n    <span class=\"keyword\">if</span> clust.right!=None: printclust(clust.right,labels=labels,n=n+1)\n\n\n\ndef getheight(clust):\n    <span class=\"comment\"># Is this an endpoint? Then the height is just 1</span>\n    <span class=\"keyword\">if</span> clust.left==None and clust.right==None: <span class=\"built_in\">return</span> 1\n\n    <span class=\"comment\"># Otherwise the height is the same of the heights of</span>\n    <span class=\"comment\"># each branch</span>\n    <span class=\"built_in\">return</span> getheight(clust.left)+getheight(clust.right)\n\ndef getdepth(clust):\n    <span class=\"comment\"># The distance of an endpoint is 0.0</span>\n    <span class=\"keyword\">if</span> clust.left==None and clust.right==None: <span class=\"built_in\">return</span> 0\n\n    <span class=\"comment\"># The distance of a branch is the greater of its two sides</span>\n    <span class=\"comment\"># plus its own distance</span>\n    <span class=\"built_in\">return</span> max(getdepth(clust.left),getdepth(clust.right))+clust.distance\n</code></pre>\n<p>TestHClustering.py   </p>\n<pre><code class=\"bash\">import os\nfrom PIL import Image , ImageDraw\nfrom HierarchicalClustering import hcluster\nfrom HierarchicalClustering import getheight\nfrom HierarchicalClustering import getdepth\n\nimport numpy as np\nimport os\n\ndef drawdendrogram(clust,imlist, jpeg=<span class=\"string\">'clusters.jpg'</span>):\n    h=getheight(clust)*20\n    w=1200\n    depth=getdepth(clust)\n    scaling=<span class=\"built_in\">float</span>(w-150)/depth\n    img=Image.new(<span class=\"string\">'RGB'</span>,(w,h),(255, 255, 255))\n    draw=ImageDraw.Draw(img)\n    draw.line((0,h/2,10,h/2),fill=(255,0,0))\n    drawnode(draw, clust, 10, int(h/2), scaling, imlist, img)\n    img.save(jpeg)\n\ndef drawnode(draw,clust, x, y, scaling,imlist,img):\n    <span class=\"keyword\">if</span> clust.id&lt;0:\n        h1=getheight(clust.left)*20\n        h2=getheight(clust.right)*20\n        top=y-(h1+h2)/2\n        bottom=y+(h1+h2)/2\n        ll=clust.distance*scaling\n        draw.line((x,top+h1/2,x,bottom-h2/2),fill=(255,0,0))\n        draw.line((x,top+h1/2,x+ll,top+h1/2),fill=(255,0,0))\n        draw.line((x,bottom-h2/2,x+ll,bottom-h2/2),fill=(255,0,0))\n        drawnode(draw,clust.left,x+ll,top+h1/2,scaling,imlist,img)\n        drawnode(draw,clust.right,x+ll,bottom-h2/2,scaling,imlist,img)\n    <span class=\"keyword\">else</span>:\n        nodeim=Image.open(imlist[clust.id])\n        nodeim.thumbnail((20,20))\n        ns=nodeim.size\n        <span class=\"built_in\">print</span> x,y-ns[1]//2\n        <span class=\"built_in\">print</span> x+ns[0]\n        <span class=\"built_in\">print</span>\n        img.paste(nodeim,(int(x),int(y-ns[1]//2),int(x+ns[0]),int(y+ns[1]-ns[1]//2))) \nimlist=[]\nfolderPath=r<span class=\"string\">'C:\\Users\\Administrator\\Desktop\\picture'</span>\n<span class=\"keyword\">for</span> filename <span class=\"keyword\">in</span> os.listdir(folderPath):\n    <span class=\"keyword\">if</span> os.path.splitext(filename)[1]==<span class=\"string\">'.jpg'</span>:\n        imlist.append(os.path.join(folderPath,filename))\nn=len(imlist)\nfeatures = np.zeros((n,3))\n<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):\n    im=np.array(Image.open(imlist[i]))\n    R=np.mean(im[:,:,0].flatten())\n    G=np.mean(im[:,:,1].flatten())\n    B=np.mean(im[:,:,2].flatten())\n    features[i]=np.array([R,G,B])\ntree=hcluster(features)\ndrawdendrogram(tree,imlist,jpeg=<span class=\"string\">'clusters.jpg'</span>)\n</code></pre>\n<p>归类结果：<br><img src=\"/2017/09/21/2017-9-21-two/1.jpg\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"<p>hierarchical clustering聚类算法python代码：<br>HierarchicalClustering.py<br></p>","more":"<p></p>\n<pre><code class=\"bash\">from numpy import *\n\n<span class=\"string\">\"\"</span><span class=\"string\">\"</span>\n<span class=\"string\">Code for hierarchical clustering, modified from </span>\n<span class=\"string\">Programming Collective Intelligence by Toby Segaran </span>\n<span class=\"string\">(O'Reilly Media 2007, page 33). </span>\n<span class=\"string\">\"</span><span class=\"string\">\"\"</span>\n\nclass cluster_node:\n    def __init__(self,vec,left=None,right=None,distance=0.0,id=None,count=1):\n        self.left=left\n        self.right=right\n        self.vec=vec\n        self.id=id\n        self.distance=distance\n        self.count=count <span class=\"comment\">#only used for weighted average </span>\n\ndef L2dist(v1,v2):\n    <span class=\"built_in\">return</span> sqrt(sum((v1-v2)**2))\n\ndef L1dist(v1,v2):\n    <span class=\"built_in\">return</span> sum(abs(v1-v2))\n\n<span class=\"comment\"># def Chi2dist(v1,v2):</span>\n<span class=\"comment\">#     return sqrt(sum((v1-v2)**2))</span>\n\ndef hcluster(features,distance=L2dist):\n    <span class=\"comment\">#cluster the rows of the \"features\" matrix</span>\n    distances={}\n    currentclustid=-1\n\n    <span class=\"comment\"># clusters are initially just the individual rows</span>\n    clust=[cluster_node(array(features[i]),id=i) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(features))]\n\n    <span class=\"keyword\">while</span> len(clust)&gt;1:\n        lowestpair=(0,1)\n        closest=distance(clust[0].vec,clust[1].vec)\n\n        <span class=\"comment\"># loop through every pair looking for the smallest distance</span>\n        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(clust)):\n            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(i+1,len(clust)):\n                <span class=\"comment\"># distances is the cache of distance calculations</span>\n                <span class=\"keyword\">if</span> (clust[i].id,clust[j].id) not <span class=\"keyword\">in</span> distances: \n                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n\n                d=distances[(clust[i].id,clust[j].id)]\n\n                <span class=\"keyword\">if</span> d&lt;closest:\n                    closest=d\n                    lowestpair=(i,j)\n\n        <span class=\"comment\"># calculate the average of the two clusters</span>\n        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 \\\n            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(clust[0].vec))]\n\n        <span class=\"comment\"># create the new cluster</span>\n        newcluster=cluster_node(array(mergevec),left=clust[lowestpair[0]],\n                             right=clust[lowestpair[1]],\n                             distance=closest,id=currentclustid)\n\n        <span class=\"comment\"># cluster ids that weren't in the original set are negative</span>\n        currentclustid-=1\n        del clust[lowestpair[1]]\n        del clust[lowestpair[0]]\n        clust.append(newcluster)\n\n    <span class=\"built_in\">return</span> clust[0]\n\n\ndef extract_clusters(clust,dist):\n    <span class=\"comment\"># extract list of sub-tree clusters from hcluster tree with distance&lt;dist</span>\n    clusters = {}\n    <span class=\"keyword\">if</span> clust.distance&lt;dist:\n        <span class=\"comment\"># we have found a cluster subtree</span>\n        <span class=\"built_in\">return</span> [clust] \n    <span class=\"keyword\">else</span>:\n        <span class=\"comment\"># check the right and left branches</span>\n        cl = []\n        cr = []\n        <span class=\"keyword\">if</span> clust.left!=None: \n            cl = extract_clusters(clust.left,dist=dist)\n        <span class=\"keyword\">if</span> clust.right!=None: \n            cr = extract_clusters(clust.right,dist=dist)\n        <span class=\"built_in\">return</span> cl+cr \n\ndef get_cluster_elements(clust):\n    <span class=\"comment\"># return ids for elements in a cluster sub-tree</span>\n    <span class=\"keyword\">if</span> clust.id&gt;=0:\n        <span class=\"comment\"># positive id means that this is a leaf</span>\n        <span class=\"built_in\">return</span> [clust.id]\n    <span class=\"keyword\">else</span>:\n        <span class=\"comment\"># check the right and left branches</span>\n        cl = []\n        cr = []\n        <span class=\"keyword\">if</span> clust.left!=None: \n            cl = get_cluster_elements(clust.left)\n        <span class=\"keyword\">if</span> clust.right!=None: \n            cr = get_cluster_elements(clust.right)\n        <span class=\"built_in\">return</span> cl+cr\n\n\ndef printclust(clust,labels=None,n=0):\n    <span class=\"comment\"># indent to make a hierarchy layout</span>\n    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n): <span class=\"built_in\">print</span> <span class=\"string\">' '</span>,\n    <span class=\"keyword\">if</span> clust.id&lt;0:\n        <span class=\"comment\"># negative id means that this is branch</span>\n        <span class=\"built_in\">print</span> <span class=\"string\">'-'</span>\n    <span class=\"keyword\">else</span>:\n        <span class=\"comment\"># positive id means that this is an endpoint</span>\n        <span class=\"keyword\">if</span> labels==None: <span class=\"built_in\">print</span> clust.id\n        <span class=\"keyword\">else</span>: <span class=\"built_in\">print</span> labels[clust.id]\n\n    <span class=\"comment\"># now print the right and left branches</span>\n    <span class=\"keyword\">if</span> clust.left!=None: printclust(clust.left,labels=labels,n=n+1)\n    <span class=\"keyword\">if</span> clust.right!=None: printclust(clust.right,labels=labels,n=n+1)\n\n\n\ndef getheight(clust):\n    <span class=\"comment\"># Is this an endpoint? Then the height is just 1</span>\n    <span class=\"keyword\">if</span> clust.left==None and clust.right==None: <span class=\"built_in\">return</span> 1\n\n    <span class=\"comment\"># Otherwise the height is the same of the heights of</span>\n    <span class=\"comment\"># each branch</span>\n    <span class=\"built_in\">return</span> getheight(clust.left)+getheight(clust.right)\n\ndef getdepth(clust):\n    <span class=\"comment\"># The distance of an endpoint is 0.0</span>\n    <span class=\"keyword\">if</span> clust.left==None and clust.right==None: <span class=\"built_in\">return</span> 0\n\n    <span class=\"comment\"># The distance of a branch is the greater of its two sides</span>\n    <span class=\"comment\"># plus its own distance</span>\n    <span class=\"built_in\">return</span> max(getdepth(clust.left),getdepth(clust.right))+clust.distance\n</code></pre>\n<p>TestHClustering.py   </p>\n<pre><code class=\"bash\">import os\nfrom PIL import Image , ImageDraw\nfrom HierarchicalClustering import hcluster\nfrom HierarchicalClustering import getheight\nfrom HierarchicalClustering import getdepth\n\nimport numpy as np\nimport os\n\ndef drawdendrogram(clust,imlist, jpeg=<span class=\"string\">'clusters.jpg'</span>):\n    h=getheight(clust)*20\n    w=1200\n    depth=getdepth(clust)\n    scaling=<span class=\"built_in\">float</span>(w-150)/depth\n    img=Image.new(<span class=\"string\">'RGB'</span>,(w,h),(255, 255, 255))\n    draw=ImageDraw.Draw(img)\n    draw.line((0,h/2,10,h/2),fill=(255,0,0))\n    drawnode(draw, clust, 10, int(h/2), scaling, imlist, img)\n    img.save(jpeg)\n\ndef drawnode(draw,clust, x, y, scaling,imlist,img):\n    <span class=\"keyword\">if</span> clust.id&lt;0:\n        h1=getheight(clust.left)*20\n        h2=getheight(clust.right)*20\n        top=y-(h1+h2)/2\n        bottom=y+(h1+h2)/2\n        ll=clust.distance*scaling\n        draw.line((x,top+h1/2,x,bottom-h2/2),fill=(255,0,0))\n        draw.line((x,top+h1/2,x+ll,top+h1/2),fill=(255,0,0))\n        draw.line((x,bottom-h2/2,x+ll,bottom-h2/2),fill=(255,0,0))\n        drawnode(draw,clust.left,x+ll,top+h1/2,scaling,imlist,img)\n        drawnode(draw,clust.right,x+ll,bottom-h2/2,scaling,imlist,img)\n    <span class=\"keyword\">else</span>:\n        nodeim=Image.open(imlist[clust.id])\n        nodeim.thumbnail((20,20))\n        ns=nodeim.size\n        <span class=\"built_in\">print</span> x,y-ns[1]//2\n        <span class=\"built_in\">print</span> x+ns[0]\n        <span class=\"built_in\">print</span>\n        img.paste(nodeim,(int(x),int(y-ns[1]//2),int(x+ns[0]),int(y+ns[1]-ns[1]//2))) \nimlist=[]\nfolderPath=r<span class=\"string\">'C:\\Users\\Administrator\\Desktop\\picture'</span>\n<span class=\"keyword\">for</span> filename <span class=\"keyword\">in</span> os.listdir(folderPath):\n    <span class=\"keyword\">if</span> os.path.splitext(filename)[1]==<span class=\"string\">'.jpg'</span>:\n        imlist.append(os.path.join(folderPath,filename))\nn=len(imlist)\nfeatures = np.zeros((n,3))\n<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):\n    im=np.array(Image.open(imlist[i]))\n    R=np.mean(im[:,:,0].flatten())\n    G=np.mean(im[:,:,1].flatten())\n    B=np.mean(im[:,:,2].flatten())\n    features[i]=np.array([R,G,B])\ntree=hcluster(features)\ndrawdendrogram(tree,imlist,jpeg=<span class=\"string\">'clusters.jpg'</span>)\n</code></pre>\n<p>归类结果：<br><img src=\"/2017/09/21/2017-9-21-two/1.jpg\" alt=\"\"></p>"},{"title":"Hexo博客在VSCode下编写及git配置问题","date":"2018-02-03T05:51:28.000Z","mathjax":true,"_content":"设置VSCode下git环境\n文件—首选项-设置\n用户设置下 添加git路径以及git-bash终端\n``` bash\n{\n    \"git.path\": \"D:\\\\Program Files\\\\Git\\\\cmd\",\n    \"terminal.integrated.shell.windows\":\"D:\\\\ProgramFiles\\\\Git\\\\bin\\\\bash.exe\",\n}\n```\n<!-- more -->\nPS:\n记录两天搭建环境过程中遇到的各种麻烦 好久不弄又出现一些新问题\n一、图片加载问题  \n下面给出hexo图片公式加载环境设置\n经过一番折腾发现加载图片必须满足一下条件  \n1、_config.yml中开启文件夹声明  \n`post_asset_folder: true`  \n2、npm安装图片插件  \n`npm install hexo-asset-image --save`  \n图片测试\n![](2018-02-03-one/1.jpg) \n二、公式加载问题  \n此处分为两个小问题  \n一是公式插件加载问题  \n二是markdown斜线注释问题  \n1、公式插件按照网上教程加载hexo-math不成功，所以另辟蹊径采用mathjax.ejs文件建立公式环境到主题目录下mathjax.ejs: \n``` bash\n<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n    tex2jax: {\n        inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"]  ],\n        processEscapes: true,\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n    }\n});\n\nMathJax.Hub.Queue(function() {\n    var all = MathJax.Hub.getAllJax(), i;\n    for(i=0; i < all.length; i += 1) {\n        all[i].SourceElement().parentNode.className += ' has-jax';                 \n    }       \n});\n</script>\n\n<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML\">\n</script>\n```\nsrc地址需要更新到mathjax接口最新地址\n然后加载启用判断在after_footer.ejs中  \n``` bash\n<% if (page.mathjax){ %>\n<%- partial('mathjax') %>\n<% } %>\n```\n2、斜线注释问题  \n在`node_modules\\marked\\lib\\marked.js`中修改两处代码这样无需替换markdown环境  \n将451行和459行的 \n``` bash \nescape: /^\\\\([\\\\`*{}\\[\\]()# +\\-.!_>])/  \nem: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/\n```\n替换为  \n``` bash\nescape: /^\\\\([`*\\[\\]()# +\\-.!_>])/\nem:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/\n```\n这样文章只要开启公式就可以加载公式  \n公式 test\n$a^2=b^2+c^2$\n\n","source":"_posts/2018-02-03-one.md","raw":"---\ntitle: Hexo博客在VSCode下编写及git配置问题\ndate: 2018-02-03 13:51:28\ntags: \n- Hexo\nmathjax: true\n---\n设置VSCode下git环境\n文件—首选项-设置\n用户设置下 添加git路径以及git-bash终端\n``` bash\n{\n    \"git.path\": \"D:\\\\Program Files\\\\Git\\\\cmd\",\n    \"terminal.integrated.shell.windows\":\"D:\\\\ProgramFiles\\\\Git\\\\bin\\\\bash.exe\",\n}\n```\n<!-- more -->\nPS:\n记录两天搭建环境过程中遇到的各种麻烦 好久不弄又出现一些新问题\n一、图片加载问题  \n下面给出hexo图片公式加载环境设置\n经过一番折腾发现加载图片必须满足一下条件  \n1、_config.yml中开启文件夹声明  \n`post_asset_folder: true`  \n2、npm安装图片插件  \n`npm install hexo-asset-image --save`  \n图片测试\n![](2018-02-03-one/1.jpg) \n二、公式加载问题  \n此处分为两个小问题  \n一是公式插件加载问题  \n二是markdown斜线注释问题  \n1、公式插件按照网上教程加载hexo-math不成功，所以另辟蹊径采用mathjax.ejs文件建立公式环境到主题目录下mathjax.ejs: \n``` bash\n<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n    tex2jax: {\n        inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"]  ],\n        processEscapes: true,\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n    }\n});\n\nMathJax.Hub.Queue(function() {\n    var all = MathJax.Hub.getAllJax(), i;\n    for(i=0; i < all.length; i += 1) {\n        all[i].SourceElement().parentNode.className += ' has-jax';                 \n    }       \n});\n</script>\n\n<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML\">\n</script>\n```\nsrc地址需要更新到mathjax接口最新地址\n然后加载启用判断在after_footer.ejs中  \n``` bash\n<% if (page.mathjax){ %>\n<%- partial('mathjax') %>\n<% } %>\n```\n2、斜线注释问题  \n在`node_modules\\marked\\lib\\marked.js`中修改两处代码这样无需替换markdown环境  \n将451行和459行的 \n``` bash \nescape: /^\\\\([\\\\`*{}\\[\\]()# +\\-.!_>])/  \nem: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/\n```\n替换为  \n``` bash\nescape: /^\\\\([`*\\[\\]()# +\\-.!_>])/\nem:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/\n```\n这样文章只要开启公式就可以加载公式  \n公式 test\n$a^2=b^2+c^2$\n\n","slug":"2018-02-03-one","published":1,"updated":"2018-02-03T07:54:59.140Z","_id":"cjd71va3h002bycvj8lubxlmz","comments":1,"layout":"post","photos":[],"link":"","content":"<p>设置VSCode下git环境<br>文件—首选项-设置<br>用户设置下 添加git路径以及git-bash终端<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"string\">\"git.path\"</span>: <span class=\"string\">\"D:\\\\Program Files\\\\Git\\\\cmd\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"terminal.integrated.shell.windows\"</span>:<span class=\"string\">\"D:\\\\ProgramFiles\\\\Git\\\\bin\\\\bash.exe\"</span>,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<p>PS:<br>记录两天搭建环境过程中遇到的各种麻烦 好久不弄又出现一些新问题<br>一、图片加载问题<br>下面给出hexo图片公式加载环境设置<br>经过一番折腾发现加载图片必须满足一下条件<br>1、_config.yml中开启文件夹声明<br><code>post_asset_folder: true</code><br>2、npm安装图片插件<br><code>npm install hexo-asset-image --save</code><br>图片测试<br><img src=\"/2018/02/03/2018-02-03-one/1.jpg\" alt=\"\"><br>二、公式加载问题<br>此处分为两个小问题<br>一是公式插件加载问题<br>二是markdown斜线注释问题<br>1、公式插件按照网上教程加载hexo-math不成功，所以另辟蹊径采用mathjax.ejs文件建立公式环境到主题目录下mathjax.ejs:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;script <span class=\"built_in\">type</span>=<span class=\"string\">\"text/x-mathjax-config\"</span>&gt;</span><br><span class=\"line\">MathJax.Hub.Config(&#123;</span><br><span class=\"line\">    tex2jax: &#123;</span><br><span class=\"line\">        inlineMath: [ [<span class=\"string\">'$'</span>,<span class=\"string\">'$'</span>], [<span class=\"string\">\"\\\\(\"</span>,<span class=\"string\">\"\\\\)\"</span>]  ],</span><br><span class=\"line\">        processEscapes: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        skipTags: [<span class=\"string\">'script'</span>, <span class=\"string\">'noscript'</span>, <span class=\"string\">'style'</span>, <span class=\"string\">'textarea'</span>, <span class=\"string\">'pre'</span>, <span class=\"string\">'code'</span>]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">MathJax.Hub.Queue(<span class=\"function\"><span class=\"title\">function</span></span>() &#123;</span><br><span class=\"line\">    var all = MathJax.Hub.getAllJax(), i;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=0; i &lt; all.length; i += 1) &#123;</span><br><span class=\"line\">        all[i].SourceElement().parentNode.className += <span class=\"string\">' has-jax'</span>;                 </span><br><span class=\"line\">    &#125;       </span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">&lt;/script&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;script <span class=\"built_in\">type</span>=<span class=\"string\">\"text/javascript\"</span> src=<span class=\"string\">\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML\"</span>&gt;</span><br><span class=\"line\">&lt;/script&gt;</span><br></pre></td></tr></table></figure></p>\n<p>src地址需要更新到mathjax接口最新地址<br>然后加载启用判断在after_footer.ejs中<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% <span class=\"keyword\">if</span> (page.mathjax)&#123; %&gt;</span><br><span class=\"line\">&lt;%- partial(<span class=\"string\">'mathjax'</span>) %&gt;</span><br><span class=\"line\">&lt;% &#125; %&gt;</span><br></pre></td></tr></table></figure></p>\n<p>2、斜线注释问题<br>在<code>node_modules\\marked\\lib\\marked.js</code>中修改两处代码这样无需替换markdown环境<br>将451行和459行的<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">escape: /^\\\\([\\\\`*&#123;&#125;\\[\\]()<span class=\"comment\"># +\\-.!_&gt;])/  </span></span><br><span class=\"line\">em: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/</span><br></pre></td></tr></table></figure></p>\n<p>替换为<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">escape: /^\\\\([`*\\[\\]()<span class=\"comment\"># +\\-.!_&gt;])/</span></span><br><span class=\"line\">em:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/</span><br></pre></td></tr></table></figure></p>\n<p>这样文章只要开启公式就可以加载公式<br>公式 test<br>$a^2=b^2+c^2$</p>\n","site":{"data":{}},"excerpt":"<p>设置VSCode下git环境<br>文件—首选项-设置<br>用户设置下 添加git路径以及git-bash终端<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"string\">\"git.path\"</span>: <span class=\"string\">\"D:\\\\Program Files\\\\Git\\\\cmd\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"terminal.integrated.shell.windows\"</span>:<span class=\"string\">\"D:\\\\ProgramFiles\\\\Git\\\\bin\\\\bash.exe\"</span>,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>","more":"<p>PS:<br>记录两天搭建环境过程中遇到的各种麻烦 好久不弄又出现一些新问题<br>一、图片加载问题<br>下面给出hexo图片公式加载环境设置<br>经过一番折腾发现加载图片必须满足一下条件<br>1、_config.yml中开启文件夹声明<br><code>post_asset_folder: true</code><br>2、npm安装图片插件<br><code>npm install hexo-asset-image --save</code><br>图片测试<br><img src=\"/2018/02/03/2018-02-03-one/1.jpg\" alt=\"\"><br>二、公式加载问题<br>此处分为两个小问题<br>一是公式插件加载问题<br>二是markdown斜线注释问题<br>1、公式插件按照网上教程加载hexo-math不成功，所以另辟蹊径采用mathjax.ejs文件建立公式环境到主题目录下mathjax.ejs:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;script <span class=\"built_in\">type</span>=<span class=\"string\">\"text/x-mathjax-config\"</span>&gt;</span><br><span class=\"line\">MathJax.Hub.Config(&#123;</span><br><span class=\"line\">    tex2jax: &#123;</span><br><span class=\"line\">        inlineMath: [ [<span class=\"string\">'$'</span>,<span class=\"string\">'$'</span>], [<span class=\"string\">\"\\\\(\"</span>,<span class=\"string\">\"\\\\)\"</span>]  ],</span><br><span class=\"line\">        processEscapes: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        skipTags: [<span class=\"string\">'script'</span>, <span class=\"string\">'noscript'</span>, <span class=\"string\">'style'</span>, <span class=\"string\">'textarea'</span>, <span class=\"string\">'pre'</span>, <span class=\"string\">'code'</span>]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">MathJax.Hub.Queue(<span class=\"function\"><span class=\"title\">function</span></span>() &#123;</span><br><span class=\"line\">    var all = MathJax.Hub.getAllJax(), i;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=0; i &lt; all.length; i += 1) &#123;</span><br><span class=\"line\">        all[i].SourceElement().parentNode.className += <span class=\"string\">' has-jax'</span>;                 </span><br><span class=\"line\">    &#125;       </span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">&lt;/script&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;script <span class=\"built_in\">type</span>=<span class=\"string\">\"text/javascript\"</span> src=<span class=\"string\">\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML\"</span>&gt;</span><br><span class=\"line\">&lt;/script&gt;</span><br></pre></td></tr></table></figure></p>\n<p>src地址需要更新到mathjax接口最新地址<br>然后加载启用判断在after_footer.ejs中<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;% <span class=\"keyword\">if</span> (page.mathjax)&#123; %&gt;</span><br><span class=\"line\">&lt;%- partial(<span class=\"string\">'mathjax'</span>) %&gt;</span><br><span class=\"line\">&lt;% &#125; %&gt;</span><br></pre></td></tr></table></figure></p>\n<p>2、斜线注释问题<br>在<code>node_modules\\marked\\lib\\marked.js</code>中修改两处代码这样无需替换markdown环境<br>将451行和459行的<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">escape: /^\\\\([\\\\`*&#123;&#125;\\[\\]()<span class=\"comment\"># +\\-.!_&gt;])/  </span></span><br><span class=\"line\">em: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/</span><br></pre></td></tr></table></figure></p>\n<p>替换为<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">escape: /^\\\\([`*\\[\\]()<span class=\"comment\"># +\\-.!_&gt;])/</span></span><br><span class=\"line\">em:/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/</span><br></pre></td></tr></table></figure></p>\n<p>这样文章只要开启公式就可以加载公式<br>公式 test<br>$a^2=b^2+c^2$</p>"},{"title":"写在前面的话","date":"2017-06-14T01:31:24.000Z","comments":1,"reward":true,"_content":"\n本主页主要用于记录个人学（wan）习（le）笔记，发波宝宝养的发发庆贺个人主页建成了！\n![](flower/flower1.jpg)\n\n<!--more-->\n![](flower/flower2.jpg)\n![](flower/flower3.jpg)\n![](flower/flower4.jpg)\n![](flower/flower5.jpg)\n![](flower/flower6.jpg)\n\n","source":"_posts/flower.md","raw":"---\ntitle: 写在前面的话\ndate: 2017-06-14 09:31:24\ncomments: true\nreward: true\ntags:\n\t- 多肉植物\n---\n\n本主页主要用于记录个人学（wan）习（le）笔记，发波宝宝养的发发庆贺个人主页建成了！\n![](flower/flower1.jpg)\n\n<!--more-->\n![](flower/flower2.jpg)\n![](flower/flower3.jpg)\n![](flower/flower4.jpg)\n![](flower/flower5.jpg)\n![](flower/flower6.jpg)\n\n","slug":"flower","published":1,"updated":"2018-01-13T08:07:57.000Z","layout":"post","photos":[],"link":"","_id":"cjd71va3h002dycvjznjjhudv","content":"<p>本主页主要用于记录个人学（wan）习（le）笔记，发波宝宝养的发发庆贺个人主页建成了！<br><img src=\"/2017/06/14/flower/flower1.jpg\" alt=\"\"></p>\n<a id=\"more\"></a>\n<p><img src=\"/2017/06/14/flower/flower2.jpg\" alt=\"\"><br><img src=\"/2017/06/14/flower/flower3.jpg\" alt=\"\"><br><img src=\"/2017/06/14/flower/flower4.jpg\" alt=\"\"><br><img src=\"/2017/06/14/flower/flower5.jpg\" alt=\"\"><br><img src=\"/2017/06/14/flower/flower6.jpg\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"<p>本主页主要用于记录个人学（wan）习（le）笔记，发波宝宝养的发发庆贺个人主页建成了！<br><img src=\"/2017/06/14/flower/flower1.jpg\" alt=\"\"></p>","more":"<p><img src=\"/2017/06/14/flower/flower2.jpg\" alt=\"\"><br><img src=\"/2017/06/14/flower/flower3.jpg\" alt=\"\"><br><img src=\"/2017/06/14/flower/flower4.jpg\" alt=\"\"><br><img src=\"/2017/06/14/flower/flower5.jpg\" alt=\"\"><br><img src=\"/2017/06/14/flower/flower6.jpg\" alt=\"\"></p>"}],"PostAsset":[{"_id":"source/_posts/2017-11-10-one/1.png","slug":"1.png","post":"cjd71va1y0003ycvjzulhiz8j","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-one/6.png","slug":"6.png","post":"cjd71va2m0015ycvjp6ntcwql","modified":0,"renderable":0},{"_id":"source/_posts/flower/flower4.jpg","slug":"flower4.jpg","post":"cjd71va3h002dycvjznjjhudv","modified":0,"renderable":0},{"_id":"source/_posts/flower/flower6.jpg","slug":"flower6.jpg","post":"cjd71va3h002dycvjznjjhudv","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-one/7.png","slug":"7.png","post":"cjd71va2m0015ycvjp6ntcwql","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-21-one/1.JPG","slug":"1.JPG","post":"cjd71va280008ycvjxdf6itu0","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-3-two/1.PNG","slug":"1.PNG","post":"cjd71va31001hycvjl4aw80qg","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-21-one/1.png","slug":"1.png","post":"cjd71va3h0027ycvjyt5n17uc","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-21-two/1.jpg","slug":"1.jpg","post":"cjd71va3h0029ycvjdojs31kg","modified":0,"renderable":0},{"_id":"source/_posts/2018-02-03-one/1.jpg","slug":"1.jpg","post":"cjd71va3h002bycvj8lubxlmz","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-28-two/1.png","slug":"1.png","post":"cjd71va2m0010ycvjnu8tgdu7","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-28-two/2.png","slug":"2.png","post":"cjd71va2m0010ycvjnu8tgdu7","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-8-two/1.png","slug":"1.png","post":"cjd71va31001lycvj67fl57va","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-8-two/2.png","slug":"2.png","post":"cjd71va31001lycvj67fl57va","modified":0,"renderable":0},{"_id":"source/_posts/2017-8-12-one/1.png","slug":"1.png","post":"cjd71va31001nycvj7wy7wt65","modified":0,"renderable":0},{"_id":"source/_posts/2017-8-12-one/2.png","slug":"2.png","post":"cjd71va31001nycvj7wy7wt65","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-14-one/1.png","slug":"1.png","post":"cjd71va3h001xycvjvfnmo829","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-14-one/2.jpg","slug":"2.jpg","post":"cjd71va3h001xycvjvfnmo829","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-three/1.png","slug":"1.png","post":"cjd71va2m0013ycvj9l5g9rf4","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-three/2.png","slug":"2.png","post":"cjd71va2m0013ycvj9l5g9rf4","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-three/3.jpg","slug":"3.jpg","post":"cjd71va2m0013ycvj9l5g9rf4","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-three/4.PNG","slug":"4.PNG","post":"cjd71va2m0013ycvj9l5g9rf4","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-8-one/1.png","slug":"1.png","post":"cjd71va31001jycvjv5pa7k6k","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-8-one/2.png","slug":"2.png","post":"cjd71va31001jycvjv5pa7k6k","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-8-one/3.png","slug":"3.png","post":"cjd71va31001jycvjv5pa7k6k","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-8-one/4.png","slug":"4.png","post":"cjd71va31001jycvjv5pa7k6k","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-28-one/1.png","slug":"1.png","post":"cjd71va2m000yycvjl165e327","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-28-one/2.png","slug":"2.png","post":"cjd71va2m000yycvjl165e327","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-28-one/3.png","slug":"3.png","post":"cjd71va2m000yycvjl165e327","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-28-one/4.png","slug":"4.png","post":"cjd71va2m000yycvjl165e327","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-28-one/5.png","slug":"5.png","post":"cjd71va2m000yycvjl165e327","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-3-one/1.png","slug":"1.png","post":"cjd71va31001dycvj9oylf9tr","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-3-one/2.jpg","slug":"2.jpg","post":"cjd71va31001dycvj9oylf9tr","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-3-one/3.png","slug":"3.png","post":"cjd71va31001dycvj9oylf9tr","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-3-one/4.png","slug":"4.png","post":"cjd71va31001dycvj9oylf9tr","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-3-one/5.png","slug":"5.png","post":"cjd71va31001dycvj9oylf9tr","modified":0,"renderable":0},{"_id":"source/_posts/2017-7-3-one/6.png","slug":"6.png","post":"cjd71va31001dycvj9oylf9tr","modified":0,"renderable":0},{"_id":"source/_posts/flower/flower1.jpg","slug":"flower1.jpg","post":"cjd71va3h002dycvjznjjhudv","modified":0,"renderable":0},{"_id":"source/_posts/flower/flower2.jpg","slug":"flower2.jpg","post":"cjd71va3h002dycvjznjjhudv","modified":0,"renderable":0},{"_id":"source/_posts/flower/flower3.jpg","slug":"flower3.jpg","post":"cjd71va3h002dycvjznjjhudv","modified":0,"renderable":0},{"_id":"source/_posts/flower/flower5.jpg","slug":"flower5.jpg","post":"cjd71va3h002dycvjznjjhudv","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-27-one/1.PNG","slug":"1.PNG","post":"cjd71va2m000oycvj6m87by53","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-27-one/2.PNG","slug":"2.PNG","post":"cjd71va2m000oycvj6m87by53","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-27-one/3.PNG","slug":"3.PNG","post":"cjd71va2m000oycvj6m87by53","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-27-one/4.PNG","slug":"4.PNG","post":"cjd71va2m000oycvj6m87by53","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-27-one/5.PNG","slug":"5.PNG","post":"cjd71va2m000oycvj6m87by53","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-27-one/6.PNG","slug":"6.PNG","post":"cjd71va2m000oycvj6m87by53","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-27-one/7.PNG","slug":"7.PNG","post":"cjd71va2m000oycvj6m87by53","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-one/1.png","slug":"1.png","post":"cjd71va2m0015ycvjp6ntcwql","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-one/2.png","slug":"2.png","post":"cjd71va2m0015ycvjp6ntcwql","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-one/3.jpg","slug":"3.jpg","post":"cjd71va2m0015ycvjp6ntcwql","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-one/4.jpg","slug":"4.jpg","post":"cjd71va2m0015ycvjp6ntcwql","modified":0,"renderable":0},{"_id":"source/_posts/2017-6-30-one/5.png","slug":"5.png","post":"cjd71va2m0015ycvjp6ntcwql","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-12-one/1.png","slug":"1.png","post":"cjd71va31001tycvjywsaaihg","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-12-one/2.png","slug":"2.png","post":"cjd71va31001tycvjywsaaihg","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-12-one/3.jpg","slug":"3.jpg","post":"cjd71va31001tycvjywsaaihg","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-12-one/4.jpg","slug":"4.jpg","post":"cjd71va31001tycvjywsaaihg","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-12-one/44.jpg","slug":"44.jpg","post":"cjd71va31001tycvjywsaaihg","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-12-one/5.jpg","slug":"5.jpg","post":"cjd71va31001tycvjywsaaihg","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-12-one/6.jpg","slug":"6.jpg","post":"cjd71va31001tycvjywsaaihg","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/1.jpg","slug":"1.jpg","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/2.jpg","slug":"2.jpg","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/3.png","slug":"3.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/4.png","slug":"4.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/5.png","slug":"5.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/6.png","slug":"6.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/7.png","slug":"7.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/8.png","slug":"8.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/c1andc2.png","slug":"c1andc2.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/c2.png","slug":"c2.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/d0.png","slug":"d0.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/d1.png","slug":"d1.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/d2.png","slug":"d2.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/g0.png","slug":"g0.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/g1.png","slug":"g1.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0},{"_id":"source/_posts/2017-9-15-one/g2.png","slug":"g2.png","post":"cjd71va3h0023ycvjlsm52vi6","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"cjd71va1c0000ycvjlsuel1e4","tag_id":"cjd71va1x0002ycvj2gwuxsk2","_id":"cjd71va270007ycvjnhf9b3mr"},{"post_id":"cjd71va280008ycvjxdf6itu0","tag_id":"cjd71va1x0002ycvj2gwuxsk2","_id":"cjd71va2f000bycvjfo9zdkts"},{"post_id":"cjd71va1u0001ycvjo7s3chx6","tag_id":"cjd71va240006ycvjf5urxjuh","_id":"cjd71va2i000dycvji93b8fsj"},{"post_id":"cjd71va2b0009ycvj2x0trmcq","tag_id":"cjd71va1x0002ycvj2gwuxsk2","_id":"cjd71va2k000gycvjartwp7ui"},{"post_id":"cjd71va2f000cycvj89pslo2x","tag_id":"cjd71va1x0002ycvj2gwuxsk2","_id":"cjd71va2m000iycvjcufd9x6u"},{"post_id":"cjd71va1y0003ycvjzulhiz8j","tag_id":"cjd71va2d000aycvjzqxc2rlx","_id":"cjd71va2m000kycvj5rf3rr2g"},{"post_id":"cjd71va2j000eycvji2660wyi","tag_id":"cjd71va1x0002ycvj2gwuxsk2","_id":"cjd71va2m000nycvjiaz38y6f"},{"post_id":"cjd71va2l000hycvjl31aoihz","tag_id":"cjd71va1x0002ycvj2gwuxsk2","_id":"cjd71va2m000pycvjj38acdxy"},{"post_id":"cjd71va200004ycvjt7kjxk1b","tag_id":"cjd71va2k000fycvjc61fcu3z","_id":"cjd71va2m000sycvj5vyi48tj"},{"post_id":"cjd71va200004ycvjt7kjxk1b","tag_id":"cjd71va2m000lycvjfa2dar1z","_id":"cjd71va2m000uycvju1kmxodg"},{"post_id":"cjd71va2m000qycvjsfxg281l","tag_id":"cjd71va1x0002ycvj2gwuxsk2","_id":"cjd71va2m000xycvj7v8x4zp7"},{"post_id":"cjd71va2m000tycvjvlf6ma4j","tag_id":"cjd71va1x0002ycvj2gwuxsk2","_id":"cjd71va2m000zycvjdavypk8z"},{"post_id":"cjd71va230005ycvjdcvz5wr9","tag_id":"cjd71va2k000fycvjc61fcu3z","_id":"cjd71va2m0012ycvjzljbalpo"},{"post_id":"cjd71va2m000yycvjl165e327","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va2m0014ycvj4ttojkr9"},{"post_id":"cjd71va2m000jycvjcze80lkd","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va310017ycvj7gahqi4t"},{"post_id":"cjd71va2m0010ycvjnu8tgdu7","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va310019ycvjy1itk03n"},{"post_id":"cjd71va2m0013ycvj9l5g9rf4","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va31001cycvjwhhjzk1w"},{"post_id":"cjd71va2m000mycvj2ml62a4g","tag_id":"cjd71va2m0011ycvjkm6xuiht","_id":"cjd71va31001eycvjskwcj097"},{"post_id":"cjd71va2m0015ycvjp6ntcwql","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va31001gycvj15ajhi0x"},{"post_id":"cjd71va310018ycvjzwi48ab3","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va31001iycvj30oh2zmh"},{"post_id":"cjd71va2m000oycvj6m87by53","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va31001kycvjk5y2ts0y"},{"post_id":"cjd71va31001aycvjy84vevpj","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va31001mycvjy3awvbh5"},{"post_id":"cjd71va31001dycvj9oylf9tr","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va31001oycvj42mqs78n"},{"post_id":"cjd71va2m000vycvjdgusaeo4","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va31001qycvjczufskxf"},{"post_id":"cjd71va31001fycvjaezexm6k","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va31001sycvju9xawfsi"},{"post_id":"cjd71va31001hycvjl4aw80qg","tag_id":"cjd71va2k000fycvjc61fcu3z","_id":"cjd71va3h001uycvjuib2m481"},{"post_id":"cjd71va31001jycvjv5pa7k6k","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h001wycvjv7comt0p"},{"post_id":"cjd71va31001lycvj67fl57va","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h001yycvja11egm3j"},{"post_id":"cjd71va31001nycvj7wy7wt65","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h0020ycvjjkyevcj0"},{"post_id":"cjd71va31001pycvjkionkmz9","tag_id":"cjd71va2k000fycvjc61fcu3z","_id":"cjd71va3h0022ycvjw27jfyu9"},{"post_id":"cjd71va31001rycvjgxpug8j1","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h0024ycvj5ipjou8r"},{"post_id":"cjd71va31001tycvjywsaaihg","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h0026ycvj9gbezy8i"},{"post_id":"cjd71va3h001vycvj2a63vpgl","tag_id":"cjd71va240006ycvjf5urxjuh","_id":"cjd71va3h0028ycvjqjbkf6ox"},{"post_id":"cjd71va3h001xycvjvfnmo829","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h002aycvjh3baq7t6"},{"post_id":"cjd71va3h001zycvjxxs31u7f","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h002cycvjgjlmmzwq"},{"post_id":"cjd71va3h0021ycvjn7xh86s4","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h002fycvjj8k4ol31"},{"post_id":"cjd71va3h0023ycvjlsm52vi6","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h002gycvjulbl39qr"},{"post_id":"cjd71va3h0025ycvjhtecjcrf","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h002hycvjvv72jnic"},{"post_id":"cjd71va3h0027ycvjyt5n17uc","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h002jycvj33uie2h3"},{"post_id":"cjd71va3h0029ycvjdojs31kg","tag_id":"cjd71va2m000wycvjpjzm1asr","_id":"cjd71va3h002kycvj6yp4j2oz"},{"post_id":"cjd71va3h002bycvj8lubxlmz","tag_id":"cjd71va3h002eycvjk8sksjvm","_id":"cjd71va3x002lycvjuvhahlp0"},{"post_id":"cjd71va3h002dycvjznjjhudv","tag_id":"cjd71va3h002iycvjbgpvs2ur","_id":"cjd71va3x002mycvjbwyxghu6"}],"Tag":[{"name":"python","_id":"cjd71va1x0002ycvj2gwuxsk2"},{"name":"LATEX","_id":"cjd71va240006ycvjf5urxjuh"},{"name":"git","_id":"cjd71va2d000aycvjzqxc2rlx"},{"name":"hexo","_id":"cjd71va2k000fycvjc61fcu3z"},{"name":"github","_id":"cjd71va2m000lycvjfa2dar1z"},{"name":"机器学习","_id":"cjd71va2m000wycvjpjzm1asr"},{"name":"BaiduYun","_id":"cjd71va2m0011ycvjkm6xuiht"},{"name":"Hexo","_id":"cjd71va3h002eycvjk8sksjvm"},{"name":"多肉植物","_id":"cjd71va3h002iycvjbgpvs2ur"}]}}